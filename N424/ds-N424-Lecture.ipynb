{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"colab":{"name":"ds-cs-N424-Lecture.ipynb","provenance":[],"toc_visible":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"867d5d2906994ff797adc53a2ff419d9":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f15d9eda9791455c869b4b79c0519b9d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_63e43782020d4a9d9c1727dd0a506318","IPY_MODEL_74901423a0924f27a08677776d415fcf"]}},"f15d9eda9791455c869b4b79c0519b9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63e43782020d4a9d9c1727dd0a506318":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","state":{"_view_name":"LabelView","style":"IPY_MODEL_abc85d2c40484f75830b5effba0dcc23","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.00MB of 0.00MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_181a9fc00a1b473fbd1d4de5431b4d13"}},"74901423a0924f27a08677776d415fcf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b99ec70fd4ff41828cd0833fd2229cb6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1bd27451c6c24a6c8922839d5958fdff"}},"abc85d2c40484f75830b5effba0dcc23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"181a9fc00a1b473fbd1d4de5431b4d13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b99ec70fd4ff41828cd0833fd2229cb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1bd27451c6c24a6c8922839d5958fdff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"41TS0Sa0rDNx"},"source":["<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n","\n","## *DATA SCIENCE / SECTION 4 / SPRINT 2 / NOTE 4*\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"QWd0b3FNfdw4"},"source":["# Neural Networks & hyperparameters (Prepare)\n","*aka Hyperparameter Tuning*\n","\n","*aka Big Servers for Big Problems*"]},{"cell_type":"markdown","metadata":{"id":"x-uha0MZi3np"},"source":["WarmUp\n","- [학습 규제 방식에 대한 설명 강의](https://youtu.be/_sz3KTyB9Lk?t=993)\n","  * L2-regularization, DropOut, Gradient Vanishing, Xavier\n","- [Gradient Descent With Momentum](https://youtu.be/yWQZcdJ4k8s?t=34)\n","  * 학습해왔던 관성의 법칙을 유지하는 방식으로 학습 개선\n","- [Batch Size](https://youtu.be/U4WB9p6ODjM?t=29)\n","  * Batch를 크게하면 좋은 이유\n","  * 그러나 항상 크게할 수 없는 이유\n","  * 일반적으로 Batch라고 하면 Mini-batch를 의미한다는 점\n"]},{"cell_type":"markdown","metadata":{"id":"6UDOYvSDnveA"},"source":["# 지난시간 복습\n","- 신경망의 순전파와 역전파 (Note 1-2)\n","  * 모델 생성과 모델 초기화 (Note 3)\n","  * 학습 과정에서 알아야 할 Tricks (Note 3)\n","  * 경사하강법의 다양성 (Note 2-3)\n","  * Overfitting 방지를 위한 노력 (Note 3)\n","- 그간 다뤄본 데이터\n","  * MNIST\n","  * Fashion MNIST"]},{"cell_type":"markdown","metadata":{"id":"9yafv0VXfdw5"},"source":["# 학습 목표\n","* <a href=\"#p1\">Part 1</a>: 대표적인 하이퍼 파라미터를 설명 할 수 있습니다\n","* <a href=\"#p2\">Part 2</a>: ETF (Experiment Tracking Framework)에 대해 알아보고 적용할 수 있습니다.\n","* <a href=\"#p3\">Part 3</a>: (Optional) RandomSearch를 사용해서 하이퍼 파라미터 공간에서 최적의 하이퍼 파라미터를 찾을 수 있습니다"]},{"cell_type":"markdown","metadata":{"id":"fmEAIyEefdw6"},"source":["# Hyperparameter Options"]},{"cell_type":"markdown","metadata":{"id":"JjDZrxWdfdw6"},"source":["## 개요\n","\n","  하이퍼 파라미터 (Hyperparameter) 튜닝은 우리가 다뤄왔었던 다른 머신러닝 알고리즘들보다 신경망에서 훨씬 더 중요합니다. 다른 지도학습 (supervised learning) 알고리즘에는 소수의 몇몇 파라미터 정도만 손보면 됐었지만, 신경망에는 훨씬 더 많은 파라미터들을 조정해야합니다. 이 파라미터들은 모델의 정확도에 엄청난 영향을 끼치기 때문에 시간은 많이 소요되더라도 신경망을 다룬다면 반드시 거쳐야하는 단계입니다. 중요한 하이퍼파라미터들은 일전 강의에서도 몇번 다뤘습니다. 오늘은 조금 더 포괄적인 개념으로 접근해보겠습니다. \n","\n","  먼저 아셔야 할 것은 ​신경망을 위한 하이퍼 파라미터 튜닝은 쉽지않습니다. '노가다'라고 말했던 것을 기억하시나요? 만약 모델의 최종 에러 평가지표(error metric)가 Linear하지 않고 불규칙적으로 변한다면 서로 다른 하이퍼 파라미터로 지정된 모델을 어떻게 비교할 수 있을까요? \n","  \n","  운 좋게 좋은 파라미터들이 걸릴 수도 있겠지만, 운이 안 좋아서 틀린 하이퍼 파라미터를 선택하게 되는 것을 어떻게 피할 수 있을까요? 사실 예제로 명시된 두 문제는 어떤 면에선 우리가 실험을 계속한다면 안고가야할 문제입니다. 실험들을 교차 검증(Cross Validation)한다면 최종적으로 계산되는 정확도들의 분산(variance)을 줄일 수 있어서 이러한 문제점들을 최소화가 가능합니다."]},{"cell_type":"markdown","metadata":{"id":"0s0o2pqBs88q"},"source":["### 실습 - Boston_Housing"]},{"cell_type":"code","metadata":{"id":"hKpOqNHXfdw7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605487587031,"user_tz":-540,"elapsed":2360,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"9884a569-deca-4386-8a90-0986d6899999"},"source":["# 데이터를 불러옵니다. \n","from tensorflow.keras.datasets import boston_housing\n","\n","(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n","57344/57026 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Pm7zow5IvaTt"},"source":["### 입력 데이터 정규화 (Normalizing)\n","\n","  입력 데이터를 신경망에 넣기 전에 정규화나 스케일링이 무조건 해야하는 것은 아닙니다, 보통 신경망이 수치형 데이터를 받으면 자체적으로 적절한 가중치를 학습해서 데이터를 다룰 수 있기 때문입니다. 하지만 학습을 빠르게 해주고, 경사하강법이 지역 최적점(local optimum)에 빠질 위험을 줄여주기 때문에 하는 것을 추천합니다. [읽어볼거리](https://stackoverflow.com/questions/4674623/why-do-we-have-to-normalize-the-input-for-an-artificial-neural-network)"]},{"cell_type":"code","metadata":{"id":"Gr0ykRBufdxA","outputId":"36dbf460-465d-4bcb-90f0-ab67023cadb5"},"source":["# 정규화를 위한 함수 호출\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)\n","print(x_train[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426\n","   0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713\n","   0.8252202 ]\n"," [-0.40342651  2.99178419 -1.33391162 -0.25683275 -1.21518188  1.89434613\n","  -1.91036058  1.24758524 -0.85646254 -0.34843254 -1.71818909  0.43190599\n","  -1.32920239]\n"," [ 0.1249402  -0.48361547  1.0283258  -0.25683275  0.62864202 -1.82968811\n","   1.11048828 -1.18743907  1.67588577  1.5652875   0.78447637  0.22061726\n","  -1.30850006]\n"," [-0.40149354 -0.48361547 -0.86940196 -0.25683275 -0.3615597  -0.3245576\n","  -1.23667187  1.10717989 -0.51114231 -1.094663    0.78447637  0.44807713\n","  -0.65292624]\n"," [-0.0056343  -0.48361547  1.0283258  -0.25683275  1.32861221  0.15364225\n","   0.69480801 -0.57857203  1.67588577  1.5652875   0.78447637  0.3898823\n","   0.26349695]\n"," [-0.37502238 -0.48361547 -0.54747912 -0.25683275 -0.54935658 -0.78865126\n","   0.18954148  0.48371503 -0.51114231 -0.71552978  0.51145832  0.38669063\n","  -0.13812828]\n"," [ 0.58963463 -0.48361547  1.0283258  -0.25683275  1.21764133 -1.03127774\n","   1.11048828 -1.06518235  1.67588577  1.5652875   0.78447637  0.44807713\n","   1.49873604]\n"," [ 0.0381708  -0.48361547  1.24588095 -0.25683275  2.67733525 -1.12719983\n","   1.11048828 -1.14833073 -0.51114231 -0.01744323 -1.71818909  0.44807713\n","   1.88793986]\n"," [-0.17228416 -0.48361547  1.24588095 -0.25683275  2.67733525 -0.90150078\n","   1.11048828 -1.09664657 -0.51114231 -0.01744323 -1.71818909 -1.97365769\n","   0.53952803]\n"," [-0.22932104 -0.48361547  1.58544339 -0.25683275  0.56888847 -1.76056777\n","   1.11048828 -1.13471925 -0.62624905  0.18716835  1.23950646  0.44807713\n","   2.99068404]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l6hgCWbir90R"},"source":["### 모델 자동 검증 기능\n","\n","우리가 늘 하는 train_test_split 대신, 케라스에는 `validation_data`라는 편리한 기능이 있습니다. 모델을 학습할 때 validation_data에 테스트 데이터를 입력하면 케라스에서 자동으로 테스트셋의 일정 부분을 검증용 데이터로 사용합니다"]},{"cell_type":"code","metadata":{"id":"GMXVfmzXp1Oo"},"source":["from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# 중요한 하이퍼 파라미터들\n","inputs = x_train.shape[1]\n","epochs = 75                 # 전체 반복횟수\n","batch_size = 10             # 한번에 학습하는 사이즈\n","\n","\n","# 모델을 생성합니다\n","model = Sequential()\n","model.add(Dense(64, activation='relu', input_shape=(inputs,)))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(1))\n","\n","# Sequential인 경우, 아래의 방법으로도 모델을 만들 수 있습니다.\n","# model = Sequential(\n","# [\n","#     Dense(64, activation='relu', input_shape=(inputs,)),\n","#     Dense(64, activation='relu'),\n","#     Dense(1)\n","# ]\n","# )\n","\n","# Compile Model\n","model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])\n","\n","# Fit Model\n","model.fit(x_train, y_train, \n","          validation_data=(x_test,y_test),  # validation set\n","          epochs=epochs,                    # 전체 반복횟수\n","          batch_size=batch_size             # 한번에 학습하는 사이즈\n","         )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sYJ8t_ezHP4W"},"source":["### 하이퍼 파라미터 튜닝 방식\n","\n","#### 1) Babysitting AKA \"Grad Student Descent\". \"육아\", 혹은 대학원생 갈아넣기\n","\n","다윈의 진화론을 아시나요? '자연 선택'이란 단어가 진화를 주도했다고 말하는데요, 우리의 선택은 자연이 해주지 않습니다. 만약 이전의 프로젝트에서 성능을 높이기 위해서 하이퍼 파라미터를 수없이 조정해봤다면, 또는 어제 여러분이 그런 일을 해보셨다면, 바로 이것을 표현한 것입니다. 이 방법은 100% 수동으로 진행되고 있어요. 학계에서 논문을 출간할 수 있을 정도로 놀라운 정확도를 보여주는 그 하이퍼 파라미터의 수치를 찾아내기 위해 쓰는 방법이죠. 물론 지도교수님들이 이 걸 직접 하시진 않습니다, 교수님의 시간은 소중하니까요... 이 방법은 소위 노가다라고 불리고 \"제출 시간 다 될 때까지 조금이라도 하이퍼 파라미터를 더 건드려본다\" 방법으로도 알려져 있습니다.\n","\n","#### 2) Grid Search\n","\n","Grid Search는 대학원생이 \"그냥 내가 실험할 것들만 컴퓨터한테 알아서 모든 조합을 돌리게 하고 난 그동안 밥이나 먹고 오면 되는 거 아닌가\"라는 기가막힌 발상입니다. 하지만 Section 2에서 여러분도 이미 겪어봤겠지만 단점이 너무나 뚜렷합니다. 범위를 잘못 설정하면 여러분이 수료하고 취직을 하고나서도 끝나지 않을 가능성도 있다라는 것입니다. 가령 5개의 하이퍼 파라미터를 5개의 값으로 각각 조정하면 5^5 = 3125개의 다른 모델을 실험하게 하는 것인데 여기다 교차 검증으로 cv = 5를 하게되면 모델은 총 15,525번을 돌아야합니다. 보다시피 전수탐색 방법은 잘못 쓰면 끝나지 않는 루프속으로 빠져들지만, 잘 활용한다면 모델의 성능을 끌어올리는데 큰 도움이 됩니다.\n","\n","Grid Search를 사용할 계획이라면, 여러 하이퍼 파라미터의 조합을 찾는 데 사용하지 말아야합니다. Grid Search는 오직 하나의 파라미터의 최적값을 찾는데 활용하시길 바랍니다. 다른 하이퍼 파라미터의 조합으로 모델의 성능이 획기적으로 올라가는 경우는 상당히 드뭅니다. 모델을 위한 하이퍼 파라미터만 제대로 튜닝해서 최적값을 쓰면서 하나씩 하이퍼 파라미터들을 조정해가면 못해도 90~95% 정도 원했던 성능값을 얻을 수 있습니다. 이런 식으로 접근하면 적어도 위에서 언급한 무한루프가 생길 위험을 줄일 수 있습니다.\n","\n","#### 3) Random Search\n","\n","Grid Search를 몇시간정도 하다보면 불현듯 자신에게 질문을 하게 됩니다. \"더 나은 방법이 있을텐데...\" 맞습니다, RandomSearch가 그 답입니다. RandomSearch를 활용하면 지정된 범위내에서 무작위로 선정한 조건으로 모델을 돌려본 후, 이 구성이 그나마 나으니까 이거 쓰고 이제 집에 가서 가족들이랑 시간을 보내라고 할 것입니다. \n","\n","Grid Search는 모든 파라미터가 동등하게 중요하다고 전제를 합니다, 하지만 꼭 그렇다고 할 수는 없습니다. 파라미터에 따라서 생각보다 더 크게 범위를 건너 뛰어야 되는 경우도 있습니다. Random Search는 상대적으로 중요하다고 생각되는 파라미터에 대해 탐색을 더 하고, 덜 중요한 하이퍼파라미터에 대해서는 실험을 덜 할 수 있도록 해줍니다. Random Search의 단점은 절대적으로 완벽한 하이퍼 파라미터를 찾아주진 않습니다. 하지만 Grid Search와 비교하면 덜 시간을 소모한다는 장점만으로도 충분히 빛을 발할 수 있습니다.\n","\n","#### 4) Bayesian Methods\n","\n","\"육아\" 방식과 GridSearch와 같은 수동적인 방식을 더 효과적으로 만들어 줄 수 있는 방식은 실험자가 결과를 보고 추후 탐색에 그 결과에서 얻은 정보를 반영하는 것입니다. 베이지안 최적화 방식을 활용한다면 우리의 하이퍼 파라미터 튜닝 방식의 \"하이퍼 파라미터 튜닝\" 할 수 있습니다. 신경망은 최적화 문제를 위한 최적화 문제 같아서 베이지안 최적화는 이전 탐색 결과를 반영해서 이후의 하이퍼 파라미터 튜닝의 성능을 높이는 전략입니다. 베이지안 방식을 활용하고 싶다면 케라스의 `keras-tuner`를 쓰면 간단하게 하실 수 있습니다. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"obzx6QgIfdxI"},"source":["## 파라미터 튜닝"]},{"cell_type":"markdown","metadata":{"id":"HfQ7D043OMMn"},"source":["### 실험해볼 수 있는 하이퍼 파라미터의 종류는 다음과 같습니다:\n","\n","- batch_size\n","- training epochs\n","- optimization algorithms\n","- learning rate (복습)\n","- momentum\n","- activation functions (복습)\n","- dropout regularization (복습)\n","- hidden layer의 neuron 갯수\n","\n","더 많은 하이퍼 파라미터가 존재하지만 중요한 것들을 골라보았고 일부는 반복해서 설명하겠습니다. "]},{"cell_type":"markdown","metadata":{"id":"Mri5-kXzVKAa"},"source":["## Batch Size\n","\n","배치 크기는 모델이 경사하강법을 통해 손실/오차 계산을 해서 모델의 가중치를 업데이트할 때 몇개의 관측치를 보게 되는지를 결정하는 파라미터입니다. 우리가 찾고자 하는 가장 적절한 곳은 가중치를 업데이트 할 수 있을만큼의 충분한 정보를 제공할 수 있는 딱 충분한 양의 관측치들인데, 이 때 너무 큰 배치 크기를 고르게 되면 한번에 모든 데이터에 대한 Loss를 계산해야 하는 문제점이 있고, 학습 속도가 빠르기 때문에 주어진 epoch 안에 가중치를 충분히 업데이트 할 만큼의 iteration을 돌릴 수 없게 되기에 적당한 양을 고르는 것이 중요합니다. Feed-forward 신경망은 다른 구조에 비해 배치 크기의 영향을 크게 받지 않습니다만, 그래도 튜닝이 필요한 중요한 하이퍼 파라미터입니다. 만약 너무 작은 사이즈를 고른다면 학습에 오랜 시간이 걸리고, 추정값에 노이즈가 많이 생기기 때문에 이 역시 지양해야합니다. 작은 Batchsize를 잘 고르면, Generlization이 잘 된다는 보고도 있습니다. 그러나 [BatchNorm](https://en.wikipedia.org/wiki/Batch_normalization)을 사용하는 효과를 볼 수 없다는 [보고](http://proceedings.mlr.press/v89/lian19a/lian19a.pdf)가 있습니다. \n","\n","대체적으로 배치 사이즈는 32에서 시작해서 512에서 멈추는 2의 제곱수로 결정합니다. 케라스는 default로 32를 배치사이즈로 정하고 있습니다. 얀 레컨의 유명한 트윗 중 하나를 보여드리겠습니다.\n","> 큰 미니배치로 학습하는 건 건강에 좋지않습니다. 주변에 혹시 32보다 큰 미니배치 쓰는 사람 있으면 돗자리 깔고 말리세요.\n","\n","저 트윗의 의미가 궁금하다면 다음의 [논문](https://arxiv.org/abs/1804.07612)을 참고해보시길 바랍니다.\n","\n","왜 배치 크기가 2의 제곱수로 설정되는지 궁금하다면 [다음 글](https://datascience.stackexchange.com/questions/20179/what-is-the-advantage-of-keeping-batch-size-a-power-of-2)을 읽어보시기 바랍니다\n","\n"]},{"cell_type":"code","metadata":{"id":"2smXfriNAGn7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605492069028,"user_tz":-540,"elapsed":19390,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"8fc0331e-2b48-498c-e15a-d3fbdf519887"},"source":["import numpy\n","import pandas as pd\n","from sklearn.model_selection import GridSearchCV\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","\n","# 재현성을 위해 랜덤시드를 생성합니다\n","#seed = 7\n","numpy.random.seed(1100)\n","\n","# 데이터셋을 불러옵니다.\n","url =\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","\n","dataset = pd.read_csv(url, header=None).values\n","\n","# 불러온 데이터셋을 X와 Y로 나눕니다\n","X = dataset[:,0:8]\n","Y = dataset[:,8]\n","\n","# 모델을 만들기 위한 함수를 만듭니다 (KerasClassifier 요구 사항)\n","def create_model():\n","    # 모델 제작\n","    model = Sequential()\n","    model.add(Dense(12, input_dim=8, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","    \n","    # 모델 컴파일링\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","# keras.wrapper를 활용하여 분류기를 만듭니다\n","model = KerasClassifier(build_fn=create_model, verbose=0)\n","\n","# GridSearch\n","batch_size = [10, 20, 40, 60, 80, 100]\n","epochs = [30]\n","param_grid = dict(batch_size=batch_size)\n","\n","# GridSearch CV를 만듭니다\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n","grid_result = grid.fit(X, Y)\n","\n","# 최적의 결과값을 낸 파라미터를 출력합니다\n","print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfe653da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfe64f6268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfed50c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfdbc6cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfdc4b1c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfe2d66a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfdd5ea400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfdb3f8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfde7b0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfe6556c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfe64fdbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcfe6556ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Best: 0.611883544921875 using {'batch_size': 100}\n","Means: 0.588787031173706, Stdev: 0.09114417717420287 with: {'batch_size': 10}\n","Means: 0.45533486008644103, Stdev: 0.1578607973725324 with: {'batch_size': 20}\n","Means: 0.5313216209411621, Stdev: 0.09518651306638408 with: {'batch_size': 40}\n","Means: 0.5680247902870178, Stdev: 0.1355803210699447 with: {'batch_size': 60}\n","Means: 0.5769459366798401, Stdev: 0.0452741273316925 with: {'batch_size': 80}\n","Means: 0.611883544921875, Stdev: 0.05903136010705967 with: {'batch_size': 100}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EKcuY6OiaLfz"},"source":["## Optimizer\n","\n","최적화도구(Optimizer, 옵티마이저)에 지난 시간에 많이 다뤄보았기 때문에 대해서는 간단하게 언급하고 넘어가겠습니다. 시간이 된다면 케라스에 있는 다양한 옵티마이저들에 대해 읽어보시길 바랍니다. \"adam\" optimizer가 보통 제일 좋은 결과를 제공합니다. 요즘은 adamW 등도 많이 사용하는데, 무엇을 선택하든 옵티마이저를 선택하는데 있어서 알아야 할 것은 옵티마이저에 따라 하이퍼 파라미터의 종류, 값 역시 달라진다는 점입니다 (learning rate, momentum, etc.) 그래서 여러분이 어떤 옵티마이저를 선택하느냐에 따라서 옵티마이저의 learning rate이나 momentum을 튜닝해야 할 수도 있습니다."]},{"cell_type":"markdown","metadata":{"id":"DG3wq5iOaLig"},"source":["## Learning Rate\n","\n","  Learning Rate은 경사하강법 기반의 optimizer 선택을 위한 하이퍼 파라미터입니다. 그러면 기존에는 어떻게 사용되었을까요? 기본 값으로 0.01로 [설정](https://www.google.com/search?q=keras+default+learning+rate&oq=keras+default+learning+rate&aqs=chrome..69i57j0i22i30l2.4191j0j7&sourceid=chrome&ie=UTF-8)되어있습니다. learning rate (학습율)이 너무 높은 경우에는 모델이 발산하게 해버리는데, 반대로 너무 낮게 설정하면 모델이 수렴하는데 실패하게 됩니다 (최적의 학습율을 찾아야 하는거죠). 일단은 크기순으로 learning rate을 튜닝합니다 ([.001, .01, .1, .2, .3, .5]). 0.5보다 높이 잡는 것은 추천하지 않지만, 한번 높이 설정한 후에 그 이유를 알아보는 것도 좋은 공부가 될 것입니다.\n","\n","어느정도 범위를 좁혔다면, 갯수를 줄여서 다시 한번 해봅니다. 만약 시도한 후에 모델이 0.1을 최적의 옵티마이저라고 한다면,[.05, .08, .1, .12, .15]로 시도해서 더 좁혀들어가보면 좋을 것 같습니다 (아직 \"최고\"를 찾진 못했으니까요) \n","\n","학습율의 튜닝과 같이 epoch의 횟수도 튜닝하는 것이 좋습니다. 왜냐하면 learning rate이 최솟값에 도달할 수 있을 때까지 iteration의 횟수를 충분히 설정했는지를 판단할 수 있기 때문입니다."]},{"cell_type":"markdown","metadata":{"id":"gNTBUWd1aLlA"},"source":["## Momentum\n","\n","모멘텀은 기본 확률적 경사 하강법과 대체적으로 많이 연관됩니다. SGD는 꽤 흔한 옵티마이저인데요, 그 이유는 사람들이 많이 이해하고 알고 있는 옵티마이저이기 때문입니다. SGD가 최고의 결과값을 도출할지는 솔직히 모르겠습니다, 하이퍼 파라미터 튜닝을 통해서 속성들을 튜닝하고 adam 옵티마이저보다 좋은 결과를 낼 수 있는지 도전해봐도 좋을 것 같습니다. 모멘텀은 옵티마이저가 최솟값을 overshooting 하게 결정하는 속성입니다. 오목한 밥그릇 한쪽에서 공을 굴리면 반대쪽에 있다가 바로 밑으로 내려가지않고 관성에 의해서 잠시 머물다 다시 내려오는 것을 상상해보세요. 모멘텀의 목적은 지역 최소점(local minima)에서 탈출하도록 시도하는 것입니다"]},{"cell_type":"markdown","metadata":{"id":"xnEG-bCJaLnZ"},"source":["## Activation Functions\n","\n","활성화 함수에 대해선 잠깐 이야기를 나눴는데요, 보통은 은닉층에는 ReLU를 사용하고 출력층에는 Sigmoid (이진 분류)나 Softmax (다중분류)를 사용합니다, 하지만 모델에 따라서 `sigmoid`, `tanh` 등 다른 활성함수들을 시도해보고 결과가 더 괜찮게 나오는지 확인해보는 것도 좋습니다 (물론 역시는 역시나일 수도 있습니다).   "]},{"cell_type":"markdown","metadata":{"id":"oul9sPq-dU-h"},"source":["## Network Weight Initialization\n","\n","우리는 처음에 망의 가중치 초기화를 어떻게 하는지에 따라 결과에 얼마나 큰 영향을 끼치는지 봤습니다. 가중치 초기화 모드는 매우 다양합니다 (아래에 종류를 적어놨습니다). 모든 것을 써볼 일은 아마 없겠지만 어떤 것을 선택하는지에 따라 모델의 초기 정확도에 큰 영향을 끼칩니다. 우리가 가중치를 잘 초기화하면 훨씬 적은 epoch으로 모델을 위한 최적의 가중치를 찾을 수 있습니다.\n","\n","> 가중치 표준편차를 1인 정규분포로 초기화를 할 때 활성화 값의 분포\n","\n","<img src=\"https://t1.daumcdn.net/cfile/tistory/994C2F3C5AB623C526\" width=600/>\n","\n","> 가중치의 편차를 1/sqrt(n) 으로 초기화한 Xavier 초기값의 활성화 값의 분포\n","\n","<img src=\"https://postfiles.pstatic.net/MjAxOTA3MjlfMzgg/MDAxNTY0Mzg4Nzk5NzY4.h7xAk1g9M4giZaliyznlzL6ri5f_gdeH0v0BwUXy6ZQg.s0RUasLqzISu_NU6k2Mi-tuejq62S4AOVc_rN8pgYaMg.PNG.tinz6461/image.png?type=w773\" width=580/>\n","\n","> 가중치 표준편차를 sqrt(2/n)으로 초기화한 He 초기값의 활성화 값의 분포\n","\n","<img src=\"https://postfiles.pstatic.net/MjAxOTA3MjlfMTc5/MDAxNTY0MzkyNDc3MTQx.Ge4g0BNWVB_OCwM1cbJ6QVOtIoSptaOwUrOBB4os6Awg.oOtc30idBFbagvrbyuD6m_QD80PS8_xOV39POd-n-Lsg.PNG.tinz6461/image.png?type=w773\" width=580/>\n","\n","c.f. Activation function에 따른 초기값 추천\n","   > ① Sigmoid  ⇒  Xavier 초기화를 사용하는 것이 유리 \n","\n","   > ② ReLU  ⇒  He 초기화 사용하는 것이 유리\n","\n","\n","`init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']`"]},{"cell_type":"markdown","metadata":{"id":"bqtEuxeQaLqE"},"source":["## 드롭아웃과 가중치 규제 (Weight Constraint)\n","\n","드롭아웃 규제값은 학습 중에 무작위로 비활성화 하고 싶은 뉴런들의 비율입니다. 지난 시간에 공부했던 것처럼, 가중치 제약(Weight Constraint)은 드롭아웃과 함께 쓰는 두번째 규제 파라미터입니다. 튜닝을 할 때는 이 두개값 모두 튜닝해야합니다.\n","드롭아웃을 어느 layer (visible vs. hidden)에 적용하는지에 따라 다른 효과를 불러올 수 있습니다. 은닉층에 드롭아웃을 썼을 때 엄청난 효과를 부를 때도 있지만, 반대로 아무런 일도 일어나지 않을 수 있는 것 입니다. 사용하고 있는 모델이 과적합이나 일반화 문제가 있지 않다면 굳이 쓸 필요는 없습니다. \n","다음 주에 공부하게될 다양한 모델들을 보시면, Dropout이 많이 적용되어 있는 것을 보실 수 있는데요, 그때에 아 여기에서는 규제방법들을 이용해서 문제를 해결해야 했구나 정도로 알고 넘어가시면 되겠습니다."]},{"cell_type":"markdown","metadata":{"id":"P2c5Cv6oaLtO"},"source":["## 은닉층의 숨겨진 뉴런들\n","\n","\n","우리가 하나의 퍼셉트론만 있었을 때 선형적으로 분리가 가능한 데이터만 학습이 가능했던 것을 기억하시나요? 하지만 layer와 노드들을 신경망에 추가할 수록 비선형 데이터 학습도 가능하게 되었습니다. 신경망이 크면 클수록, 노드가 많으면 많을 수록 신경망 역시 비선형 데이터도 학습 시킬 수 있습니다. 다만 많은 노드와 레이어는 학습 시간을 늘리게 되고 모델이 과적합할 확률을 높입니다. 신경망이 커질수록 드롭아웃 규제나 다른 규제 방법으로 이러한 가능성들에 대비하고 있어야 합니다.\n","\n","보통 깊이 (layer 추가)가 길이 (노드 추가)보다 신경망에 더 중요합니다. 이것이 딥러닝에 사람들이 몰리는 이유입니다. 몇가지 딥러닝 구조는 몇가지 머신러닝 프로젝트들에 혁신을 불러왔습니다.\n","다른 망 구조를 참조하게 될 수도 있습니다. 예를 들어 이미지 분류 문제를 풀 때 만약 resnet, inception, ResNeXt, SENet, EfficientNet 등의 SOTA (State of the Art: 최신/최고 기술)를 활용하지 않았다고 가정해보겠습니다. 그럼 아마도 좋은 성능의 모델을 찾기 위해서 수많은 시간을 실험에 할애하게 될 것입니다.\n","물론 휴리스틱은 존재하지만, 직접 다양한 값들을 실험해보면서 자신만의 감을 찾으면서 문제를 해결하는 것이 장기적으로 훨씬 더 많은 도움이 되기 때문에 아래의 글은 어디까지나 \"참고\"만 하시길 바랍니다. \n","- https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/"]},{"cell_type":"markdown","metadata":{"id":"8XVBDUE2fdxQ"},"source":["# 실험 기록 프레임워크\n","<a id=\"p2\"></a>"]},{"cell_type":"markdown","metadata":{"id":"rX7aetDxfdxQ"},"source":["## Overview\n","\n","다양한 실험을 진행하다보면 점점 결과들을 관리하는 것이 점점 힘들어지는 것을 느끼게 될 것입니다. 어떤 파라미터 조합이 제일 좋았지? 어제 했던 결과와 차이가 있었던가? 비록 파이썬 노트북을 활용하고 있지만, 사실 실험 결과를 기록하기엔 적절하지 않습니다. 이 때 Comet.ml 과 Weights and Biases가 이러한 고민들을 해결 해줄 수 있습니다.\n","이 도구들은 여러분이 실험을 실시간으로 기록하고, 실험에 쓰인 코드와 결과값을 보관해줍니다. 실험 결과는 원하는 평가지표로 언제든지 시각화해서 모델의 성능을 볼 수 있게 해줍니다. epoch이 끝날 때마다 데이터가 해당 툴들에 보내지고, 모델이 수렴하고 있는지 확인할 수 있습니다. 오늘은 Weights and Biases를 활용해보겠습니다"]},{"cell_type":"markdown","metadata":{"id":"VZCfTFuKfdxR"},"source":["## Follow Along\n"," \n","먼저 다음 셀을 실행하기 전에 터미널에서 `wandb`에 로그인이 되있어야 합니다. \n","\n","```zsh\n","# 아래의 커맨드를 실행합니다\n","wandb.login\n","```\n","구체적인 방법은 Weights and Biases의 [QuickStart](https://docs.wandb.com/quickstart)를 참고해주시길 바랍니다"]},{"cell_type":"code","metadata":{"id":"ZnsBwJ-ToZMK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606290404844,"user_tz":-540,"elapsed":12444,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"6928c3cb-1546-42f0-e313-94d6874d7c08"},"source":["!pip install wandb"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/7c/bf3cba8513f02c92fff0f0dab49846f1aa3da93c71fb4de7f34f501d15f0/wandb-0.10.11-py2.py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 10.2MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n","Collecting watchdog>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/10/500580a0987363a0d9e1f3dd5cb1bba94a47e19266c6ce9dfb6cdd455758/watchdog-0.10.4.tar.gz (98kB)\n","\u001b[K     |████████████████████████████████| 102kB 9.3MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/e1/3a9f8ca1009fc6a1e850801f2386e9d88b95147218cbe8c33bc4d60b3695/sentry_sdk-0.19.4-py2.py3-none-any.whl (128kB)\n","\u001b[K     |████████████████████████████████| 133kB 37.7MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 36.7MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n","Collecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/08/b2/ef713e0e67f6e7ec7d59aea3ee78d05b39c15930057e724cc6d362a8c3bb/configparser-5.0.1-py3-none-any.whl\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 7.3MB/s \n","\u001b[?25hCollecting pathtools>=0.1.1\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.2)\n","Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.9MB/s \n","\u001b[?25hCollecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n","Building wheels for collected packages: watchdog, subprocess32, pathtools\n","  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for watchdog: filename=watchdog-0.10.4-cp36-none-any.whl size=74841 sha256=6947c64c9f265c11ef3bfbc051e30899b5ab9b59140a62ee9cde96498d099245\n","  Stored in directory: /root/.cache/pip/wheels/9e/11/04/5160b8815b0cc7cf574bdc6d053e510169ec264c8791b4ec3a\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=755872eb7c31849b36444f902c80936c69116a1ebdb343d20c2b385ac5eea63e\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=4fd92ca9f4293e358fdaafa80f4437bfb4af214f687d9f4a083131762fc693c2\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","Successfully built watchdog subprocess32 pathtools\n","Installing collected packages: pathtools, watchdog, shortuuid, sentry-sdk, docker-pycreds, smmap, gitdb, GitPython, configparser, subprocess32, wandb\n","Successfully installed GitPython-3.1.11 configparser-5.0.1 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-0.19.4 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.10.11 watchdog-0.10.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5wpf-SzxfdxS"},"source":["import wandb\n","from wandb.keras import WandbCallback"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RWmT0WCfdxU"},"source":["# group, project 변수를 설정합니다.\n","wandb_project = \"\"\n","wandb_group = \"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTHKXKK3pMsh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606290422470,"user_tz":-540,"elapsed":2394,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"d2f80910-ed07-409c-db32-dde596583335"},"source":["!git clone http://github.com/wandb/tutorial"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'tutorial'...\n","warning: redirecting to https://github.com/wandb/tutorial/\n","remote: Enumerating objects: 8, done.\u001b[K\n","remote: Counting objects: 100% (8/8), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 39 (delta 3), reused 6 (delta 2), pack-reused 31\u001b[K\n","Unpacking objects: 100% (39/39), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"68WPyCBypMvS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606290511821,"user_tz":-540,"elapsed":84933,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"aad24f0d-4b26-4438-c947-0e3302fe2f6a"},"source":["!cd tutorial; pip install --upgrade -r requirements.txt;"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ad/769c195c72ac72040635c66cd9ba7b0f4b4fc1ac67e59b99fa6988446c22/tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n","\u001b[K     |████████████████████████████████| 320.4MB 47kB/s \n","\u001b[?25hRequirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2.4.3)\n","Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.1.4)\n","Collecting numpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/86/753182c9085ba4936c0076269a571613387cdb77ae2bf537448bfd63472c/numpy-1.19.4-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n","\u001b[K     |████████████████████████████████| 14.5MB 340kB/s \n","\u001b[?25hCollecting pillow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/19/d4c25111d36163698396f93c363114cf1cddbacb24744f6612f25b6aa3d0/Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 41.4MB/s \n","\u001b[?25hRequirement already up-to-date: wandb in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.10.11)\n","Collecting h5py\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/7a/e53e500335afb6b1aade11227cdf107fca54106a1dca5c9d13242a043f3b/h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n","\u001b[K     |████████████████████████████████| 4.0MB 43.4MB/s \n","\u001b[?25hCollecting opencv-python\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/80/10a9ae6fa0940f25af32739d1dc6dfdbbdc79af3f04c5ea1a6de4303cd54/opencv_python-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (49.5MB)\n","\u001b[K     |████████████████████████████████| 49.5MB 70kB/s \n","\u001b[?25hCollecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n","\u001b[K     |████████████████████████████████| 6.8MB 33.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (2.3.0)\n","Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (0.3.3)\n","Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.1.2)\n","Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.6.3)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.12.1)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (3.12.4)\n","Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (2.3.0)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (3.3.0)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (0.10.0)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.33.2)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r requirements.txt (line 1)) (0.35.1)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 2)) (3.13)\n","Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->-r requirements.txt (line 2)) (1.4.1)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n","Requirement already satisfied, skipping upgrade: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (0.10.4)\n","Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (7.1.2)\n","Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (5.4.8)\n","Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (5.0.1)\n","Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (2.3)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (3.1.11)\n","Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (0.19.4)\n","Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (3.5.4)\n","Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb->-r requirements.txt (line 6)) (0.4.0)\n","Collecting cached-property; python_version < \"3.8\"\n","  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (0.17.0)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow->-r requirements.txt (line 1)) (50.3.2)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (1.17.2)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (1.0.1)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (3.3.3)\n","Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (1.7.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (0.4.2)\n","Requirement already satisfied, skipping upgrade: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb->-r requirements.txt (line 6)) (0.1.2)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 6)) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 6)) (2020.11.8)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 6)) (4.0.5)\n","Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (4.1.1)\n","Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (4.6)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (0.2.8)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (2.0.0)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (0.4.8)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (3.4.0)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 1)) (3.1.0)\n","\u001b[31mERROR: tensorflow 2.3.1 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.3.1 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.4 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, cached-property, h5py, tensorflow, pillow, opencv-python, threadpoolctl, scikit-learn\n","  Found existing installation: numpy 1.18.5\n","    Uninstalling numpy-1.18.5:\n","      Successfully uninstalled numpy-1.18.5\n","  Found existing installation: h5py 2.10.0\n","    Uninstalling h5py-2.10.0:\n","      Successfully uninstalled h5py-2.10.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","  Found existing installation: Pillow 7.0.0\n","    Uninstalling Pillow-7.0.0:\n","      Successfully uninstalled Pillow-7.0.0\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed cached-property-1.5.2 h5py-3.1.0 numpy-1.19.4 opencv-python-4.4.0.46 pillow-8.0.1 scikit-learn-0.23.2 tensorflow-2.3.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U3-zYyZUpMyS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606290758399,"user_tz":-540,"elapsed":2186,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"0e69bbfd-49f8-4ea2-809b-0ccd26303664"},"source":["!wandb login 6a1f7dd199ef2c241cc2dafb7ae52925d6de7385"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gtmJPO-tfdxW","colab":{"base_uri":"https://localhost:8080/","height":731,"referenced_widgets":["867d5d2906994ff797adc53a2ff419d9","f15d9eda9791455c869b4b79c0519b9d","63e43782020d4a9d9c1727dd0a506318","74901423a0924f27a08677776d415fcf","abc85d2c40484f75830b5effba0dcc23","181a9fc00a1b473fbd1d4de5431b4d13","b99ec70fd4ff41828cd0833fd2229cb6","1bd27451c6c24a6c8922839d5958fdff"]},"executionInfo":{"status":"error","timestamp":1606290909101,"user_tz":-540,"elapsed":6192,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"7cbe363c-98b5-4615-88e4-0146a451d3a4"},"source":["import numpy\n","import pandas as pd\n","from sklearn.model_selection import GridSearchCV\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","wandb.init(project='dsft02') \n","\n","# 데이터 및 하이퍼파라미터 설정\n","X =  x_train\n","y =  y_train\n","\n","inputs = X.shape[1]\n","wandb.config.epochs = 50\n","wandb.config.batch_size = 10\n","\n","# 모델을 구축합니다\n","model = Sequential()\n","model.add(Dense(64, activation='relu', input_shape=(inputs,)))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(1))\n","\n","# 모델을 컴파일 합니다\n","model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])\n","\n","# 모델을 학습합니다\n","model.fit(X, y, \n","          validation_split=0.33, \n","          epochs=wandb.config.epochs, \n","          batch_size=wandb.config.batch_size, \n","          callbacks=[WandbCallback()]\n","         )"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["Finishing last run (ID:149mz8ok) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 289<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"867d5d2906994ff797adc53a2ff419d9","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["...Successfully finished last run (ID:149mz8ok). Initializing new run:<br/><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.11<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">rare-frog-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/ds-ssb/dsft02\" target=\"_blank\">https://wandb.ai/ds-ssb/dsft02</a><br/>\n","                Run page: <a href=\"https://wandb.ai/ds-ssb/dsft02/runs/3fo689wl\" target=\"_blank\">https://wandb.ai/ds-ssb/dsft02/runs/3fo689wl</a><br/>\n","                Run data is saved locally in <code>/content/wandb/run-20201125_075503-3fo689wl</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1/50\n","WARNING:tensorflow:Model was constructed with shape (None, 28) for input Tensor(\"dense_4_input:0\", shape=(None, 28), dtype=float32), but it was called on an input with incompatible shape (None, 28, 28).\n","WARNING:tensorflow:Model was constructed with shape (None, 28) for input Tensor(\"dense_4_input:0\", shape=(None, 28), dtype=float32), but it was called on an input with incompatible shape (None, 28, 28).\n","1087/4020 [=======>......................] - ETA: 6s - loss: 8.5644 - mse: 8.5644 - mae: 2.5118"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-7900830d0181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWandbCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m          )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"nbDi0Zuqt4AP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605507738798,"user_tz":-540,"elapsed":780,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"4d3c95d8-c9aa-4b11-99f2-4d59bcbd5245"},"source":["!ls wandb/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["debug-internal.log  debug.log  latest-run  run-20201116_062105-1jbu2nbo\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mlReqFEQfdxY"},"source":["### Your Turn\n","\n","예시에서 사용하지 않았던 하이퍼 파라미터를 몇개 골라서 튜닝을 한 후 모델을 학습해보세요. 결과는 Weights & Bias에 제출해봅니다."]},{"cell_type":"code","metadata":{"id":"Ghd5nDc5vQg5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605508079165,"user_tz":-540,"elapsed":1904,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"080ed9ea-46e1-4571-e289-37fdf84e3714"},"source":["!wandb login 6a1f7dd199ef2c241cc2dafb7ae52925d6de7385"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xquf5nl2fdxZ"},"source":["wandb_project = \"n424\"\n","\n","wandb.init(project=wandb_project) # 초기화 및 실험 준비\n","wandb.config.epochs = 50  # epoch 수 설정\n","wandb.config.batch_size = 10 # 배치 크기 설정\n","\n","# 모델을 학습합니다\n","model.fit(X, y, \n","          validation_split=0.33, \n","          epochs=wandb.config.epochs, \n","          batch_size=wandb.config.batch_size, \n","          callbacks=[WandbCallback()]\n","         )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W10gr1J_fdxb"},"source":["## Challenge\n","\n","오늘의 과제에서는 Weights & Biases에서 모델을 학습하고 튜닝해보는 연습을 하게 될 것 입니다"]},{"cell_type":"markdown","metadata":{"id":"5L5hcEQrfdxb"},"source":["# Hyperparameters with RandomSearchCV (Learn)"]},{"cell_type":"markdown","metadata":{"id":"ZnolFwy0fdxc"},"source":["## Overview\n","\n","`GridSearchCV`는 시간이 너무 오래 소요됩니다. 조금 더 세련된 전략이 필요해질 것입니다.\n","Keras-Tuner를 사용해서 다른 방법을 찾아보겠습니다"]},{"cell_type":"code","metadata":{"id":"dWlSrNhOfdxc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605508463966,"user_tz":-540,"elapsed":6652,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"ca48a3f4-1088-4c9a-b96e-2acc3e971d6f"},"source":["!pip install keras-tuner"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting keras-tuner\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/f7/4b41b6832abf4c9bef71a664dc563adb25afc5812831667c6db572b1a261/keras-tuner-1.0.1.tar.gz (54kB)\n","\r\u001b[K     |██████                          | 10kB 10.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 20kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 40kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 51kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.7MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.19.4)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n","Collecting terminaltables\n","  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.23.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (2.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.17.0)\n","Building wheels for collected packages: keras-tuner, terminaltables\n","  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-cp36-none-any.whl size=73200 sha256=6deda35942d7c6a8d987538b38c8d3d5287889544aeca43f94ba88cacfc2a81e\n","  Stored in directory: /root/.cache/pip/wheels/b9/cc/62/52716b70dd90f3db12519233c3a93a5360bc672da1a10ded43\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=a0e740685ff28531dd1d8e8be9a6ed11717c1fba10732eaf48ebf2e22b7e39fb\n","  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n","Successfully built keras-tuner terminaltables\n","Installing collected packages: terminaltables, colorama, keras-tuner\n","Successfully installed colorama-0.4.4 keras-tuner-1.0.1 terminaltables-3.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V7kk_Qo05x3p"},"source":["기존 샘플로 확인해보기"]},{"cell_type":"code","metadata":{"id":"XX0V01bW5w9n","colab":{"base_uri":"https://localhost:8080/","height":735},"executionInfo":{"status":"ok","timestamp":1606290832059,"user_tz":-540,"elapsed":52346,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"eee5011c-cd1a-499f-f30f-04d369b772d1"},"source":["import pandas as pd\n","!pip install tensorflow-gpu==2.0.0-rc1\n","import tensorflow as tf\n","\n","\n","mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==2.0.0-rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n","\u001b[K     |████████████████████████████████| 380.5MB 43kB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.12.4)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.33.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.35.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.19.4)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.3.3)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.0)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.10.0)\n","Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n","\u001b[K     |████████████████████████████████| 4.3MB 42.6MB/s \n","\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n","\u001b[K     |████████████████████████████████| 501kB 44.6MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-rc1) (50.3.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (3.1.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.3.3)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (1.5.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (2.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.4.0)\n","Installing collected packages: keras-applications, tb-nightly, tf-estimator-nightly, tensorflow-gpu\n","Successfully installed keras-applications-1.0.8 tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorboard","tensorflow"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w37ibImf508_"},"source":["from kerastuner.tuners import RandomSearch\n","\n","def build_model(hp):\n","\n","    model = tf.keras.models.Sequential([\n","      tf.keras.layers.Flatten(input_shape=(28, 28)),\n","      tf.keras.layers.Dense(units=hp.Int('units',\n","                                      min_value=32,\n","                                      max_value=256,\n","                                      step=32),\n","                                      activation='relu'),\n","      tf.keras.layers.Dropout(0.2), # 다음강의에서 설명이 될 component :: 존재목적 Overfitting 방지\n","      tf.keras.layers.Dense(10, activation='softmax')\n","    ])\n","    \n","    model.compile(\n","        optimizer=keras.optimizers.Adam(\n","            hp.Choice('learning_rate',\n","                      values=[1e-2, 1e-3, 1e-4])),\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy'])\n","    \n","    return model\n","\n","    \n","# model = tf.keras.models.Sequential([\n","#   tf.keras.layers.Flatten(input_shape=(28, 28)),\n","#   tf.keras.layers.Dense(units=hp.Int('units',\n","#                                       min_value=32,\n","#                                       max_value=256,\n","#                                       step=32),\n","#                                       activation='relu'),\n","#   tf.keras.layers.Dropout(0.2), # 다음강의에서 설명이 될 component :: 존재목적 Overfitting 방지\n","#   tf.keras.layers.Dense(10, activation='softmax')\n","# ])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nfw_Rh5f7Grt"},"source":["tuner = RandomSearch(\n","    build_model,\n","    objective='val_accuracy',\n","    max_trials=5,\n","    executions_per_trial=3,\n","    directory='./keras-tuner-trial',\n","    project_name='helloworld')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cjDyD9CB51CX","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1605511312035,"user_tz":-540,"elapsed":1809,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"0d532248-d103-4926-cc20-3c21ff9c07d1"},"source":["tuner.search_space_summary()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Default search space size: 2</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-default: None</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-max_value: 256</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-min_value: 32</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-sampling: None</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-step: 32</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-default: 0.01</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-ordered: True</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"3--yl4VK51Eq","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1605511692406,"user_tz":-540,"elapsed":372887,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"43144ae2-daa2-4dae-9549-34ad776e5afd"},"source":["tuner.search(x_train, y_train,\n","             epochs=5,\n","             validation_data=(x_test, y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2822 - accuracy: 0.9173 - val_loss: 0.1321 - val_accuracy: 0.9614\n","Epoch 2/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.1330 - accuracy: 0.9598 - val_loss: 0.0965 - val_accuracy: 0.9712\n","Epoch 3/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.1001 - accuracy: 0.9690 - val_loss: 0.0820 - val_accuracy: 0.9770\n","Epoch 4/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0798 - accuracy: 0.9756 - val_loss: 0.0740 - val_accuracy: 0.9772\n","Epoch 5/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0674 - accuracy: 0.9788 - val_loss: 0.0745 - val_accuracy: 0.9774\n","Epoch 1/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.2806 - accuracy: 0.9166 - val_loss: 0.1359 - val_accuracy: 0.9603\n","Epoch 2/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.1318 - accuracy: 0.9606 - val_loss: 0.0951 - val_accuracy: 0.9706\n","Epoch 3/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0961 - accuracy: 0.9703 - val_loss: 0.0806 - val_accuracy: 0.9746\n","Epoch 4/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0784 - accuracy: 0.9759 - val_loss: 0.0768 - val_accuracy: 0.9754\n","Epoch 5/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0658 - accuracy: 0.9796 - val_loss: 0.0734 - val_accuracy: 0.9771\n","Epoch 1/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2759 - accuracy: 0.9204 - val_loss: 0.1272 - val_accuracy: 0.9618\n","Epoch 2/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.1321 - accuracy: 0.9604 - val_loss: 0.0978 - val_accuracy: 0.9706\n","Epoch 3/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0955 - accuracy: 0.9712 - val_loss: 0.0911 - val_accuracy: 0.9741\n","Epoch 4/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0791 - accuracy: 0.9758 - val_loss: 0.0728 - val_accuracy: 0.9781\n","Epoch 5/5\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.0655 - accuracy: 0.9796 - val_loss: 0.0775 - val_accuracy: 0.9770\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: dff604ef9e5ea41e5fc504296d1075b6</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9775333404541016</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 160</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3246 - accuracy: 0.9025 - val_loss: 0.1724 - val_accuracy: 0.9487\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2430 - accuracy: 0.9302 - val_loss: 0.1768 - val_accuracy: 0.9541\n","Epoch 3/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.2282 - accuracy: 0.9374 - val_loss: 0.1813 - val_accuracy: 0.9570\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2215 - accuracy: 0.9396 - val_loss: 0.1996 - val_accuracy: 0.9518\n","Epoch 5/5\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.2059 - accuracy: 0.9444 - val_loss: 0.2171 - val_accuracy: 0.9498\n","Epoch 1/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.3296 - accuracy: 0.9026 - val_loss: 0.1890 - val_accuracy: 0.9448\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2535 - accuracy: 0.9281 - val_loss: 0.1555 - val_accuracy: 0.9567\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2275 - accuracy: 0.9371 - val_loss: 0.1782 - val_accuracy: 0.9507\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2178 - accuracy: 0.9405 - val_loss: 0.1553 - val_accuracy: 0.9620\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2112 - accuracy: 0.9433 - val_loss: 0.1913 - val_accuracy: 0.9568\n","Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3238 - accuracy: 0.9022 - val_loss: 0.1661 - val_accuracy: 0.9511\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2469 - accuracy: 0.9298 - val_loss: 0.1815 - val_accuracy: 0.9520\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2292 - accuracy: 0.9362 - val_loss: 0.1732 - val_accuracy: 0.9560\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2288 - accuracy: 0.9388 - val_loss: 0.1803 - val_accuracy: 0.9564\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2041 - accuracy: 0.9451 - val_loss: 0.2115 - val_accuracy: 0.9570\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: 587f6b517f3b69311174cbd8799825f8</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9586666822433472</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 96</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.3218 - accuracy: 0.9081 - val_loss: 0.1902 - val_accuracy: 0.9483\n","Epoch 2/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2422 - accuracy: 0.9343 - val_loss: 0.2003 - val_accuracy: 0.9480\n","Epoch 3/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2273 - accuracy: 0.9397 - val_loss: 0.2019 - val_accuracy: 0.9536\n","Epoch 4/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2218 - accuracy: 0.9436 - val_loss: 0.1814 - val_accuracy: 0.9534\n","Epoch 5/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2076 - accuracy: 0.9476 - val_loss: 0.1879 - val_accuracy: 0.9586\n","Epoch 1/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.3131 - accuracy: 0.9070 - val_loss: 0.1890 - val_accuracy: 0.9467\n","Epoch 2/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2407 - accuracy: 0.9332 - val_loss: 0.1747 - val_accuracy: 0.9506\n","Epoch 3/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2230 - accuracy: 0.9409 - val_loss: 0.1891 - val_accuracy: 0.9541\n","Epoch 4/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2178 - accuracy: 0.9429 - val_loss: 0.1879 - val_accuracy: 0.9568\n","Epoch 5/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2053 - accuracy: 0.9467 - val_loss: 0.2164 - val_accuracy: 0.9581\n","Epoch 1/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.3083 - accuracy: 0.9098 - val_loss: 0.1695 - val_accuracy: 0.9551\n","Epoch 2/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2474 - accuracy: 0.9320 - val_loss: 0.1650 - val_accuracy: 0.9565\n","Epoch 3/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2307 - accuracy: 0.9384 - val_loss: 0.1824 - val_accuracy: 0.9573\n","Epoch 4/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2134 - accuracy: 0.9459 - val_loss: 0.1886 - val_accuracy: 0.9622\n","Epoch 5/5\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2093 - accuracy: 0.9482 - val_loss: 0.1622 - val_accuracy: 0.9606\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: 9df1b3d84ae227f1d0db03a4515e5d10</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9596333305040995</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 192</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3366 - accuracy: 0.8977 - val_loss: 0.1833 - val_accuracy: 0.9465\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2598 - accuracy: 0.9250 - val_loss: 0.1690 - val_accuracy: 0.9532\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2374 - accuracy: 0.9312 - val_loss: 0.1581 - val_accuracy: 0.9582\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2244 - accuracy: 0.9356 - val_loss: 0.1650 - val_accuracy: 0.9604\n","Epoch 5/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.2215 - accuracy: 0.9373 - val_loss: 0.1909 - val_accuracy: 0.9511\n","Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3420 - accuracy: 0.8973 - val_loss: 0.1884 - val_accuracy: 0.9442\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2550 - accuracy: 0.9257 - val_loss: 0.1761 - val_accuracy: 0.9504\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2361 - accuracy: 0.9346 - val_loss: 0.1697 - val_accuracy: 0.9473\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2256 - accuracy: 0.9363 - val_loss: 0.1596 - val_accuracy: 0.9606\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2223 - accuracy: 0.9396 - val_loss: 0.1500 - val_accuracy: 0.9623\n","Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3390 - accuracy: 0.8986 - val_loss: 0.1905 - val_accuracy: 0.9448\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2572 - accuracy: 0.9257 - val_loss: 0.1713 - val_accuracy: 0.9501\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2396 - accuracy: 0.9301 - val_loss: 0.1780 - val_accuracy: 0.9514\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2247 - accuracy: 0.9359 - val_loss: 0.1705 - val_accuracy: 0.9539\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2178 - accuracy: 0.9383 - val_loss: 0.1866 - val_accuracy: 0.9547\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: dec15993b1c8e9884d586bafbd774d5b</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9591333270072937</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 64</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.8245 - accuracy: 0.7749 - val_loss: 0.3880 - val_accuracy: 0.8995\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4057 - accuracy: 0.8857 - val_loss: 0.2958 - val_accuracy: 0.9194\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3342 - accuracy: 0.9042 - val_loss: 0.2535 - val_accuracy: 0.9296\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2931 - accuracy: 0.9161 - val_loss: 0.2269 - val_accuracy: 0.9364\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2645 - accuracy: 0.9234 - val_loss: 0.2048 - val_accuracy: 0.9416\n","Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.8469 - accuracy: 0.7683 - val_loss: 0.3846 - val_accuracy: 0.9023\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4038 - accuracy: 0.8867 - val_loss: 0.2950 - val_accuracy: 0.9189\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3326 - accuracy: 0.9059 - val_loss: 0.2549 - val_accuracy: 0.9273\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2955 - accuracy: 0.9162 - val_loss: 0.2318 - val_accuracy: 0.9339\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2674 - accuracy: 0.9245 - val_loss: 0.2106 - val_accuracy: 0.9399\n","Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.8632 - accuracy: 0.7601 - val_loss: 0.3880 - val_accuracy: 0.8997\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4063 - accuracy: 0.8832 - val_loss: 0.2938 - val_accuracy: 0.9209\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3317 - accuracy: 0.9048 - val_loss: 0.2523 - val_accuracy: 0.9299\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2936 - accuracy: 0.9157 - val_loss: 0.2247 - val_accuracy: 0.9354\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2661 - accuracy: 0.9239 - val_loss: 0.2073 - val_accuracy: 0.9389\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: 08cbbc2c8bc2947f388ef909380c394e</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9401333332061768</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 64</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["INFO:tensorflow:Oracle triggered exit\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jfulyvP551HK","colab":{"base_uri":"https://localhost:8080/","height":903},"executionInfo":{"status":"ok","timestamp":1605513210732,"user_tz":-540,"elapsed":832,"user":{"displayName":"Sibaek Seong","photoUrl":"","userId":"03151236595317567383"}},"outputId":"b28a0e4a-9f88-4379-e621-fbd5e8c5293b"},"source":["tuner.results_summary()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Results in ./keras-tuner-trial/helloworld</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Showing 10 best trials</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: dff604ef9e5ea41e5fc504296d1075b6</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9775333404541016</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 160</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: 9df1b3d84ae227f1d0db03a4515e5d10</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9596333305040995</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 192</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: dec15993b1c8e9884d586bafbd774d5b</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9591333270072937</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 64</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: 587f6b517f3b69311174cbd8799825f8</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9586666822433472</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 96</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: 08cbbc2c8bc2947f388ef909380c394e</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9401333332061768</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 64</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"EAvN7h5Sfdxt"},"source":["# Review\n","* <a href=\"#p1\">Part 1</a>: 각각에 대해서 설명할 수 있는 지, 이해되지 않은 것들은 없는지 확인해 봅시다.\n","    - Activation Functions\n","    - Optimizer\n","    - Number of Layers\n","    - Number of Neurons\n","    - Batch Size\n","    - Dropout\n","    - Learning Rate\n","    - Number of Epochs\n","    - and many more\n","* <a href=\"#p2\">Part 2</a>: 실험 추적 프레임워크를 구현을 스스로 해볼 수 있는 지 점검합시다\n","    - Weights & Biases\n","    - Comet.ml\n","    - By Hand / GridSearch"]},{"cell_type":"markdown","metadata":{"id":"COUqF7gQfdxt"},"source":["## 읽어볼만한 자료\n","- [Grid Search Hyperparameters for Deep Learning](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)\n","- [Hyperparameters Optimization for Deep Learning Models](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/)\n","- [Dropout Regularization in Deep Learning](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/)\n","- [Weight Constraints in Deep Learning](https://machinelearningmastery.com/introduction-to-weight-constraints-to-reduce-generalization-error-in-deep-learning/)\n","- [Number of Layers and Nodes in a Neural Network](https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/)\n","- [Batch Normalization](https://shuuki4.wordpress.com/2016/01/13/batch-normalization-%EC%84%A4%EB%AA%85-%EB%B0%8F-%EA%B5%AC%ED%98%84/)\n","\n"]},{"cell_type":"code","metadata":{"id":"dqGaJv1ekA3W"},"source":[""],"execution_count":null,"outputs":[]}]}