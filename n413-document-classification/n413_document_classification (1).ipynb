{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "P41_NLP",
      "language": "python",
      "name": "p41_nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "n413-document-classification.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqbGgvLnsRMK"
      },
      "source": [
        "<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / NOTE 3*\n",
        "\n",
        "---\n",
        "\n",
        "# Deep Learning for sequence data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XRE8OltyEnE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYrI4-tdsRMY"
      },
      "source": [
        "# 🏆 학습 목표\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a> 자연어 예측방법에 대해서 이해하기\n",
        "  * Word2Vec - CBOW, Skip-gram\n",
        "  * NNLM - Neural Network Language Model\n",
        "  * RNNLM - Recurrent Neural Network Language Model\n",
        "\n",
        "- <a href=\"#p2\">Part 2: </a> 시퀀스 모델링에 사용되는 신경망에 대해서 배운다.\n",
        "  * 시퀀스 : 순서가 있는 데이터의 집합\n",
        "  * RNN 계열 (LSTM, GRU 포함)과는 다른 시퀀스 처리 방식인 Transformer에 대해서 알고 있다.\n",
        "  * Keras를 사용하여 텍스트 생성 문제에 LSTM 적용해본다.\n",
        "  * RNN을 실전문제에 사용해보았고, RNN도 기존 신경망과 다르지 않고 충분히 해결할 수 있다는 자신감을 갖는 것. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV2USpTMsRMZ"
      },
      "source": [
        "### Warm up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnvZpCRSsRMZ"
      },
      "source": [
        "예측기반의 방법이란 신경망 구조나 또는 다른 모델을 통하여 특정 문맥에서 어떤 단어가 나올지를 예측하면서 단어를 벡터로 만드는 방식입니다. 예측방법에는 Word2Vec, Neural Network Language Model(NNLM), \n",
        "Recurrent Neural Network Language Model(RNNLM) 등이 있습니다. <br>\n",
        " $\\space$ Word2Vec는 CBOW, Skip-gram 2가지 모델로 나눌 수 있는데, 이는 서로 반대의 개념이라고 생각할 수 있습니다. CBOW(Continuous Bag of Words)의 경우는 어떤 단어를 문맥 안의 주변 단어들을 통해서 예측하는 방법이고, 반대로 Skip-gram의 경우에는 어떤 단어를 가지고 특정 문맥 안의 주변 단어들을 예측하는 방법입니다. \n",
        "\n",
        "영상을 통해서 해당 내용을 좀 더 자세히 살펴봅시다.\n",
        "- [Word2Vec](https://www.youtube.com/watch?v=UqRCEmrv1gQ)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVsFWh_2vS7h"
      },
      "source": [
        "기존에 배웠던 카운트 기반 방법으로 만든 단어 벡터보다 단어 간의 유사도를 잘 측정한다. 또한 단어들의 복잡한 특징까지도 잘 잡아낸다. 이렇게 만들어진 단어 벡터는 서로에게 유의미한 관계를 측정할 수 있다는 점이 놀랍다. \n",
        "- 왕(king) - 남자(man) + 여자(woman) = 여왕(queen)\n",
        "- 아빠(father) - 남자(man) + 여자(woman) = 엄마(mother)\n",
        "\n",
        "위와같은 법칙이 성립하도록 만드는 것이다\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/3010/1*OEmWDt4eztOcm5pr2QbxfA.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaIJe2CmwPuu"
      },
      "source": [
        "---\n",
        "- [RNN, LSTM 원리 소개 영상](https://youtu.be/SoNtAjxA3Jo?t=116)\n",
        "  * Vanishing Gradient 개념을 이해하고, 그것을 극복하기 위해서 한 것은?\n",
        "  * Gate의 개수와 범위는?\n",
        "- [GRU 소개영상](https://youtu.be/cs3tSnAsyRs?t=2569)\n",
        "  * Gate의 수를 줄일 수 있지 않을까? LSTM과의 차이는?\n",
        "  * Reset/Update Gate - Vanishing Gradient 를 해결한 방법이 어떻게 달라졌나?\n",
        "- 신호처리(음성, 사진, 동영상)의 개념 [DSP강의](http://www.kocw.net/home/search/kemView.do?kemId=334394&ar=relateCourse)(이런 게 있다... 강의를 듣진 마세요. 나중에 관련 업무를 하게되고 충분한 시간이 있을 때면 봐도 좋습니다)\n",
        "  * 분석(analysis) - 레이더(RADAR, RAdio Detection And Ranging), 소나(SONAR, SOund NAvigation Ranging), \n",
        "  * 처리(processing)\n",
        "  * 합성(synthesis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86CIimEi0C_e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by9oie2bzm_t"
      },
      "source": [
        "#자연어 예측방법에 대해서 이해하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biVHgxXLw41z"
      },
      "source": [
        "## 문서를 벡터로 만들기 위해 단어 임베딩을 사용해 봅시다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJzjQzJAzm_t"
      },
      "source": [
        "지난 시간에 배웠던 BoW와 달리 Word2Vec과 같은 단어 임베딩 방법은 문맥(context)정보를 보존하는 특징이 있습니다. \n",
        "\n",
        "BoW는 단어의 존재 여부와 그 빈도 정보를 중요하게 다루는 대신 단어의 순서 정보를 무시하여 단어 주변 문맥정보를 잃어버린다는 단점이 있습니다.\n",
        "\n",
        "이와 달리 단어 임베딩 방법중 하나인 Word2Vec은 문장에서 인접한 단어들의 정보를 중요시 하여 벡터화할 때 문맥 정보를 보존합니다. 그래서 의미적 또는 구조적으로 비슷한 사용법을 가진 단어들을 알 수 있게 됩니다.\n",
        "\n",
        "#### *임베딩이란?*\n",
        "자연어를 컴퓨터가 이해할 수 있는 수의 나열인 벡터 형태로 바꾸는 과정 또는 결과를 의미합니다. 앞서 살펴본 BoW 방법들은 문서를 벡터화 한 것이라 볼 수 있습니다. \n",
        "\n",
        "### Word2Vec 이란?\n",
        "Word2Vec은 구글 연구팀이 발표한(Mikolov et al., 2013) 기법으로 가장 널리 쓰이는 단어 임베딩 모델 중 한 가지 입니다. 단어 임베딩 방법으로는 skip-gram과 CBOW 두 모델이 제안되었습니다. \n",
        "\n",
        "#### 분포가설(Distributional Hypothesis)\n",
        "\n",
        "Word2Vec이 어떻게 문맥 정보를 보존하는지 이해하려면 분포가설([Distributional Hypothesis](https://en.wikipedia.org/wiki/Distributional_semantics))을 알아야 합니다. \n",
        "분포가설은 비슷한 문맥에서 등장하는 단어들은 비슷한 의미를 지닌다는 것 입니다. 여기서 분포(distribution)란 특정 윈도우(window) 범위 안에 동시에 등장하는 이웃 단어나 문맥의 집합을 말합니다. \n",
        "\n",
        "예를 들어 두 문장\n",
        "\n",
        "- I found **good** stores.\n",
        "- I found **bad** stores.\n",
        "\n",
        "에서 **good**과 **bad**은 주변에 분포한 문맥 단어들이 매우 유사함으로 추축하건데 비슷한 의미를 지닐 것이다 라고 가정하는 것 입니다.\n",
        "\n",
        "> \"You shall know a word by the company it keeps\" - John Firth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1mrs0MWzm_t"
      },
      "source": [
        "### Word2Vec을 구현하는 방법으로 Skip-Gram을 살펴보겠습니다\n",
        "\n",
        "CBOW, Skip-Gram은 Word2Vec을 구현하는 두 가지 방법입니다.\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/304163783/figure/fig11/AS:668313973698561@1536349876279/Neural-Network-Architecture-for-CBoW-and-Skip-Gram-Model.ppm\"/>\n",
        "\n",
        "여기서는 Skip-Gram만 살펴 보겠습니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkk1lF9Lzm_t"
      },
      "source": [
        "<img src=\"http://mccormickml.com/assets/word2vec/skip_gram_net_arch.png\" width=\"800\" />\n",
        "\n",
        "위 그림은 Skip-Gram 신경망 모식도 입니다.([Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/))\n",
        "\n",
        "입력으로 원핫인코딩된 단어벡터가 들어오고 출력부분에서는 입력단어와 다른 모든 단어들이 문맥 단어일 확률값을 계산하게 됩니다.\n",
        "\n",
        "신경망 학습을 위해서는 학습데이터를 구성하는 방법이 중요한데,\n",
        "\n",
        "Skip-Gram 모델은 만들어진 학습데이터에서 타겟단어를 입력받아 주변 단어를 예측하는 과정에서 학습이 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vPot7zlzm_u"
      },
      "source": [
        "\n",
        "예를 들어서 **\"The tortoise jumped into the lake\"** 라는 문장이 있고 윈도우 크기가 2인 경우 다음과 같이 skip-Gram을 학습하기 위한 데이터 쌍을 구축할 수 있습니다.\n",
        "\n",
        "* 타겟: **The**, 주변 문맥단어: tortoise, jumped\n",
        "    * 학습 샘플: (the, tortoise), (the, jumped)\n",
        "* 타겟: **tortoise**, 주변 문맥단어: tortoise, jumped\n",
        "    * 학습 샘플: (tortoise, the), (tortoise, jumped), (tortoise, into)\n",
        "* 타겟: **jumped**, 주변 문맥단어: tortoise, jumped\n",
        "    * 학습 샘플: (jumped, the), (jumped, tortoise), (jumped, into), (jumped, the)\n",
        "* 타겟: **into**, 주변 문맥단어: tortoise, jumped\n",
        "    * 학습 샘플: (into, tortoise), (into, jumped), (into, the), (into, lake)\n",
        "                    ...\n",
        "\n",
        "이런 방법으로 학습 데이터를 만들면 다음과 같은 데이터쌍이 만들어 집니다. 타겟단어를 입력으로, 문맥단어를 레이블로 하여 classification 학습을 진행한다고 생각하시면 됩니다. 전체 코퍼스에서 단어별로 슬라이딩하여 가능한 학습데이터를 모두 생성하고 신경망을 학습합니다.\n",
        "\n",
        "|타겟단어|문맥단어|\n",
        "|---------|---------|\n",
        "|the|tortoise|\n",
        "|the|jumped|\n",
        "|tortoise|the|\n",
        "|tortoise|jumped|\n",
        "|tortoise|into|\n",
        "|jumped|the|\n",
        "|jumped|tortoise|\n",
        "|jumped|into|\n",
        "|jumped|the|\n",
        "|into|tortoise|\n",
        "|into|jumped|\n",
        "|into|the|\n",
        "|into|lake|\n",
        "|...|...|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ_CbX_jzm_u"
      },
      "source": [
        "학습이 다 끝난 후 은닉층의 가중치가 임베딩벡터의 차원이 됩니다. 은닉층의 노드 수를 조절하여 임베딩벡터의 차원을 조절할 수 있겠지요.\n",
        "<img src=\"https://i.imgur.com/1ETMljf.png\" width=\"600\" />\n",
        "\n",
        "학습과정에서 효율을 높이기 위해 사용하는 기법들이 있지만 지금은 아직 신경망을 배우기 전이기 때문에 너무 깊게 들어가지 않겠습니다.\n",
        "\n",
        "결과적으로 skip-gram 모델을 통해 결과로 단어 임베딩 벡터들을 얻게되어 단어, 문장들 간의 관련도 계산, 문서 분류같은 작업에 사용될 수 있습니다.\n",
        "\n",
        "CountVectorizer, TF-IDF을 사용할 때 문맥정보를 보기위해 할 수 있는 최선의 방법은 bi-gram, tri-grams 같은 n-gram을 사용하는 것이었습니다. 하지만 skip-grams은 그 이상을 넘어 보다 강력한 문맥 정보를 제공해 줄 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE4WJRCvzm_u"
      },
      "source": [
        "#### CBOW(Continuous Bag of Words)\n",
        "\n",
        "Word2Vec을 구현하는 방법 중 CBOW는 skip-gram과 반대로 주변에 있는 문맥단어들을 가지고 타겟 단어 하나를 맞추는 과정을 통해 학습이 이루어 집니다.\n",
        "예를 들어 입력이 (jumped, the, lake) 일 때 타겟 단어로 'into' 를 예측하며 학습을 합니다.  \n",
        "\n",
        "하지만 Skip-gram이 같은 코퍼스를 사용했을 때 더 많은 학습 데이터를 만들어 낼 수 있기 때문에 임베딩 결과의 품질이 CBOW 보다 좋은 것으로 알려져 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2GGXaIKzm_u"
      },
      "source": [
        "\n",
        "#### 그럼 임베딩 모델 학습은 어떻게 해야 할까요?\n",
        "Word2Vec을 학습시키기 위해서는 충분히 큰 코퍼스를 학습시켜야 한다는 것을 알 수 있습니다. 다행인 것은 이미 충분히 큰 코퍼스들로 학습된 단어 임베딩을 쉽게 찾아 사용할 수 있다는 것입니다. 여러분이 지금까지 사용해온 Spacy 라이브러리의 모델도 Word2Vec 와 유사한 방식으로 학습한 임베딩을 제공합니다. 무지막지하게 큰 [Common Crawl](https://en.wikipedia.org/wiki/Common_Crawl) 데이터를 학습에 사용해 만든 모델이기 때문에 영어의 경우 충분히 대표성을 가진 임베딩이 나올 수 있을 것이라 생각할 수 있겠습니다.\n",
        "\n",
        "이제 spacy를 통해 임베딩을 어떻게 사용하는지 살펴 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWIVbptuzm_u",
        "outputId": "a57dd60c-ca56-49b3-cc7d-2a2014f96f53"
      },
      "source": [
        "tokens = nlp(\"Dogs and cats school gagasdf\")\n",
        "\n",
        "# vector_norm: 벡터의 크기\n",
        "for token in tokens:\n",
        "    print(token.text, token.has_vector, token.vector_norm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dogs True 7.193099\n",
            "and True 4.6577983\n",
            "cats True 6.933004\n",
            "school True 6.7380905\n",
            "gagasdf False 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2TAPfx5zm_u"
      },
      "source": [
        "입력한 문장에 대한 임베딩 벡터를 얻습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIoEr--Vzm_u",
        "outputId": "29e2388d-2b94-4261-9367-97b806bb1d06"
      },
      "source": [
        "vects = tokens.vector\n",
        "print(vects)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.79408014e-01  1.26198798e-01 -1.11785397e-01 -2.83820003e-01\n",
            " -2.62799971e-02  5.58035970e-02 -1.45570010e-01 -5.27487993e-02\n",
            "  1.69332191e-01  1.93045998e+00 -2.79807180e-01  1.38399795e-01\n",
            " -1.85558006e-01  5.02085984e-02 -1.40728995e-01  9.67558026e-02\n",
            "  2.06080005e-01  8.19686055e-01 -1.57560199e-01 -6.11754060e-02\n",
            " -1.73499614e-01 -1.09055400e-01 -4.25813980e-02 -2.84800589e-01\n",
            "  1.65506005e-01 -9.49792042e-02 -2.45875999e-01 -1.76592007e-01\n",
            "  1.02721252e-01 -1.18426010e-01 -9.64230075e-02  2.92337183e-02\n",
            " -8.17720070e-02 -2.63900049e-02  2.31444001e-01  9.93599277e-03\n",
            "  1.33631989e-01 -2.89353997e-01  8.05701874e-03  2.12559611e-01\n",
            "  1.11464588e-02  1.04168795e-01  6.81307912e-03 -1.94971208e-02\n",
            "  7.46979937e-02 -9.89580080e-02 -2.04918385e-01  1.74181998e-01\n",
            "  1.38363212e-01 -1.74419403e-01 -8.65179971e-02 -2.17613988e-02\n",
            "  1.88542008e-02  4.70872000e-02 -9.22998041e-02  2.23565191e-01\n",
            " -3.33181992e-02  6.36455938e-02 -2.20621794e-01  3.23160827e-01\n",
            "  7.06618130e-02 -1.33299991e-01  7.05728009e-02  5.07225990e-02\n",
            "  1.85075998e-02 -1.73200995e-01  1.46570206e-01  2.28904009e-01\n",
            "  1.15869999e-01  1.45907611e-01 -7.41464198e-02 -2.93245306e-03\n",
            "  1.76927999e-01 -1.12230204e-01  2.02573389e-01  3.83340009e-02\n",
            "  4.02077772e-02  3.21223959e-02  2.37526014e-01  2.03440199e-03\n",
            "  4.61397991e-02  1.76907986e-01 -1.65638000e-01  1.10619962e-02\n",
            " -1.38576003e-02 -2.04356030e-01  2.19403982e-01  2.58924007e-01\n",
            "  3.17174017e-01  2.84796022e-02 -2.06128061e-02  6.32442012e-02\n",
            "  1.92617387e-01 -1.55552402e-01  9.87199880e-03 -5.76351993e-02\n",
            "  1.22454248e-01 -1.15851797e-01  3.43279950e-02 -2.05176428e-01\n",
            "  1.57538012e-01  3.03530008e-01  1.66659970e-02 -5.13790026e-02\n",
            "  1.80297971e-01 -5.39748013e-01  2.14044809e-01 -8.67253989e-02\n",
            "  3.15148011e-02 -1.00457408e-01  1.08274005e-01  2.16653999e-02\n",
            "  1.42108604e-01 -4.26528037e-01 -6.20442033e-02 -6.88948408e-02\n",
            " -1.86819993e-02 -9.54598188e-04 -5.10616079e-02  2.23586001e-02\n",
            "  6.64183944e-02  1.26925990e-01  3.90487969e-01 -4.52394426e-01\n",
            " -4.82079992e-03  6.15017936e-02  2.62621999e-01 -3.26151960e-02\n",
            " -1.16785005e-01  3.10663991e-02  1.36915985e-02 -3.22481804e-02\n",
            " -1.79007590e-01  1.52172610e-01  2.93281972e-01 -3.51880044e-02\n",
            " -6.65543973e-02  8.87220055e-02  1.69600800e-01  1.53597400e-01\n",
            " -1.21144199e+00 -3.34477782e-01  2.03879997e-01  2.19875187e-01\n",
            "  1.89845204e-01  5.13368025e-02 -4.38288040e-02  9.24024060e-02\n",
            " -4.63436022e-02 -3.40633988e-02  9.41860117e-03  3.12891975e-02\n",
            " -6.10519946e-02  2.44600587e-02 -1.31334007e-01 -3.30240019e-02\n",
            " -9.23147947e-02  2.20420063e-02 -7.53320083e-02 -4.78557974e-01\n",
            "  1.62741989e-01 -8.43316093e-02 -7.46396035e-02 -2.92490005e-01\n",
            " -1.03690766e-01 -1.79798044e-02 -1.38816804e-01 -2.04536602e-01\n",
            "  3.32040004e-02  3.14394012e-02  2.03837991e-01  1.79215401e-01\n",
            "  1.75188005e-01 -4.60227951e-02 -5.63515946e-02  2.44379997e-01\n",
            " -2.07816407e-01  2.52512813e-01  1.02010593e-01  2.14170814e-01\n",
            "  7.75867999e-02 -1.33704007e-01 -2.19155401e-01  7.01961964e-02\n",
            " -2.02604815e-01 -5.36981598e-02 -1.69788003e-02  7.92500377e-03\n",
            "  5.94210029e-02 -2.57445991e-01 -1.15660593e-01 -2.66319998e-02\n",
            " -2.19249800e-01 -2.91447997e-01 -1.45527408e-01  3.56470019e-01\n",
            "  4.31900024e-02 -3.80075991e-01  3.97520006e-01 -6.94609955e-02\n",
            " -2.37546012e-01 -1.70287006e-02 -1.38436794e-01 -8.76650065e-02\n",
            "  2.73934782e-01  6.83466792e-02  2.27189988e-01 -5.07079959e-02\n",
            "  2.79985994e-01  5.14696017e-02 -2.67293990e-01  3.06694984e-01\n",
            " -1.55797794e-01  3.10354587e-02 -2.70036012e-01 -1.10019602e-01\n",
            "  6.86846003e-02  2.56755412e-01  1.59152038e-02  1.60861403e-01\n",
            " -3.22834030e-02  4.09860015e-02 -1.26569003e-01 -2.85745561e-01\n",
            " -2.96884000e-01  1.23613931e-01 -1.84703991e-01  3.35820019e-01\n",
            "  1.30998015e-01  8.82645994e-02 -2.94773996e-01 -9.63780005e-03\n",
            " -3.65859978e-02 -1.06170796e-01  2.74767399e-01  8.46758038e-02\n",
            "  1.10649601e-01 -1.13876007e-01  2.25924999e-01 -1.33907586e-01\n",
            " -4.24908698e-01 -5.14791980e-02 -2.08838016e-01 -7.06599932e-03\n",
            " -5.62896021e-02  3.76334004e-02 -3.46244395e-01  7.22953975e-02\n",
            " -2.02894002e-01 -4.09839908e-03 -3.69865410e-02  1.78002000e-01\n",
            " -1.16780594e-01  1.06330000e-01  1.23366609e-01  5.25748022e-02\n",
            " -1.09817997e-01 -1.42497614e-01 -1.29482403e-01 -1.83818005e-02\n",
            "  1.13296404e-01 -1.46337777e-01 -2.18502015e-01 -8.41268003e-02\n",
            "  2.72519998e-02  1.13252386e-01 -2.62620002e-01 -1.49156868e-01\n",
            " -4.07759566e-03  6.72063977e-02 -2.86052585e-01  2.65085995e-01\n",
            " -1.78678796e-01 -8.74760188e-03 -7.27500161e-03 -1.13103958e-02\n",
            "  4.27139997e-02  2.53716201e-01 -1.54976606e-01  4.04243991e-02\n",
            "  4.32590023e-02  1.28732011e-01 -1.57697603e-01 -1.35332197e-01\n",
            "  1.16097197e-01  2.14821100e-01  3.52397978e-01 -2.47403592e-01\n",
            " -7.57020712e-03 -7.91880041e-02 -1.05859995e-01 -3.32543790e-01\n",
            "  1.85099952e-02  1.60729602e-01 -1.59693107e-01  3.80479395e-01\n",
            "  6.79079965e-02 -1.03840396e-01  1.02859996e-01 -9.37639922e-02]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz7KEIRTzm_v",
        "outputId": "7c2870bb-c477-4916-8a8f-5e7f07459d7c"
      },
      "source": [
        "# 벡터의 차원을 보겠습니다\n",
        "len(vects)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxk_Lof6zm_v",
        "outputId": "bb82b2a1-e4b2-4257-8d08-ee4bf0b18227"
      },
      "source": [
        "# 두 문서를 만들어 코사인 유사도를 측정해 보겠습니다\n",
        "doc1 = nlp(\"I found a wonderful restaurant\")\n",
        "doc2 = nlp(\"the food is delicious\")\n",
        "\n",
        "similarity = doc1.similarity(doc2)\n",
        "print(similarity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.792971253536227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YikT-Qsizm_v",
        "outputId": "e870a3c7-9099-4653-8d22-254535f2e5ad"
      },
      "source": [
        "doc3 = nlp(\"The restaurant we found yesterday is wonderful\")\n",
        "\n",
        "print(doc1.similarity(doc3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9173849797280267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME-aYDw4zm_v",
        "outputId": "d99fab42-933a-425a-9772-3d4e24d30715"
      },
      "source": [
        "car = nlp('car')\n",
        "bus = nlp('bus')\n",
        "human = nlp('human')\n",
        "monkey = nlp('monkey')\n",
        "lion = nlp('lion')\n",
        "gorilla = nlp('gorilla')\n",
        "avengers = nlp('avengers')\n",
        "marvel = nlp('marvel')\n",
        "\n",
        "print('car vs bus : ', car.similarity(bus))\n",
        "print('bus vs human : ', bus.similarity(human))\n",
        "print('human vs monkey : ', human.similarity(monkey))\n",
        "print('human vs lion : ', human.similarity(lion))\n",
        "print('monkey vs gorilla : ', monkey.similarity(gorilla))\n",
        "print('avengers vs marvel : ', avengers.similarity(marvel))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "car vs bus :  0.4816960149829203\n",
            "bus vs human :  0.12412277316164501\n",
            "human vs monkey :  0.39899946231157096\n",
            "human vs lion :  0.27611871750909667\n",
            "monkey vs gorilla :  0.6525881793034227\n",
            "avengers vs marvel :  0.5988409089010447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G013Wj9Szm_v"
      },
      "source": [
        "### PCA를 사용한 벡터 시각화\n",
        "300 차원인 벡터들은 시각화 하기 어렵기 때문에 PCA를 사용해 2차원으로 변환해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7TbDo6Vzm_w",
        "outputId": "94d0cbd9-5cd0-4a93-c017-d4631bb4f528"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def get_word_vectors(words):\n",
        "    # 단어 벡터로 변환합니다\n",
        "    return [nlp(word).vector for word in words]\n",
        "\n",
        "words = ['car', 'truck', 'suv', 'bus', 'human', 'man', 'woman', 'monkey', 'fish' , 'shark', 'lion', 'tiger', 'avengers', 'marvel', 'thor', 'comics', 'superhero']\n",
        "\n",
        "# PCA 모델의 차원을 설정하여 \n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Fit & Transform\n",
        "word_vect_2d = pca.fit_transform(get_word_vectors(words))\n",
        "\n",
        "# 각 벡터가 300 차원에서 2차원으로 줄어 든 것을 확인 할 수 있습니다\n",
        "word_vect_2d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.66200993, -3.32131749],\n",
              "       [-3.546578  , -2.85085021],\n",
              "       [-1.79310422, -3.71355107],\n",
              "       [-3.06282644, -2.17552236],\n",
              "       [-0.32817602,  1.3725565 ],\n",
              "       [-1.07378983,  0.56357398],\n",
              "       [-1.38479131,  0.34247838],\n",
              "       [-0.32481679,  2.04812646],\n",
              "       [-1.69068704,  3.8972493 ],\n",
              "       [-0.79176752,  3.43002251],\n",
              "       [-0.28481803,  2.75749512],\n",
              "       [-0.77280682,  3.10963932],\n",
              "       [ 4.97271183, -1.21201458],\n",
              "       [ 2.90881958, -0.6911009 ],\n",
              "       [ 3.43790293, -1.18524999],\n",
              "       [ 3.76755523, -1.36028237],\n",
              "       [ 3.62918236, -1.0112526 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj6SRS1Pzm_w",
        "outputId": "9c097e9b-c7a0-4139-8303-ec817c31df01"
      },
      "source": [
        "# 결과가 잘 보이도록 크기를 설정합니다\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "# 단어벡터를 그립니다\n",
        "plt.scatter(word_vect_2d[:,0], word_vect_2d[:,1])\n",
        "\n",
        "# 점 옆에 단어를 표시합니다\n",
        "for word, coord in zip(words, word_vect_2d):\n",
        "    x, y = coord\n",
        "    plt.text(x, y, word, size= 15)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3b47N6mzm_w",
        "outputId": "d257e2b1-1317-408d-f464-6a4ed133846b"
      },
      "source": [
        "# 벡터 연산을 통해 단어간의 관계를 추론할 수 있습니다\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "king = nlp(\"king\").vector\n",
        "queen = nlp(\"queen\").vector\n",
        "man = nlp(\"man\").vector\n",
        "woman = nlp(\"woman\").vector\n",
        "\n",
        "# 단어벡터가 의미를 가진다면 다음과 같은 연산을 통해 result는 queen과 비슷한 뜻이 되겠지요?\n",
        "result = king - man + woman\n",
        "\n",
        "print(\"similarity between queen and (king - man + woman) : \", 1 - cosine(queen, result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "similarity between queen and (king - man + woman) :  0.7880843877792358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaD2wI5Fzm_w"
      },
      "source": [
        "### 문서에서 벡터화 하여 KNN으로 검색해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDISNXc4zm_w"
      },
      "source": [
        "Spacy를 사용해 문서를 임베딩 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0c8IwrFzm_w"
      },
      "source": [
        "X = [nlp(str(d)).vector for d in data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmd4YJitzm_x",
        "outputId": "c3d16d64-abaa-456b-d638-1b8ed6fba26d"
      },
      "source": [
        "pd.DataFrame(X).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(401, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3wQZmRszm_x"
      },
      "source": [
        "단어 queen 과 가장 유사한 단어를 찾아 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7VFnEk3zm_x"
      },
      "source": [
        "import numpy as np\n",
        "most_similar= nlp.vocab.vectors.most_similar(np.array([queen]), n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkn5Ez4Nzm_x",
        "outputId": "fa3e63f1-9dc7-498e-8b7a-f72d6c1fb1ea"
      },
      "source": [
        "# return tuple: (keys, best_rows, scores)\n",
        "most_similar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 5247273317732208552,  4176741725343376093, 10168488388102651113,\n",
              "         15897987006174384596,  6350019949300993244,  6861946004817705414,\n",
              "         13176088972490086564,  7102492827649024548,  7464393751932445219,\n",
              "         14826469074451677028]], dtype=uint64),\n",
              " array([[ 59856,   6026,   5310,  11962,  16454, 172357, 391588,  27270,\n",
              "           3150,   2183]], dtype=int32),\n",
              " array([[1.    , 1.    , 1.    , 0.7322, 0.7322, 0.7322, 0.7253, 0.7253,\n",
              "         0.7253, 0.7253]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PPhPcLnzm_x",
        "outputId": "e7555377-827e-4701-a602-d2fd62ebd945"
      },
      "source": [
        "most_similar[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5247273317732208552,  4176741725343376093, 10168488388102651113,\n",
              "       15897987006174384596,  6350019949300993244,  6861946004817705414,\n",
              "       13176088972490086564,  7102492827649024548,  7464393751932445219,\n",
              "       14826469074451677028], dtype=uint64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIe5U3i_zm_x",
        "outputId": "9c715d94-eda3-4489-ff92-5970336bc374"
      },
      "source": [
        "for key in most_similar[0][0]:\n",
        "    print(nlp.vocab[key].text,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QUEEN\n",
            "queen\n",
            "Queen\n",
            "queens\n",
            "Queens\n",
            "QUEENS\n",
            "KIng\n",
            "KING\n",
            "king\n",
            "King\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mofOq3YFzm_x"
      },
      "source": [
        "문서 임베딩 벡터로 NN 모델을 학습합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0rhepyczm_y",
        "outputId": "a03c1b25-8d90-4d70-82ee-82f7bb45a9cb"
      },
      "source": [
        "nn_spacy = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "nn_spacy.fit(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qguG8vlSzm_y"
      },
      "source": [
        "Tfidf 벡터로 찾은 0번째 문서와 가장 유사한 문서 5개를 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8RKZX3rzm_y",
        "outputId": "cf4eb316-9218-41ed-84e6-0680e7e413a1"
      },
      "source": [
        "nn.kneighbors([dtm.iloc[0].values])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.        , 1.10314436, 1.12437104, 1.15991512]]),\n",
              " array([[  0,  62,  92, 297, 300]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h27I70iizm_y"
      },
      "source": [
        "Spacy 임베딩 모델로 찾아 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyJkr41Ozm_y",
        "outputId": "f90b0d71-9fee-4a66-a4bc-361e9e25ccfa"
      },
      "source": [
        "nn_spacy.kneighbors([X[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.        , 0.49605979, 0.50772691, 0.50784463]]),\n",
              " array([[62,  0, 92, 83, 52]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_I7YIPezm_y"
      },
      "source": [
        "문서62는 문서0과 동일하고 그 외, 문서 92를 가장 가깝다고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOm9h2Xczm_z",
        "outputId": "969c78e3-ebe8-4dbd-ca96-1707ca04ff53"
      },
      "source": [
        "print(data[0][:150],'\\n')\n",
        "print(data[92][:150])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\"Mobiles rack up 20 years of use\\n\\nMobile phones in the UK are celebrating their 20th anniversary this weekend.\\n\\nBritain's first mobile phone call was m\" \n",
            "\n",
            "b'Finding new homes for old phones\\n\\nRe-using old mobile phones is not just good for the environment, it has social benefits too.\\n\\nResearch has found tha'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfrGRJ9jzm_z",
        "outputId": "b960d7bd-fe05-449b-f2ef-31b82983dc99"
      },
      "source": [
        "# spacy\n",
        "print(data[83][:150])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Looks and music to drive mobiles\\n\\nMobile phones are still enjoying a boom time in sales, according to research from technology analysts Gartner.\\n\\nMore'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3p_sIqhzm_z",
        "outputId": "e513fa82-339e-426e-ec92-ec40004b9400"
      },
      "source": [
        "# tfidf\n",
        "print(data[297][:150])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\"'Friends fear' with lost mobiles\\n\\nPeople are becoming so dependent on their mobile phones that one in three are concerned that losing their phone woul\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvcIzQyjzm_z"
      },
      "source": [
        "지금까지 자연어를 벡터로 표현하는 방법들에 대해 살펴보았습니다. Bag-of-Words 모델 중 단어의 출현 빈도를 사용해 텍스트 문서를 벡터로 변환하는 CounterVectorizer를 사용해 보았고, 문서별 단어의 빈도를 계산해 가중치를 적용한 TfidfVectorizer를 사용해 보았습니다.\n",
        "\n",
        "이렇게 변환된 벡터는 코사인 유사도와 같은 방법을 통해 문서들 간 유사성을 수치로 나타낼 수 있었습니다. 문서들이 많을 때 코사인 유사도를 다 적용해서 가장 가까운 문서를 찾는 방법은 효율적이지 않습니다. 그래서 K-NN과 같은 트리 기반 알고리즘을 사용해 가장 가까운 K개의 문서를 빠르게 검색할 수 있었습니다.\n",
        "\n",
        "BoW는 단어의 존재와 빈도를 중요시 여기는 대신 단어들의 순서정보를 무시하여 주변 문맥 정보가 없어지는 단점이 있었습니다. Word2Vec과 같은 담어 임베딩 방법은 벡터 생성 과정 중에 문맥 정보를 보존하여 유사한 의미를 가진 단어나 문장은 는 유사도가 큰 벡터가 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za4R7MaesRMZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTiSKYt5sRMa"
      },
      "source": [
        "여러분은 이미 머신러닝을 이용해 분류기를 학습시킬 수 있습니다. 그리고 텍스트 문서에서 어떻게 특성들을 추출하는지 배웠습니다. 이제 텍스트 문서를 분류하는 모델을 만들 차례 입니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1MMsFrssRMa"
      },
      "source": [
        "## 텍스트에서 특성들을 추출하고 문서 분류기를 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzrqZrDZsRMa"
      },
      "source": [
        "Sklearn 파이프라인을 사용하면 머신러닝 프로세스에 사용되는 여러 컴포넌트들을 쉽게 연결할 수 있었습니다.\n",
        "\n",
        "이번에는 파이프라인을 이용해 코퍼스 입력, 차원 축소, 학습 프로세스를 진행해 보겠습니다.\n",
        "\n",
        "벡터화 과정중에 n-gram 범위, 최대 토큰의 수 같은 하이퍼파라미터들을 수정해 가며 실험을 해 보아야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWHQ3Nu9sRMa"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBI6ri-rsRMb"
      },
      "source": [
        "20개 뉴스그룹으로 분류된 18,000개의 뉴스그룹 문서 데이터셋 입니다.\n",
        "- [20newsgroups](https://scikit-learn.org/stable/datasets/index.html#the-20-newsgroups-text-dataset)\n",
        "- 전자와 정치에 관한 두 개의 다른 카테고리 뉴스를 가져오겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEjMkWtSsRMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d5976c-8a25-4b05-b905-8850a2d9cd7b"
      },
      "source": [
        "categories = ['sci.electronics',\n",
        "              'talk.politics.misc']\n",
        "\n",
        "ng_train = fetch_20newsgroups(subset='train'\n",
        "                             , remove=('headers', 'footers', 'quotes')\n",
        "                             , categories=categories\n",
        "                             )\n",
        "\n",
        "ng_test = fetch_20newsgroups(subset='test'\n",
        "                             , remove=('headers', 'footers', 'quotes')\n",
        "                             , categories=categories\n",
        "                             )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR9OEW6zsRMo"
      },
      "source": [
        "## Spacy 단어 임베딩을 사용합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkTWpYU0sRMo"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2_r88G2sRMp"
      },
      "source": [
        "doc = nlp(\"The tortoise jumped into the lake\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgN3zdP7sRMp"
      },
      "source": [
        "Spacy는 기본적으로 300차원으로 임베딩 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qq8woicsRMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3926098-0271-4e32-fc45-907f424a8cf1"
      },
      "source": [
        "len(doc.vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G87Wt29ysRMp"
      },
      "source": [
        "def get_word_vectors(docs):\n",
        "    return [nlp(doc).vector for doc in docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slM9zTCQsRMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3800f45-7d0c-43be-8c7a-ceec462c6cc2"
      },
      "source": [
        "%%time\n",
        "X_spacy = get_word_vectors(ng_train.data)\n",
        "\n",
        "len(X_spacy) == len(ng_train.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 45.2 s, sys: 1.41 s, total: 46.6 s\n",
            "Wall time: 46.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0ih4d8rsRMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed0b3df4-273d-4e91-f195-6e63ac4460e8"
      },
      "source": [
        "%%time\n",
        "X_test_spacy = get_word_vectors(ng_test.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 27.1 s, sys: 884 ms, total: 28 s\n",
            "Wall time: 28.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRI8Dd6ssRMp"
      },
      "source": [
        "랜덤포레스트로 학습해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glk-XdKHsRMq"
      },
      "source": [
        "rfc.fit(X_spacy, ng_train.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QofFi3RosRMq"
      },
      "source": [
        "y_test_spacy = rfc.predict(X_test_spacy)\n",
        "accuracy_score(ng_test.target, y_test_spacy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2h6lOEWsRMq"
      },
      "source": [
        "#### MLP(Multi-layer perceptron classifier)를 간단히 사용해보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMZjPbIMsRMq"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(solver='lbfgs'\n",
        "                   , alpha=1e-5\n",
        "                   , hidden_layer_sizes=(16,2)\n",
        "                   , random_state=2\n",
        "                   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRBUP4EFsRMq"
      },
      "source": [
        "clf.fit(X_spacy, ng_train.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "010opTQUsRMq"
      },
      "source": [
        "clf.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAV_KM0WsRMq"
      },
      "source": [
        "y_test = clf.predict(X_test_spacy)\n",
        "accuracy_score(ng_test.target, y_test_spacy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoC3ScQR0_gS"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYmzbqqbwx8y"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKdA-PG8wwZF"
      },
      "source": [
        "이전까지 신경망의 개념에서와 CNN에서의 전체적은 흐름은 비슷하였습니다. 흐름이 한 방향으로만 흐르는 피드포워드(Feed Forward, FF)인 신경망들이었습니다. 물론 신경망을 학습할 때에는 역방향으로 움직이는 역전파에 대해서 배웠지만, 이것은 학습하는 과정이었기 때문에 신경망을 실제로 사용할 때에는 순방향으로만 사용하였습니다. 입력 신호가 은닉층으로 전달되고, 또 다음 층으로 전달하고 이렇게 순차적으로 전달해왔습니다.  이렇게 FF는 구성이 단순하여 이해하기 쉽지만, 큰 단점이 하나 있습니다. 바로 시계열(순서의 패턴에 의미가 있는) 데이터를 다루지 못합니다. 기존에 우리가 다뤘던 네트워크의 구조가 시계열 형태의 패턴을 잡아내지 못하기 때문입니다. 그래서 오늘은 시계열의 데이터 성질(패턴)을 잡아낼 수 있는 순환신경망(RNN)에 대해서 배워보겠습니다.\n",
        "\n",
        "시계열 데이터, 다른 말로 `시퀀스`는 열거 된 데이터입니다. 우리 일상에서는 `주문` 등의 반복적인 작업들이 이에 해당됩니다. Python 리스트(List)가 시계열 데이터의 좋은 예라고 할 수 있습니다. 두 개의 리스트 `[1, 2, 2, -1]`은 `[1, 2, -1, 2]`는 서로 다르다는 것입니다. 내용의 집합은 동일하지만, 순서가 다르면 다른 데이터가 될 수 있습니다. 이렇게 우리가 사용하는 데이터 구조 (예 : NumPy 배열)는 종종 이런 기본구조를 기반으로 구축되어 있죠.\n",
        "\n",
        "일상생활에서 대표적인 예는 바로 우리의 '말'이죠. 말의 순서가 중요하죠. 문법이 그러한 법칙을 담고 있습니다. 이렇게 시계열 데이터는 순서뿐만 아니라 \"시간\" 축이라는 마커(표시)가 있는 데이터입니다. 날짜, 타임 스탬프, [Unix 시간](https://en.wikipedia.org/wiki/Unix_time) 등. 모든 시계열은 또한 시퀀스이며 일부 기술의 경우 항목이 \"얼마나 멀리 떨어져 있는지\"를 고려하기도 하고, 단순히 순서만 고려할 수 있습니다 (특히 일정한 간격으로 수집 된 데이터가 특히 일관된 경우 중요하지 않을 수 있음). 오늘 배울 기본적인 RNN의 경우는 `얼마나 멀리 떨어져 있는가`보다 `순서`가 더 중요할 수 있습니다. RNN은 먼 데이터를 기억조차 하지 못하기 때문이죠. 기본적인 개념을 배우고 나면, 꽤 먼 거리에 있는 데이터를 배울 수 있는 LSTM에 대해서도 배워볼 것이고, 시계열을 다루지만 RNN을 사용하지 않는 Attention Network에 대해서도 간단하게 배워볼 것입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQYByaiPLilF"
      },
      "source": [
        "# 확률과 언어모델 Review\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_K8B0BRLqkG"
      },
      "source": [
        "## Word2Vec\n",
        "\n",
        "단어를 Vector공간으로 변환시키는 방법이라고 배웠고, 의미를 되새기기 위해서 그림을 참조하면 다음과 같습니다. \n",
        "<img src=\"https://miro.medium.com/max/3010/1*OEmWDt4eztOcm5pr2QbxfA.png\"/>\n",
        "\n",
        " 한편, 수식적으로 이라는 단어데이터를 생각해보겠습니다.<br>\n",
        "> $w_1, w_2, w_3, ..., w_l$ \n",
        "\n",
        "\n",
        " $w_l$을 `target`으로 예측해야한다고 했을 때, 기존의 맥락(context)과 이후 맥락을 반영해야겠습니다. <br>\n",
        "\n",
        " > $P(w_{l} | w_{l-1}, w_{l+1}$)\n",
        "\n",
        "CBOW는 위 식의 사후확률을 나타냅니다. 좌우를 고려하지 않고, 좌측(과거)만 고려하면, \n",
        "\n",
        " > $P(w_{l} | w_{l-1}, w_{l-2}$)\n",
        "\n",
        " 이렇게 식을 만들어볼 수 있습니다. 이런 모델의 형태는 머신러닝이나 통계학에서 마르코프체인(Markov Chain)으로 다뤄지기도 합니다. 위 수식은 level2 마르코프체인이 되는 것입니다. 과거 2개만을 고려했다는 의미이죠. 이렇게 파라미터의 조절을 통해서 기존 머신러닝에서 다뤘던 내용들을 Word2Vec 충분히 커버할 수 있습니다. 이후 단어와 과거로 단어로부터 몇개씩 고려할 것인지도 하나의 하이퍼파라미터로 조절하는 것이죠. 이 변수를 과거를 $k$, 이후를 $j$라고 한다면, $k=2, j=0$인 경우를 다룬 것이고, $k=3, j=1$이라면 식은 다름과 같이 변경될 수 있는 것입니다.\n",
        "\n",
        "  > $P(w_{l} | w_{l-1}, w_{l-2}, w_{l-3}, w_{l+1}$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM_rkqAFcXT_"
      },
      "source": [
        "## 확률적 언어모델(Language Model)\n",
        "\n",
        "> $P(w_1, ..., w_m) = P(w_m|w_1, ..., w_{m-1})P(w_{m-1}|w_1, ..., w_{m-2})...P(w_2|w_1)P(w_1)$\n",
        "\n",
        "이렇게 최근에 나온 단어가 나오기까지의 사후확률은 위와같이 분해해서 쓸 수 있습니다. 이 확률은 동시에 연속적인 사건의 발생임으로 독립확률의 곱으로 동시확률을 나타냅니다. \n",
        "\n",
        "축약해서 하나의 기호로 쓰면 다음과 같습니다.\n",
        "> $\\prod _{t=1}^{m} P(w_t | w_1, ..., w_{t-1})$\n",
        "\n",
        "이렇게 모델링한 것을 기준으로 다음 단어를 예측하게 되는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "# 시퀀스를 위한 신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eej9tGivlBWG"
      },
      "source": [
        "## RNN\n",
        "\"전통적인\" 시계열 처리 방법은 많은 것(예, Markov Chains)들이 있지만 딥러닝 시대에 접어들면서 시퀀스 데이터에 대한 기술은 RNN으로 집중되었습니다. 기본적인 신경망에 재귀(recurrent)연결을 두면서 시간축 정보를 반영할 수 있도록 만든 구조입니다. 여기서 recurrent라는 단어는 라틴어에서 유래되었는데 '몇 번이나 반복해서 일어나는 일'이라는 뜻입니다. 우리말로는 '재발하다, 주직적으로 일어나다, 순환하다'는 의미로 번역될 수 있습니다.  따라서 오늘 배울 RNN은 무엇인가 순환하는 신경망이라는 것을 마음에 담고 시작해보겠습니다. \n",
        "\n",
        "시퀀스 데이터의 간단한 예시를 들어보겠습니다. `피보나치 수열`을 기억하십니까? 이전과 전전 단계의 합산으로 새로운 수열이 만들어지는 구조입니다. 앞서 언급된 2nd markov Chain도 이런 방식으로 $n-2$단계와 $n-1$단계로 $n$ 단계가 정해지는 예시를 들었는데 그 중에 둘의 합으로 표시하는 방법입니다. 이렇게 모델이 정해지면 다음으로 나올 무수히 많은 숫자들을 만들 수 있다는 이론에 근거합니다. \n",
        "\n",
        "> $F_n = F_{n-1} + F_{n-2}$\n",
        "\n",
        "수학공식의 경우 기본 케이스 $ F_0 = 1, F_1 = 1 $라는 최초 입력이 필요하며 나머지는 알고리즘에 의해서 생성됩니다. 그러나 우리가 신경망에서 다룰 것은 루프(loop)형태를 다루게 됩니다. 그림으로 설명하면 다음과 같습니다.\n",
        "\n",
        "\n",
        "![RNN, Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
        "\n",
        "화살표 왼쪽 그림에서 $h$ 라고 쓴 은닉층에 자기 자신의 입력으로 돌아가는 Edge $V$이 있습니다.이 루프는 지금 시점의 $t$의 출력을 위해서 $t-1$ 값이 $U$와 합쳐져 $h$에 다시 반영되는 것을 의미합니다. \n",
        "\n",
        "전체 네트워크가 왼쪽 그림처럼 표시되지만, 네트워크를 시점에 따라 이해하도록 펼쳐보면 오른쪽 그림처럼 주어진 $t-1$ 시점에서 $x_{t-1}$, $t$ 시점에서 $x_{t}$에서 그리고, $t+1$시점에서 $x_{t+1}$에서 어떻게 작동하는지 확인할 수 있습니다.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSl3CSWwj4vc"
      },
      "source": [
        "각 시각의 RNN 계층은 그 계층으로의 입력과 1개 전의 RNN 계층으로부터 출력을 받아들입니다. 이 두 데이터로 지금 시각의 출력을 다시 계산하게 됩니다. \n",
        "> $h_t = sigmoid(h_{t-1}W_h + x_tW_x + b)$\n",
        "\n",
        "와 같은 형태로 계산할 수 있습니다. 이렇게 간단한 수식으로 변화내보면 조금 더 이해하기가 쉽습니다.  가중치가 2개가 생긴 것이죠. 입력 x를 h로 변환하기 위한 $W_x$와 RNN의 은닉층의 출력을 다음 h로 전환해주는 $W_h$가 있는 것입니다. 신경망에서 bias도 있다는 것은 잊지 않으셨으리라 생각합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b_1Khd-lJrq"
      },
      "source": [
        "# 배웠던 RNN을 간단한 코드로 살펴보면 다음과 같습니다. \n",
        "import numpy as np\n",
        "\n",
        "class RNN:\n",
        "  def __init__(self, Wx, Wh, b):\n",
        "    self.params = [Wx, Wh, b]\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "    self.cache = None\n",
        "\n",
        "  def forward(self, x, h_prev):\n",
        "    Wx, Wh, b = self.params\n",
        "    t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
        "    h_next = np.sigmoid(t)\n",
        "\n",
        "    self.cache = (x, h_prev, h_next)\n",
        "    return h_next"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHxszBx1mCtK"
      },
      "source": [
        "개념을 설명할 때에는 복잡하고 어려워 보였지만, 코드로 구현하고 나면 사실 별 다른 게 없습니다. 쉽게 개념을 이해하고 넘어가시면 됩니다. RNN에서의 학습도 기존 신경망처럼 계산할 수 있는데, Backpropagation through time이란 표현을 이용하여 BPTT라고합니다. 순서대로 하나씩 계산을 할 수 있습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtyGK1uGdTvU"
      },
      "source": [
        "여기서의 문제점은 $V$의 반복이 문제가 됩니다. 만약 이 Recurrent가 100회, 1000회 반복된다고 보면, $V$의 100제곱, 1000제곱이 식 내부로 들어가게 될 것입니다. 1.1의 10제곱만해도 2.85배로 커지게 됩니다. 이렇게 발산하게되는 문제가 발생하게 되고, 한편 0.9의 제곱식을 고려하면, 무수히 작아지는 것을 볼 수 있습니다. \n",
        "\n",
        ">$V$의 크기를 적절하게 조절해주면 되지 않을까? \n",
        "\n",
        "라는 생각이 들기 시작합니다. 이렇게 $V$의 크기를 조절하는 Gate를 만들어서 적절히 조절해주면서 RNN을 조절해보자는 개념에서 출발한 것이 바로 LSTM입니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl_LOn0BHa_F"
      },
      "source": [
        "## LSTM\n",
        "이렇게 **RNN에 Gate를 추가한 모델을 LSTM**이라고 합니다. 요즘에는 단순한 RNN은 사용하지 않고 대부분 장기 단기 기억 장치 (LSTM)를 사용합니다.  지칭하는 이름 자체가 변하기도 하였는데요, 요즘 RNN이라고 하면 당연히 LSTM이나 이후에 배울 GRU를 지칭할 정도로 LSTM이 대표적인 RNN의 모델이 되었습니다. 오히려 전에 배운 RNN을 `기본적인 RNN`이라고 표현하기도 합니다. \n",
        "\n",
        "아래 그림은 그 단위 모듈에 대한 예시입니다.\n",
        "\n",
        "\"무언가 복잡해 보입니다. 한 블럭 안에서 많은 일이 진행되고 있습니다. 블럭 하나 안에 작은 신경망이 들어있다고 생각하시면 조금 쉽게 이해할 수 있습니다. 기존 신경망의 학습(역전파)에 대해서 배우며 기울기의 미분에 의해서 학습되는 개념을 배웠는데, 이 블럭 속에서도 같은 원리가 적용되며 역전파를 설계할 수 있습니다. 그러면 이 변화가 RNN과는 무엇이 다른가? \n",
        "\n",
        "**LSTM의 장점은 그 이름인 Long Short Term Memory 처럼 최근(short) 이벤트에 더 많은 비중을 둘수도 있으면서 동시에 오래된 (long) 정보를 완전히 잃지 않을 수 있다는 것**입니다. 과거 정보를 얼마나 유지할 것인지(forget gate), 새로 입력된 정보는 얼마만큼 활용할 것인지(input gate), 그리고 두 정보를 이용하여 얼마만큼 출력을 할 것인지(output gate)를 통해서 3가지 Gate의 비율만큼 정보를 끌어다가 쓸 수 있는 모델을 만들어낸 것입니다.\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F9905CF385BD5F5EC027F20\"/>\n",
        "\n",
        "위에서도 언급했지만, 충분한 반복(iterations) 후에 일반적인 신경망의 값이 너무 작아서 gradients가 제대로 전파되지 못하고, 0으로 수렴하는 문제(vanishing gradient)가 발생합니다. **[Gradient Vanishing 문제](https://en.wikipedia.org/wiki/Vanishing_gradient_problem)라고 하며, RNN의 대표적인 문제로 유명합니다. 그것을 개선하기 위해서 LSTM의 gate들이 생겼다고 보실 수 있습니다.** 일상 생활의 예를 들어보면, 업무 대화를 하던 중에, 12시가 되면 Forget Gate를 빠르게 동작시켜서, 일 얘기를 중단하고 갑자기 점심을 뭐 먹을 지 생각하게 되고, 업무의 모든 것을 빠르게 잊어버리고 음식을 찾아 떠나게 만드는 역할을 수행하는 것입니다. \n",
        "\n",
        "\n",
        "점심시간이면 점심을 먹어야 한다고 알려주는 머신이라면 꽤 괜찮지 않습니까? LSTM을 사용하는 특히 매력적인 애플리케이션이 바로 언어 모델링입니다. 언어는 본질적으로 정렬 된 시퀀스 데이터입니다 (문자 / 단어가 차례로 이동하고 순서가 * 중요합니다 *). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectness/)에 대해서는 한번 읽어보시면 좋습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2PxnHsMzLSk"
      },
      "source": [
        "LSTM 역전파 \n",
        "\n",
        "<img src=\"http://i.imgur.com/2BZtc2l.gif\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF578lp6G3o5"
      },
      "source": [
        "## GRU\n",
        "Gated Recurrent Unit, GRU\n",
        "한편, 이 LSTM의 간소한 버전인 GRU도 가볍게 소개합니다. \n",
        "구조를 살펴봅시다. \n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F99F0EC3E5BD5F6460255CF\"/>\n",
        "\n",
        "- LSTM Cell에서의 두 상태 벡터 $c_t$ ​와 $h_t$​가 하나의 벡터 $h_t$​로 합쳐짐.\n",
        "- 하나의 Gate controller인 $z_t$가 forget, input gate를 모두 제어하며,  $z_t$가 1을 출력하면 forget 게이트가 열리고, input 게이트가 닫히며, $z_t$가 0이면, 반대로 동작함.\n",
        "- GRU 셀은 output 게이트가 사라짐. 전체 상태 벡터 $h_t$가 각 시각에서 출력되며, 이전 상태의 $h_t-1$의 어느 부분이 출력될 지 새롭게 제어하는 Gate controller인 $r_t$이 있음.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "이제부터 TensorFlow와 Keras를 사용하여 자연어로 RNN을 훈련시켜 보겠습니다.\n",
        "\n",
        "- https://www.tensorflow.org/guide/keras/rnn\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n",
        "- https://keras.io/api/layers/recurrent_layers/lstm/\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        "\n",
        "여기 `tensorflow.contrib` [RNN/LSTM 예시](https://www.tensorflow.org/tutorials/sequences/recurrent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "## 따라해봅시다!\n",
        "시퀀스는 주가부터 텍스트까지 다양한 모양과 형태로 제공됩니다. 우리는 주로 텍스트에 초점을 맞춰 공부하도록 하겠습니다. 왜냐하면 텍스트를 시퀀스로 모델링하는 것은 신경망의 강점이기 때문입니다. 먼저 TensorFlow 튜토리얼을 사용하여 간단한 분류 작업부터 시작하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyBVcWqOlBWH"
      },
      "source": [
        "### 1. Keras를 이용한 RNN/LSTM 감정분류(Sentiment Classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti23G0gRe3kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4bc212b-4583-4d34-9a15-cc44c9f086d5"
      },
      "source": [
        "'''\n",
        "# IMDB 감성 분류 작업에 대한 LSTM 모델을 학습합니다.\n",
        "데이터 집합이 사실 너무 작아서 LSTM이 강점을 발휘할 수 없습니다.\n",
        "TF-IDF + LogReg와 같은 간단하고 빠른 방법이 LSTM에 비해 훨씬 빠릅니다.\n",
        "**Notes**\n",
        "- RNN은 까다롭습니다. 배치 크기 선택이 중요하고, 손실 및 최적화 도구 선택이 중요합니다. 일부 구성은 수렴되지 않을 것입니다.\n",
        "- 교육 중 LSTM 손실 감소 패턴은 CNN/MLP/etc에서 보는 것는 상당히 다를 수 있습니다.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imd\n",
        "\n",
        "# 이 단어 랭크 수 뒤에 텍스트는 사용하지 않도록 잘라냅니다(단어 등장 순위 : max_feature)\n",
        "# 참조링크 : https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data\n",
        "max_features = 20000\n",
        "# 최대 단어 길이\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwW0TZ87lBWQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26aec2e-e2af-4025-ca2d-bb21b018275b"
      },
      "source": [
        "print('Pad Sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad Sequences (samples x time)\n",
            "x_train shape:  (25000, 80)\n",
            "x_test shape:  (25000, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeNO2I63lBWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003029b3-ce27-4f66-a55d-12884990fb58"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
              "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
              "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
              "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
              "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
              "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
              "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
              "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
              "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdwCFRz3lBWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b9f8cc-f847-4fc1-b958-3943d7e84cdd"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(max_features, 128))\n",
        "# model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Embedding(max_features, 128),\n",
        "  tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl4iHbNxlBWa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "209d855f-c2ad-4f2e-f9c2-e35fcb2590d3"
      },
      "source": [
        "unicorns = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size, \n",
        "          epochs=3, \n",
        "          validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 263s 337ms/step - loss: 0.4315 - accuracy: 0.7940 - val_loss: 0.3762 - val_accuracy: 0.8362\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 263s 336ms/step - loss: 0.2586 - accuracy: 0.8971 - val_loss: 0.4020 - val_accuracy: 0.8347\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 264s 338ms/step - loss: 0.1669 - accuracy: 0.9374 - val_loss: 0.4462 - val_accuracy: 0.8284\n",
            "Epoch 4/5\n",
            "  3/782 [..............................] - ETA: 2:39 - loss: 0.1435 - accuracy: 0.9375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-14af549fa2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_data=(x_test,y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V90NGxkblBWd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3924fd62-a256-4fcb-d8cc-916160d3ed57"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(unicorns.history['loss'])\n",
        "plt.plot(unicorns.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pETWPIe362y"
      },
      "source": [
        "### 2. LSTM 텍스트 생성기 with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZlqNJnMlBWh"
      },
      "source": [
        "LSTMs로 무엇을 할 수 있을까요? **시퀀스**를 분석하고 있기 때문에, 우리는 분류 이상의 것을 할 수 있습니다. \n",
        "\n",
        "다음 텍스트를 **생성**할 수 있습니다. \n",
        "**니체(Friedrich Nietzsche)의 글** 을 이용해서 실습을 해봅시다\n",
        "\n",
        "Keras [LSTM text Generation](https://keras.io/zh/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDSeEDN2lBWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293461b6-67c1-46d6-d577-91bee5fc657e"
      },
      "source": [
        "# 라이브러리, 데이터 불러오기\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "path = get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 600893\n",
            "total chars: 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWf-YJp79wUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "845a1a65-7fdf-4c7e-e11f-4bc4a8323980"
      },
      "source": [
        "# max length를 이용하여 문자열의 크기 정렬\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 200285\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDgXQ51N9x5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f663dde1-5459-4189-ad4f-8118f36ec424"
      },
      "source": [
        "# LSTM 모델 제작\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvc8OpIP9yCZ"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWDL61Pf9yF4"
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=60,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIWN328cwNHO"
      },
      "source": [
        "# Transfromer (심화 학습)\n",
        "Attention이라는 개념을 사용하여 시계열 데이터를 처리하는 방법입니다. 위에서 배운 3가지의 개념은 모두 RNN을 기반으로 하고 있습니다. 문장에 여러가지 단어가 있으면 한 단어 한 단어를 신경망에 넣고 다음을 예측하는 시퀀스 처리 방식을 가지고 있다면, 이 Transformer/Attention은 문장을 한번에 넣는데, 순서정보를 입력해주는 것입니다.  \"나는 머신러닝을 배우고 있다\"라는 단어를 넣는다고 하면 \"나는(0) 머신러닝을(1) 배우고(2) 있다(3)\"을 넣어주고 처리하는 방식입니다. 이번 강의에서는 이 내용을 소개하진 않습니다. 그러나 시퀀스를 처리는 데 Transformer라는 개념이 사용된다는 것을 알고 넘어가는 것이 중요합니다.  시간이 있으신 분들은 이 개념을 배워두시면, 실무에 가셔서 바로 적용이 가능합니다. 이에 대한 [유튜브 강의](https://youtu.be/FeEmmylAF0o?t=310)를 소개합니다. GPT라는 Transformer를 기반으로한 네트워크에 대한 설명의 일부인데 수업 중에서는 이정도로만 알고 넘어가시면 되겠습니다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1_lh58plBXE"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>\n",
        "- <a href=\"#p2\">Part 2: </a>  시퀀스 모델링에 사용된 신경망 예 + Keras를 사용하여 텍스트 생성 문제에 LSTM 적용\n",
        "\n",
        "        - 시계열 데이터 (like Stock Prices, Weather, etc.)\n",
        "        - Text Classification\n",
        "        - Text Generation 등\n",
        "    * LSTMs, GRU가 일반적으로 대부분의 문제에서 RNN보다 선호됩니다.\n",
        "    * 최근에는 LSTM, RNN 외에도 Attention(Transformer)을 이용한 모델을 이용하여 시퀀스 데이터를 다루고 있습니다. \n",
        "\n",
        "\n",
        "     * 입력 데이터의 형태가 매우 중요\n",
        "     * 훈련하는 데 시간이 다소 많이 걸림 \n",
        "     * 영화 대본, 창작 업무에 사용가능 (GPT를 이용한 창작, 생각공유가 이슈가 되고 있음)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENLLcbmksRMr"
      },
      "source": [
        "## 참고자료\n",
        "- [Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
        "\n",
        "- 음성을 텍스트로 변환시키는 기술 [LAS with attention 논문](https://https://arxiv.org/abs/1508.01211), [블로그 버전](https://https://kaen2891.tistory.com/30)\n",
        "- 텍스트를 음성으로 변환하는 기술 [Tacotron 블로그](https://https://hcnoh.github.io/2018-12-11-tacotron)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhqNjZ3nx5Ev"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}