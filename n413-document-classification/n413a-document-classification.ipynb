{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n",
    "\n",
    "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / NOTE 3*\n",
    "\n",
    "# 📝 Assignment\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 텍스트에서 특성을 추출하고 문서 분류기를 만들어 보세요.\n",
    "* LSA를 사용해 문서의 차원을 축소해 분류에 사용합니다.\n",
    "* Spacy 단어 임베딩을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이번 과제에서는 위스키 리뷰 텍스트에서 특성을 추출하고 문서 분류기를 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터를 가져옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/whisky/train.csv')\n",
    "# 테스트 세트는 마지막 성능 확인에만 사용합니다.\n",
    "test = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/whisky/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 데이터를 분석합니다.\n",
    "- 타겟 분포 등을 확인합니다.\n",
    "- 타겟별 텍스트를 확인합니다.\n",
    "- 필요한 분석을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature -> description \n",
    "# rating -> great:0, good:1, bad:2\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 카테고리별 문장 샘플을 프린트해 봅니다.\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "train[train.rating == 2].sample(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### 훈련/검증 데이터 셋으로 분리합니다\n",
    "X_train, X_val, y_train, y_val = train_test_split(train['description']\n",
    "                                                   ,train['rating']\n",
    "                                                   ,test_size=0.2\n",
    "                                                   ,stratify=train['rating'] # train/test 모두 rating 비율과 같게 합니다\n",
    "                                                   ,random_state=1)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 파이프라인을 구성해 보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = ...\n",
    "clf = ...\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "...\n",
    "accuracy_score(pred, sol['rating'])\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 하이퍼파라미터를 설정하고 학습을 수행하세요\n",
    "vectorizer와 분류모델의 최적 하이퍼파라미터를 찾기 위한 설정입니다. 마음것 시도하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'clf__max_depth':(5,10,15,20),\n",
    "    ...\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 결과를 분석합니다.\n",
    "- Accuracy 점수가 70% 이상 나오도록 노력해 보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 세트를 가지고 예측을 수행합니다.\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 결과를 리포팅 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 잠재의미분석(Latent Semantic Analysis, LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 파이프라인을 구성해 보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = ...\n",
    "svd = ...\n",
    "clf = ...\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', vect)\n",
    "    , ('svd', svd)\n",
    "    , ('clf', rfc)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 하이퍼파라미터를 설정해 주세요\n",
    "vectorizer와 분류모델의 최적 하이퍼파라미터를 찾기 위한 설정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'svd__n_components': [10,100,250],\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'clf__max_depth':(5,10,15,20),\n",
    "    ...\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 결과를 분석하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 결과를 리포팅 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Spacy 단어 임베딩을 사용해서 결과를 다시 도출하고 비교 분석합니다.\n",
    "- 텍스트를 추출하고 분류하는 파이프라인을 만드세요\n",
    "- 파이프라인을 GridSearchCV 혹은 RandomizedSearchCV를 사용하여 튜닝하세요\n",
    "- Spacy 단어 임베딩을 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    \n",
    "    'max_depth' : randint(3,10),\n",
    "    'min_samples_leaf': randint(2,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 임베딩을 사용하세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ...predict(test['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수고하셨습니다!\n",
    "\n",
    "70%이상을 달성하였다면 충분합니다!\n",
    "\n",
    "- 내일 배울 토픽모델링(Topic modeling)에 관해 공부해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P41_NLP",
   "language": "python",
   "name": "p41_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
