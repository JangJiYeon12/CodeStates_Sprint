{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N423a_Word2Vec_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skn9ZDVioced"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 3 / Assignment 2*\n",
        "\n",
        "--- \n",
        "\n",
        "# Segmentation and Data Augmentation\n",
        "\n",
        "Segmentation의 성능과 관련이 있는 파라미터를 검색한다. <br>\n",
        "오늘의 과제는 아주 간단한 미니 프로젝트처럼 구성되어있다.<br>\n",
        "아래 체크리스트를 점검하면서 과제를 수행해보자. \n",
        "- Keras, tensorflow, pytorch 등 프레임워크에서 제공하는 예제가 아닌 단어/문장 생성기 등 시퀀스 예제 찾기 (RCNN, Faster RCNN, MASK RCNN, Yolo 사용예제)\n",
        "  - 문항 1) 예제 키워드(주제)를 입력하시오. \n",
        "  - 문항 2) 찾는 과정에서 사용한 **검색어**를 모두 입력하시오. \n",
        "  - 문항 3) 사용할 레포지토리를 찾은 검색어를 입력하시오. <br>\n",
        "\n",
        "- 찾아본 코드(레포지토리)를 Colab, Conda, jupyter등 내 환경에서 구현해본다. (참고, github 등에서 readme.md를 잘 따라하면 수행하기가 쉽다. 샘플링크 참조)\n",
        "  - 문항 4) 위 방법을 수행하면서 발생한 오류를 찾아 해결하고 블로그에 해당 내용을 정리하여 게시하고, 블로그 링크를 입력하시오. (오류가 없었다면 공백)\n",
        "<br>\n",
        "\n",
        "- 만약 찾은 코드가 제대로 돌아가지 않는다면, 수정하는 것도 좋지만, 같은 기능을 하는 다른 github를 찾아보며 위과정을 반복한다.<br>\n",
        "\n",
        "- 레포지토리 코드를 이용하여 데모가 잘 구현되었다면, 이제 디테일을 파악해보자\n",
        "  - 문항 5) 어떤 데이터(데이터 설명)를 사용하였는가?\n",
        "  - 문항 6) 전처리과정에 사용한 내용은 무엇인가?\n",
        "  - 문항 7) 어떤 구조(LSTM의 구조 및 node개수 등)의 모델인가? <br>\n",
        "\n",
        "- 이해하기 어려운 코드를 포함하고 있고 직접 설명하기 어렵다면, 인용된 논문을 찾아 주석을 달아두고 이해한 부분만으로 정리한 뒤 Reference에 해당 논문을 남겨두자.\n",
        "\n",
        "c.f. [샘플링크](https://github.com/keithito/tacotron)를 보면 Git에 잘 구성된 페이지를 볼 수 있다. README와 Requirements, 데모코드, notebook 등이 잘 되어있는 레포지토리를 활용할 것. (**단, 이 링크는 샘플일 뿐, 이 링크를 통해서 과제를 해서는 안 된다**)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltj1je1fp5rO"
      },
      "source": [
        "# TODO - Words, words, mere words, no matter from the heart."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# 도전과제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "\n",
        "- 위의 과제에서 사용한 네트워크에 적용할 다른 데이터를 찾아본다. 예) 셰익스피어 텍스트를 이용한 과제라면, 니체의 글을 적용해보는 등의 다른 데이터를 적용해보기\n",
        "- 해당 모델에서 가장 쉬운 부분을 변경해보기. 예) hidden layer의 node수를 변경, activation function을 바꿔보기, LSTM을 GRU, RNN 등으로 변경해보기 등\n",
        "- readme에서 제공한 자료보다 성능을 올려볼 것\n",
        "\n",
        "## 피해야 할 Resources:\n",
        "- https://www.tensorflow.org/guide/keras/rnn\n",
        "- https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
        "- https://victorzhou.com/blog/keras-rnn-tutorial/\n",
        "- https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
        "- https://www.kaggle.com/thousandvoices/simple-lstm\n"
      ]
    }
  ]
}