{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "N431a_Auto_New.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10OXb-oNKVzO"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 3 / Assignment 1*\n",
        "# Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfZdD_cp1t5"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "케라스를 이용한 바이너리 이미지 분류 모델에 3가지 CNN 모델을 적용하여 보는 과제입니다. <br/>\n",
        "\n",
        "- [데이터 다운로드](https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/datasets/mountainForest.zip)\n",
        "\n",
        "산의 이미지(./data/mountin/*)와 숲의 이미지(./data/forest/*)를 분류하는 문제입니다. <br/>\n",
        "산을 Positive (1)로, 숲 이미지를 Negative(0)로 레이블링 하여줍니다.\n",
        "\n",
        "클래스당 약 350개의 이미지로 이루어져 있는데요.<br/>\n",
        "표본이 작다는 점을 감안하면 현실적으로 어려운 문제입니다.\n",
        "\n",
        "하지만 이번 과제에서는 해당 데이터에 여러 가지 모델을 적용해보는는 것에 중점을 두어 봅시다. <br/>\n",
        "과제를 통해 이미지 분류에 적용할 수 있는 여러 모델을 알아보고 서로를 비교하는 데 익숙해져 보면 좋겠죠?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Ng0p_35yrh"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI3qR2nVKVzT"
      },
      "source": [
        "## Part 1 : Pre-trained Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXXsDSZvriLL"
      },
      "source": [
        "Keras에서 제공하는 pre-trained 모델인 ResNet50을 불러와서 사용해봅니다. [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1)은 50 개의 layer를 가진  CNN기반의 모델입니다. <br/>\n",
        "이미지를 [1000 개의 클래스로](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt)를 분류하는 모델인데요. 우리가 풀어야 할 과제는 2가지 이므로 마지막 출력단을 변경해서 사용해 볼 수 있습니다.\n",
        "\n",
        "\n",
        "`ResNet50`을 불러올 때, **`include_top=False`** 로 하면, 기존 1000가지 클래스로의 분류 문제를 풀 수 있는 ResNet 모델에서 Fully Connected layer 부분을 제거해주는 역할을 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHZAR2pnyD65"
      },
      "source": [
        "```python\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D()\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "resnet = ResNet50(weights='imagenet', include_top=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_Km6oGLqP0z"
      },
      "source": [
        "아래 부분은 ResNet50 레이어들의 파라미터를 학습하지 않도록 설정합니다. <br/>\n",
        "이렇게 설정된 매개 변수는 역전파를 통해 오차 정보가 전파 되더라도 파라미터가 업데이트 되지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8Kn76NkyIgG"
      },
      "source": [
        "```python\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qg5wDPPqV0P"
      },
      "source": [
        "모델에 추가로 **`Fully-conneted layer(Dense)`** 를 추가해야 합니다. <br/>\n",
        "사전 학습 모델을 불러오면서 최상위 레이어인 **`Fully-conneted layer`** 를 제거했기 때문이지요.\n",
        "\n",
        "새로 추가하는 **`Fully-conneted layer`** 에서는 목적인 이진 분류에 맞게 출력층을 설계하여 주어야 합니다. <br/> **`GlobalAveragePooling2D`** 레이어는 마지막 컨벌루션 레이어 출력(2 차원) 각각의 평균을 취해주어 **`Dense`** 층에 들어갈 수 있도록 해줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfCWu5bJyNoW"
      },
      "source": [
        "```python\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x) # 출력층을 설계합니다.\n",
        "model = Model(resnet.input, predictions)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvJd3ItAKVzU"
      },
      "source": [
        "### Load in Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTcetvpqwO5X"
      },
      "source": [
        "[Keras ImageDataGenerator](https://keras.io/api/preprocessing/image/) 를 참고하여 데이터를 불러옵니다. <br/>\n",
        "위 링크뿐만 아니라 구글링을 통해 ImageDataGenerator 라이브러리에 대한 여러 예제를 조사하고 참고해보세요. \n",
        "\n",
        "Notebook을 여러분의 Google Drive에 Mount 한 후에 이미지를 불러오도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4c0M58cKVzW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMzezBMBKVza"
      },
      "source": [
        "### Instatiate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0i14sSCKVzb",
        "outputId": "74a33d44-bf1f-4542-8339-f02985a1b731"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/jonathansokoll/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtQX3ALdKVzf"
      },
      "source": [
        "### Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPEt-wwuKVzg",
        "outputId": "1545ee98-10d5-4253-d11e-13effb509682"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 561 samples, validate on 141 samples\n",
            "Epoch 1/5\n",
            "561/561 [==============================] - 39s 69ms/sample - loss: 0.1216 - accuracy: 0.9715 - val_loss: 1.4221 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "561/561 [==============================] - 35s 62ms/sample - loss: 0.0410 - accuracy: 0.9875 - val_loss: 2.9222 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "561/561 [==============================] - 35s 62ms/sample - loss: 0.0646 - accuracy: 0.9697 - val_loss: 0.9962 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "561/561 [==============================] - 39s 70ms/sample - loss: 0.0723 - accuracy: 0.9733 - val_loss: 0.2627 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "561/561 [==============================] - 38s 68ms/sample - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.4859 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f980e9c6f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjBDRtCw55Sb"
      },
      "source": [
        "## Part 2 : Custom CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gpEjsFpKVzj"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "이 단계에서는 Keras를 사용하여 자신 만의 CNN을 작성하고 훈련합니다. <br/>\n",
        "네트워크에 적어도 하나의 Conv 레이어와 pooling 레이어가있는 아키텍처를 만들어 사용해 보세요. <br/> 아래는 여러분이 참고할 수 있도록 표시한 결과이며 여러분의 마음대로 설계하여도 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St--__KE0mN5"
      },
      "source": [
        "### Make a Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgwLFkhUKVzj",
        "outputId": "5f9184eb-4a1d-4f2e-a83e-ad6bdf063a71"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 215, 215, 32)      9632      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 43, 43, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 39, 39, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 9, 9, 64)          102464    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5184)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 64)                331840    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 495,265\n",
            "Trainable params: 495,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS18U9mP0f2F"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5NrX3K9KVzm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqy74Fpo0jXi"
      },
      "source": [
        "### Fit Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yju2nvVNKVzp",
        "outputId": "0cd03a87-2b28-4ade-a721-086627273a94"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 561 samples, validate on 141 samples\n",
            "Epoch 1/5\n",
            "561/561 [==============================] - 18s 32ms/sample - loss: 0.2667 - accuracy: 0.9073 - val_loss: 0.1186 - val_accuracy: 0.9858\n",
            "Epoch 2/5\n",
            "561/561 [==============================] - 18s 32ms/sample - loss: 0.2046 - accuracy: 0.9073 - val_loss: 0.3342 - val_accuracy: 0.8511\n",
            "Epoch 3/5\n",
            "561/561 [==============================] - 18s 32ms/sample - loss: 0.1778 - accuracy: 0.9287 - val_loss: 0.2746 - val_accuracy: 0.8723\n",
            "Epoch 4/5\n",
            "561/561 [==============================] - 18s 32ms/sample - loss: 0.1681 - accuracy: 0.9323 - val_loss: 0.8487 - val_accuracy: 0.5957\n",
            "Epoch 5/5\n",
            "561/561 [==============================] - 18s 32ms/sample - loss: 0.1606 - accuracy: 0.9394 - val_loss: 0.3903 - val_accuracy: 0.8582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f97388777f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    }
  ]
}