{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N412_Backpropagation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELV1ffGLL6xY"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / NOTE 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP-7IhbYL_0I"
      },
      "source": [
        "# N412. 경사하강법(Gradient Descent)과 역전파(Backpropagation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xszYUl5MDds"
      },
      "source": [
        "## 🛫 Warm Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEYOJtTFMIEK"
      },
      "source": [
        "- [역전파 미적분 | 딥러닝](https://youtu.be/tIeHLnjs5U8) - 3Blue1Brown\n",
        "- [Neural Networks Demystified (Part 4: Backpropagation)\n",
        "](https://youtu.be/GlcnxUlrtek) - Welch Labs : 학습 과정을 잘 모사한 영상입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3-v_vZbM7E8"
      },
      "source": [
        "### 지난 시간 내용 복습하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk1sLHX8NAH5"
      },
      "source": [
        "- **인공지능의 역사**\n",
        "\n",
        "- **퍼셉트론(Perceptron)과 논리 게이트(AND, NAND, OR 그리고 XOR)**\n",
        "\n",
        "- **신경망의 기본 구조**\n",
        "    - Input\n",
        "    - Activation function\n",
        "    - Output\n",
        "\n",
        "- **신경망의 동작 원리**\n",
        "    - 데이터 전처리 및 입력\n",
        "    - 모델 제작 및 가중치 초기화\n",
        "    - 모델에 데이터를 넣고 출력값을 얻음\n",
        "    - 출력값과 레이블(정답지)과 비교 후 Loss 계산\n",
        "    - Loss를 반영하여 가중치 업데이트 -> 이번 강의에서 배우게 될 **역전파(BackPropagation) + 경사하강법(Gradient Descent)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YldS9c4M4AD"
      },
      "source": [
        "## 🏆 학습 목표"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZalFKLf2Nj5s"
      },
      "source": [
        "- **경사 하강법(Gradient descent)과 역전파(Backpropagation)**에 대해 이해하고 설명할 수 있다.\n",
        "- **케라스(`Keras`) 프레임워크를 이용하여 모델을 구축**할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWYA1gouEFwb"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH_69WOVvh8V"
      },
      "source": [
        "## 역전파를 배우기 전에"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPJyLjuQvlXh"
      },
      "source": [
        "> ❗️ ***오늘 배울 <font color=\"ff6f61\">역전파와 경사 하강법은 신경망을 처음 배울 때에 가장 어려운 부분</font>입니다.<br/>\n",
        "처음부터 수학적인 내용을 모두 이해하지 못해도 좋습니다.<br/>\n",
        "일단 역전파를 통한 신경망 학습을 개념적으로 이해한 뒤에, 강의와 노트를 반복하면서 내용을 이해하려 시도해보시면 좋겠습니다 :)***\n",
        "\n",
        "먼저 어제 배웠던 내용을 한 번 돌아본 후에 역전파로 넘어가도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdiecJnkOnb3"
      },
      "source": [
        "### 신경망 구조 (recap.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIH2bx5dOpT2"
      },
      "source": [
        "이번 강의에서는 신경망이 어떻게 훈련되는지에 대해 조금 더 깊게 알아보도록 하겠습니다.\n",
        "\n",
        "지난 강의에서 신경망의 학습(Training)이란 **적절한 '가중치'를 찾아가는 과정**임을 배웠습니다.\n",
        "그렇다면 어떻게 신경망은 스스로 적절한 가중치를 찾을 수 있는 것일까요?\n",
        "\n",
        "그 답은 바로, 이번 시간에 배울 **<font color=\"ff6f61\">경사 하강법(Gradient descent, GD)과 역전파(Backpropagation, BP)</font>**입니다.<br/>\n",
        "조금 더 자세하게 말하면 경사 하강법에 필요한 기울기(Gradient)계산을 역전파 알고리즘을 통해 구하게 됩니다.\n",
        "\n",
        "지난 강의에서 학습했던 신경망의 기본적인 구조와 연산에 대해 간략히 짚어보겠습니다.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ3Ly_yWr8Vm"
      },
      "source": [
        "<img src=\"https://i.imgur.com/dlGareT.gif\" alt=\"backpropagation\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTk7PRZHrjjX"
      },
      "source": [
        "- 신경망에는 크게 3개의 층 **[=입력층(Input layer), 은닉층(Hidden layer), 출력층(output layer)]**이 존재합니다.\n",
        "\n",
        "- 각 층은 한 개 이상의 노드(Node)로 구성되어 있으며, 각 노드는 **가중치(Weight)와 편향(Bias)**으로 연결되어 있습니다.\n",
        "\n",
        "- **<font color=\"ff6f61\">순전파</font> : 입력층에서 입력된 신호가 은닉층의 연산을 거쳐 출력층에서 값을 내보내는 과정**\n",
        "    - 입력층(왼쪽)에서부터 출력층(오른쪽) 방향으로 데이터가 전달됩니다.\n",
        "        1. 입력층으로부터(혹은 이전 은닉층으로부터) 신호(데이터)를 전달받습니다.\n",
        "        2. 입력된 데이터를 가중치 및 편향과 연산한 뒤에 더해줍니다.(가중합, weighted sum)\n",
        "        3. 가중합을 통해 구해진 값은 활성화 함수(Activation function)를 통해 다음 층으로 전달됩니다.\n",
        "        \n",
        "특정 층에 입력되는 데이터의 특성이 $n$ 개인 경우 이 과정을 수식으로 나타내면 다음과 같이 나타낼 수 있습니다.<br/>\n",
        "(아래 식에서 활성화 함수는 시그모이드 함수입니다.)\n",
        "\n",
        "\\begin{align}\n",
        " y = \\text{sigmoid}\\bigg(\\sum( b + w_{1}x_{1} + w_{2}x_{2} + ... + w_{n}x_{n})\\bigg)\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_uFig8Fvwqm"
      },
      "source": [
        "### 경사 하강법과 역전파 미리 맛보기 : 신경망 학습 알고리즘 요약"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqWXjgxWOvYH"
      },
      "source": [
        "오늘 배울 내용을 간략하게 줄여보겠습니다.\n",
        "\n",
        "> ❗️ ***당장 아래 요약을 이해하지 못해도 좋습니다. 아래에서 하나씩 자세하게 살펴볼 예정입니다.<br/>\n",
        "게다가 원래 역전파를 단번에 이해하기란 어렵습니다. 갑자기 수식이 너무 많이 등장한다고 좌절하지 않아도 됩니다.***\n",
        "\n",
        "1. **데이터와 목적에 맞게 신경망 구조를 설계**합니다.\n",
        "    - 입력층 노드(유닛) 수 = **데이터의 Feature 수로 설정합니다.**\n",
        "    - 출력층 노드(유닛) 수 = **문제(분류, 회귀 등)에 따라 다르게 설정합니다.**\n",
        "    - 은닉층 수와 각 은닉층의 노드 수를 결정합니다.\n",
        "2. **가중치를 랜덤하게 초기화** 해줍니다. (초기화 방법에 대해서는 다음에 배울 것입니다.)\n",
        "3. 순전파를 통해 출력값($h_{\\theta}(x^{(i)})$) 을 모든 입력 데이터($x^{(i)}$)에 대해 계산합니다.\n",
        "4. **비용 함수(Cost function**, $J(\\theta)$)를 계산합니다.\n",
        "5. **역전파**를 통해 각 가중치에 대한 편미분 값($\\partial J(\\theta)/\\partial\\theta_{jk}^{l}$) 을 계산합니다.\n",
        "6. **경사하강법을 사용하여 비용함수인 ($J(\\theta)$)를 최소화하는 방향으로 가중치를 갱신**합니다.\n",
        "7. **중지 기준을 충족하거나 비용 함수를 최소화 할 때까지 2-5 단계를 반복**합니다. 2-5 단계를 한 번 진행하는 것을 **iteration** 라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpNGFv5EBwgO"
      },
      "source": [
        "- **<font color=\"ff6f61\">비용 함수(Cost Function) 혹은 손실 함수(Loss function)</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffhraXdYOxTt"
      },
      "source": [
        "신경망은 손실 함수를 최소화 하는 방향으로 가중치를 갱신합니다.<br/>\n",
        "그렇기 때문에 손실 함수를 잘 정의해주어야 가중치가 제대로 갱신될 수 있겠죠?\n",
        "\n",
        "입력 데이터를 신경망에 넣어 순전파를 거치면 마지막 출력층을 통과한 값이 도출됩니다.<br/>\n",
        "출력된 값과 그 데이터의 타겟값을 **손실 함수에 넣어 손실(Loss or Error)를 계산**합니다.<br/>\n",
        "한 데이터 포인트에서의 손실을 **Loss** 라고 하며, 전체 데이터셋의 Loss를 합한 개념을 **Cost** 라고 합니다.\n",
        "\n",
        "대표적인 손실 함수는 MSE, Cross-Entropy 등이 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGNsYW44E3LA"
      },
      "source": [
        "신경망 학습에는 다른 머신러닝 알고리즘들 보다 **훨씬 많은** 훈련 데이터가 필요합니다.<br/>\n",
        "그에 따라 훈련 시간도 오래 걸리고 최적화를 위해서 더 많은 **하이퍼파라미터를 튜닝**해 주어야 합니다.<br/>\n",
        "이렇게 복잡한 신경망을 훈련하기 위해서는 특별한 방법이 필요합니다, 바로 **역전파(Backpropagation) 알고리즘** 입니다.\n",
        "\n",
        "그럼 이제 신경망을 훈련시키는 역전파 알고리즘을 제대로 배워보도록 하겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPO0YR1yO0N8"
      },
      "source": [
        "## 역전파(Backpropagation, BP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO7mnyI_O4La"
      },
      "source": [
        "**<font color=\"ff6f61\">역전파(Backpropagation)</font>**는 [\"Backwards Propagation of Errors\"](https://en.wikipedia.org/wiki/Backpropagation)의 줄임말 입니다.<br/>\n",
        "말 그대로 순전파와는 **반대 방향으로 손실(Loss or Error) 정보를 전달**해주는 역할을 합니다.\n",
        "\n",
        "순전파가 **입력 신호 정보를 입력층부터 출력층까지 전달하여 값을 출력**하는 알고리즘이었다면,<br/>\n",
        "역전파는 구해진 **손실 정보를 출력층부터 입력층까지 전달하여 각 가중치를 얼마나 업데이트 해야할지를 결정**하는 알고리즘입니다.\n",
        "\n",
        "매 iteration 마다 구해진 **손실(Loss)을 줄이는 방향**으로 가중치를 업데이트합니다.<br/>\n",
        "그렇다면 **손실을 줄이는 방향**이 어떤 방향인지를 알 수 있을까요?\n",
        "이 방향을 결정하는 것이 바로 **<font color=\"ff6f61\">경사 하강법(Gradient Descent, GD)</font>**입니다.\n",
        "\n",
        "경사 하강법과 역전파를 이해하기 위해서는 **미분법**에 대한 이해가 필요합니다.<br/>\n",
        "수식에 대한 설명은 Warm Up 영상을 참고하여 익숙해져 보도록 합시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVChCZotO47O"
      },
      "source": [
        "지난 강의에서는 신경망의 순전파(Feed-Forward Propagation)에 대해서 배웠습니다.<br/>\n",
        "그리고 경사 하강법과 역전파에 대해서도 코드로 잠시 다루어보았는데요.<br/>\n",
        "이번 시간에는 경사 하강법과 역전파 부분을 자세히 알아보도록 하겠습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecLK2exeO85-"
      },
      "source": [
        "<img src=\"https://i.imgur.com/Y5XVbrp.png\" title=\"https://becominghuman.ai/understanding-the-structure-of-neural-networks-1fa5bd17fef0\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00yjbAa230aE"
      },
      "source": [
        "### 예제를 통해서 이해해보기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6VaoSzKO-z7"
      },
      "source": [
        "**`공부시간`** 과 **`수면시간`** 을 특성(Feature)으로 하고 시험 점수를 레이블로 하는 회귀 예제를 풀어봅시다.<br/>\n",
        "데이터에서 특성과 레이블은 아래와 같은 선형 관계를 이루고 있다고 가정하겠습니다.<br/>\n",
        "아래 식에서 $x_1$ 은 **`공부시간`**을 나타내고 $x_2$ 는 **`수면시간`**을 나타낸다고 해보겠습니다.\n",
        "\n",
        "$y = 5x_1 + 2x_2 + 40$\n",
        "\n",
        "그리고 신경망이 위 관계를 알아서 잘 찾아낼 수 있는지를 알아보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ26yTfL3yRw"
      },
      "source": [
        "1. **필요한 패키지를 `import` 하고 랜덤 시드(random seed)를 고정합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuW58m1LO4e-"
      },
      "source": [
        "# 해당 코드는 선형함수를 예측하는 예제입니다. \n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(812)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpIaJT6_4Kqx"
      },
      "source": [
        "2. **임의의 특성 데이터로부터 관계를 만족하는 레이블을 도출한 뒤에 데이터셋을 만듭니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd81KjHQ4LH4"
      },
      "source": [
        "# [공부시간, 수면시간]\n",
        "X = np.array(([8,8],\n",
        "              [2,5],\n",
        "              [7,6]), dtype=float)\n",
        "\n",
        "# 선형 관계를 바탕으로 시험 점수 레이블을 생성합니다.\n",
        "y = X[:,0]*5 + X[:,1]*2\n",
        "y = y.reshape(3,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjNcGpJTE3yS"
      },
      "source": [
        "3. **특성을 정규화(Normalization) 합니다.**\n",
        "\n",
        "각 특성 및 레이블의 최댓값으로 나누어 주어 0~1 사이의 값으로 만들어줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JntJxcVZE5JP",
        "outputId": "7c37aec9-fb11-4b7e-f77a-b240a8769147"
      },
      "source": [
        "X = X / np.amax(X, axis=0)\n",
        "y = y / np.amax(y, axis=0)\n",
        "\n",
        "print(\"공부시간, 수면시간 \\n\", X)\n",
        "print(\"시험점수 \\n\", y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "공부시간, 수면시간 \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "시험점수 \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LdNeb6nPCGP"
      },
      "source": [
        "4. **신경망을 구축합니다.**\n",
        "\n",
        "> ❗️ ***클래스 개념이 익숙하지 않을 수 있습니다.<br/>\n",
        "클래스 자체의 의미보다는 주석을 따라 코드를 한줄 한줄 따라가 보도록 합시다.***\n",
        "\n",
        "`NeuralNetwork` 클래스 내 `__init__` 메소드(함수)에서 신경망을 구축합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmDZfDC1LrHh"
      },
      "source": [
        "class NeuralNetwork:\n",
        "    \"\"\"\n",
        "    신경망(Neural network)를 정의하는 클래스(Class) 선언\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        신경망의 구조를 결정합니다.\n",
        "\n",
        "        inputs : 입력층 노드 수\n",
        "        hiddenNodes : 은닉층 노드 수\n",
        "        outputNodes : 출력층 노드 수\n",
        "        w1, w2 : 은닉층(layer 1), 출력층(layer 2)의 가중치\n",
        "        \"\"\"\n",
        "        \n",
        "        self.inputs = 2\n",
        "        self.hiddenNodes = 3\n",
        "        self.outputNodes = 1\n",
        "        \n",
        "        # 가중치를 초기화 합니다.\n",
        "        # layer 1 가중치 shape : 2x3\n",
        "        self.w1 = np.random.randn(self.inputs,self.hiddenNodes)\n",
        "        \n",
        "        # layer 2 가중치 shape : 3x1\n",
        "        self.w2 = np.random.randn(self.hiddenNodes, self.outputNodes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g48qC1Xy7Q-R"
      },
      "source": [
        "> ❓ ***왜 입력 노드의 수는 2로 해주었을까요?***<br/>\n",
        "❓ ***왜 출력 노드의 수는 1로 해주었을까요?***<br/>\n",
        "❓ ***왜 `layer 1, layer 2`의 가중치 행렬 shape 은 각각 2X3, 3X1 로 설정하였을까요?***\n",
        "\n",
        "> ❗️ ***신경망에서 <font color=\"ff6f61\">가중치 행렬의 `shape`은 굉장히 중요하면서도 헷갈리는 부분</font>입니다.<br/>\n",
        "단번에 완벽히 이해할 수는 없겠지만 반복하여 보면서 익숙해져 봅시다!***\n",
        "\n",
        "실제로 가중치가 어떻게 생성되었는지 출력해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vg259zrPGY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d437bad3-8128-4351-8ed3-94f97d6e7d16"
      },
      "source": [
        "# 정의된 클래스를 사용해보고, 해당 가중치를 디스플레이 하는 코드입니다. \n",
        "nn = NeuralNetwork()\n",
        "\n",
        "print(\"Layer 1 가중치: \\n\", nn.w1)\n",
        "print(\"Layer 2 가중치: \\n\", nn.w2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 가중치: \n",
            " [[ 2.48783189  0.11697987 -1.97118428]\n",
            " [-0.48325593 -1.50361209  0.57515126]]\n",
            "Layer 2 가중치: \n",
            " [[-0.20672583]\n",
            " [ 0.41271104]\n",
            " [-0.57757999]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvxnl3IaAQAQ"
      },
      "source": [
        "- **Review : 행렬의 곱셈 연산**\n",
        "\n",
        "$A_{l \\times m}, B_{m \\times n}$ 두 행렬을 곱할 때 $\\Rightarrow (AB)_{l \\times n}$<br/>\n",
        "결과값으로 나오는 행렬의 shape은 $\\big($<font color='red'>$l$</font> $\\times$ <font color='blue'>$m$</font>$\\big)$ $\\cdot$ $\\big($ <font color='blue'>$m$</font> $\\times$ <font color='green'>$n$</font> $\\big)$ = <font color='red'>$l$</font> $\\times$ <font color='green'>$n$</font> 행렬의 형태로 연산이 됩니다.\n",
        "\n",
        "아래 그림을 참조하여 행렬의 곱셈 연산에 대한 내용을 다시 떠올려봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyCt_jelPKB9"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/18/Matrix_multiplication_qtl1.svg\" width=\"450\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIZ-3Q2qDaUO"
      },
      "source": [
        "5. **순전파 기능을 추가로 구현합니다.**\n",
        "\n",
        "**기존 `NeuralNetwork` 클래스에 순전파 기능을 추가**하여 봅시다.<br/>\n",
        "순전파에 필요한 활성화 함수(sigmoid)를 구현한 뒤에 가중합(weighted sum)부분과 활성화 함수가 적용되는 부분을 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtoouVz8PKmM"
      },
      "source": [
        "class NeuralNetwork:\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        신경망의 구조를 결정합니다.\n",
        "\n",
        "        inputs : 입력층 노드 수\n",
        "        hiddenNodes : 은닉층 노드 수\n",
        "        outputNodes : 출력층 노드 수\n",
        "        w1, w2 : layer 1, layer 2의 가중치\n",
        "        \"\"\"\n",
        "        self.inputs = 2\n",
        "        self.hiddenNodes = 3\n",
        "        self.outputNodes = 1\n",
        "        \n",
        "        # 가중치를 초기화 합니다.\n",
        "        # layer 1 가중치 shape : 2x3\n",
        "        self.w1 = np.random.randn(self.inputs,self.hiddenNodes)\n",
        "        \n",
        "        # layer 2 가중치 shape : 3x1\n",
        "        self.w2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
        "        \n",
        "    def sigmoid(self, s):\n",
        "        \"\"\"\n",
        "        활성화 함수인 시그모이드 함수를 정의합니다.\n",
        "        s : 활성화 함수에 입력되는 값(=가중합)\n",
        "        \"\"\"\n",
        "        return 1 / (1+np.exp(-s))\n",
        "    \n",
        "    def feed_forward(self, X):\n",
        "        \"\"\"\n",
        "        순전파를 구현합니다.\n",
        "        입력 신호를 받아 출력층의 결과를 반환합니다.\n",
        "        \n",
        "        hidden_sum : 은닉층(layer 1)에서의 가중합(weighted sum)\n",
        "        activated_hidden : 은닉층(layer 1) 활성화 함수의 함숫값\n",
        "        output_sum : 출력층(layer 2)에서의 가중합(weighted sum)\n",
        "        activated_output : 출력층(layer 2) 활성화 함수의 함숫값\n",
        "        \"\"\"\n",
        "        \n",
        "        self.hidden_sum = np.dot(X, self.w1)\n",
        "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "\n",
        "        self.output_sum = np.dot(self.activated_hidden, self.w2)\n",
        "        self.activated_output = self.sigmoid(self.output_sum)\n",
        "        \n",
        "        return self.activated_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtV91UhbI37E"
      },
      "source": [
        "6. **순전파를 거쳐 출력되는 값을 알아봅시다.**\n",
        "\n",
        "입력한 데이터가 신경망 순전파를 거쳐 어떤 출력값을 내는 지 확인해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAQenxirPS8A"
      },
      "source": [
        "# 선언한 클래스를 불러와서 할당합니다.\n",
        "nn = NeuralNetwork()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW2YtQCqJUao",
        "outputId": "66cc63ee-e988-413b-8d08-cdcb1a1d7174"
      },
      "source": [
        "# 첫 번째 데이터를 출력합니다.\n",
        "print(X[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXZjYC74JXRR",
        "outputId": "a4db6bc2-5cc7-4f65-c8b3-8c9546e35a10"
      },
      "source": [
        "# 첫 번째 데이터를 입력한 뒤 신경망이 출력하는 값을 살펴보겠습니다.\n",
        "output = nn.feed_forward(X[0])\n",
        "print(\"예측값: \", output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측값:  [0.21945787]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gTPu7dEPUYf"
      },
      "source": [
        "7. **손실(Error,Loss)과 비용(Cost) 계산**\n",
        "\n",
        "1개의 데이터에 대해 실제 타겟 레이블과 출력값을 비교하여 손실(`error`)을 구해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAawfPI5PV-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6290b888-bf2a-4a1b-a715-6dc15d08d98c"
      },
      "source": [
        "# 실제 타겟 레이블과 출력값을 비교하여 손실(error)을 구합니다.\n",
        "error = y[0] - output\n",
        "error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.78054213])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcRHiMlMMoch"
      },
      "source": [
        "이 과정을 모든 데이터에 적용하여 비용(Cost)를 구해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY7akPN6MvPy",
        "outputId": "b4434595-8637-4945-bb9e-949c82512c9e"
      },
      "source": [
        "# 모든 데이터를 예측해보고 에러값을 계산해 보겠습니다.\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StYYK5D8M12y",
        "outputId": "19c6c63e-72ce-471a-c1d1-c579f9728b6c"
      },
      "source": [
        "output_all = nn.feed_forward(X)\n",
        "print(output_all)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.21945787]\n",
            " [0.34573206]\n",
            " [0.23788921]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv3vM_ckM9yS",
        "outputId": "1504e486-98e4-4cf2-b76c-7b5d9bdcd544"
      },
      "source": [
        "error_all = y - output_all\n",
        "print(error_all)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.78054213]\n",
            " [0.0114108 ]\n",
            " [0.6013965 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7bWbvMrND2o"
      },
      "source": [
        "#### 결과값 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tZ54d0QNMkj"
      },
      "source": [
        "1. 각각의 **에러가 작어야 하는데 너무 크게 나왔습니다.** 에러가 크게 나오는 이유는 무엇일까요?\n",
        "    - 에러가 높게 나오는 이유는 예측값이 **정확하지 않기(여기서는 너무 작게 나오기) 때문**입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoD92VIMPBsU"
      },
      "source": [
        "2. 그렇다면 **예측값이 작게 나오는 이유**는 무엇일까요?\n",
        "    - 임의로 지정하였던 두 번째 층의 가중치 값(`w2`)이 작거나\n",
        "    - 첫 번째 층의 출력값(`activated_hidden`)이 작기 때문입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1khxbqguPrsa"
      },
      "source": [
        "3. **첫 번째 층의 출력값(`activated_hidden`)이 작은 이유**는 무엇일까요?\n",
        "- 입력 데이터(`X`)는 변하지 않는 값이므로 첫 번째 층의 가중치 값(`w1`)이 작기 때문입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZJf6lWFQZUj"
      },
      "source": [
        "**1, 2, 3**을 고려했을 때 예측값을 증가시키기 위한 방법은 **첫 번째 층과 두 번째 층의 가중치(`w1, w2`)를 증가시키는 것**뿐입니다.\n",
        "\n",
        "이렇게 각 층마다 가중치가 있을텐데 에러를 최소화하기 위해서 어떤 가중치를 얼마나 올려주어야 할까요?<br/>\n",
        "일단 각 층의 가중치를 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAJQ90D7Pb-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "026a624c-ee78-4455-f6d6-2d1be825012b"
      },
      "source": [
        "# 각각의 변수(가중치)를 디스플레이 하기 위한 코드입니다.\n",
        "attributes = ['w1', 'hidden_sum', 'activated_hidden', 'w2', 'activated_output']\n",
        "\n",
        "for i in attributes:\n",
        "    if i[:2] != '__':\n",
        "        print(i+'\\n', getattr(nn,i), '\\n'+'---'*3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1\n",
            " [[-1.75351135  1.23279898  0.24464757]\n",
            " [-0.06568225  0.30190098  0.79723428]] \n",
            "---------\n",
            "hidden_sum\n",
            " [[-1.8191936   1.53469996  1.04188185]\n",
            " [-0.47942924  0.49688786  0.55943332]\n",
            " [-1.58358412  1.30512484  0.81199233]] \n",
            "---------\n",
            "activated_hidden\n",
            " [[0.13953066 0.82269293 0.73921295]\n",
            " [0.38238691 0.62172769 0.63632141]\n",
            " [0.17028848 0.78669622 0.6925339 ]] \n",
            "---------\n",
            "w2\n",
            " [[ 1.23073545]\n",
            " [-1.52187331]\n",
            " [-0.25502715]] \n",
            "---------\n",
            "activated_output\n",
            " [[0.21945787]\n",
            " [0.34573206]\n",
            " [0.23788921]] \n",
            "---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3MHHUG4RHQh"
      },
      "source": [
        "#### 손실(Error)을 줄이기 위해서는 어떻게 해야 할까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzI9r1nNPcbZ"
      },
      "source": [
        "아래 그림을 보면 알 수 있듯, **비용 함수 $J$ 의 경사(Gradient)가 작아지는 방향으로 업데이트** 하면 손실 함수의 값을 줄일 수 있습니다.<br/>\n",
        "매 Iteration 마다 **<font color=\"ff6f61\">해당 가중치에서의 비용 함수의 도함수(=비용 함수를 미분한 함수)를 계산</font>하여** 경사가 작아질 수 있도록 가중치를 변경합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaobXDMGPi5b"
      },
      "source": [
        "<img src=\"https://i.imgur.com/ehYYRtw.png\" alt=\"Gradient Descent in 1D\" width=\"700\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Uf9AGwaPioi"
      },
      "source": [
        "위에서 설계한 신경망은 총 9개의 가중치를 가지고 있습니다. 첫 번째 층에는 6개(`w1`), 두 번째 층에는 3개(`w2`)가 있죠.<br/>\n",
        "그렇기 때문에 해당 신경망의 비용 함수는 9차원 공간상의 함수$(J)$가 되겠습니다.<br/>\n",
        "비용 함수의 경사가 줄어드는 방향으로 가중치를 갱신해나가면 되겠죠?\n",
        "\n",
        "비용 함수 $J$를 수식으로 나타내 보겠습니다.\n",
        "\n",
        "$$\n",
        "J(\\theta) = J(\\theta_1, \\theta_2, \\theta_3, \\theta_4, \\theta_5, \\theta_6, \\theta_7, \\theta_8, \\theta_9)\n",
        "$$\n",
        "\n",
        "아래는 비용 함수를 가중치 2개에 대해서만 단순화시켜 나타낸 그림입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpHICzw8Pilo"
      },
      "source": [
        "<img src=\"https://i.imgur.com/yZA6RUJ.png\" alt=\"Gradient descent algorithm direction Equation 1. (Image courtesy of Andrew Ng)\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_PSaZJ9PqNt"
      },
      "source": [
        "- **볼록/오목 함수(Convex/Concave function)와 지역 최적점(Local Optima)**\n",
        "\n",
        "경사 하강법을 통해 최저점을 찾는 메커니즘은 볼록(Convex) 함수에서만 잘 동작합니다.<br/>\n",
        "하지만 실제 손실 함수는 위 그림처럼 볼록 함수와 오목 함수가 부분부분 섞여있는 형태인데요.<br/>\n",
        "그렇기 때문에 전역 최적점(Global Optima)를 찾지 못하고 **지역 최적점(Local Optima)에 빠질 수 있습니다.**\n",
        "\n",
        "지역 최적점에 빠지게 되는 문제를 방지하기 위한 여러가지 방법이 있는데요.<br/>\n",
        "이런 알고리즘에 대해서는 잠시 후에 알아보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSkwMFVqBLgZ"
      },
      "source": [
        "> ❗️ ***볼록 함수(Convex function)와 오목 함수(Concave function)의 수학적인 의미보다는 각 함수가 대략 어떤 형태인지 알아봅시다.<br/>\n",
        "각 함수의 형태로부터 볼록 함수에서는 왜 경사 하강법이 잘 되고, 오목 함수에서는 안 될지 상상해봅시다.***\n",
        "\n",
        "> 🔍 ***참조 링크 : [Convex(볼록) & Concave(오목) 알아보기](https://blog.naver.com/sw4r/221148661854) <br/>\n",
        "추천 검색어 : Convex Optimization, Gradient Descent***\n",
        "\n",
        "> ❗️ ***그리고 지역 최적점이란 무엇인지, 왜 지역 최적점에 빠지면 안좋은지를 알아봅시다.***\n",
        "\n",
        "> 🔍 ***추천 검색어 : Gradient Descent Local Optima***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CduJwgvPhr-"
      },
      "source": [
        "### 가중치 업데이트 : 역전파 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcP_MVZ7kaWy"
      },
      "source": [
        "6. **<font color=\"ff6f61\">역전파 기능을 구현</font>해봅시다.**\n",
        "\n",
        "> ❗️ ***역전파(***`backward`***) 함수 내 과정이 이해가 되지 않을 수 있습니다.<br/>\n",
        "아래에서 다시 설명이 될 예정이므로 당장 이해가 되지 않더라도 좋습니다.***\n",
        "\n",
        "> ❗️ ***아래 그림은 역전파 시 각 변수(`o_error`,`o_delta`,`z2_error`,`z2_delta`)의 이해를 돕기 위한 것으로 노드 수는 신경쓰지 않으셔도 됩니다.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdvgnpemTgp9"
      },
      "source": [
        "<img src=\"https://i.imgur.com/brCdkz1.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GuCg1YaPjpu"
      },
      "source": [
        "# 음수 가중치를 가지는 활성화는 낮추고, 양수 가중치를 가지는 활성화는 높이고 싶습니다.\n",
        "class NeuralNetwork:\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        신경망의 구조를 결정합니다.\n",
        "\n",
        "        inputs : 입력층 노드 수\n",
        "        hiddenNodes : 은닉층 노드 수\n",
        "        outputNodes : 출력층 노드 수\n",
        "        w1, w2 : layer 1, layer 2의 가중치\n",
        "        \"\"\"\n",
        "        self.inputs = 2\n",
        "        self.hiddenNodes = 3\n",
        "        self.outputNodes = 1\n",
        "        \n",
        "        # 가중치를 초기화 합니다.\n",
        "        # layer 1 가중치 shape : 2x3\n",
        "        self.w1 = np.random.randn(self.inputs,self.hiddenNodes)\n",
        "        \n",
        "        # layer 2 가중치 shape : 3x1\n",
        "        self.w2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
        "        \n",
        "    def sigmoid(self, s):\n",
        "        \"\"\"\n",
        "        활성화 함수인 시그모이드 함수를 정의합니다.\n",
        "        s : 순전파 과정에서 활성화 함수에 입력되는 값(=가중합)\n",
        "        \"\"\"\n",
        "        return 1 / (1+np.exp(-s))\n",
        "\n",
        "    def sigmoidPrime(self, s):\n",
        "        \"\"\"\n",
        "        활성화 함수(sigmoid)를 미분한 함수입니다.\n",
        "        s : 순전파 과정에서 활성화 함수에 입력되는 값(=가중합)\n",
        "        \"\"\"\n",
        "        sx = self.sigmoid(s)\n",
        "        return sx * (1-sx)\n",
        "    \n",
        "    def feed_forward(self, X):\n",
        "        \"\"\"\n",
        "        순전파를 구현합니다.\n",
        "        입력 신호를 받아 출력층의 결과를 반환합니다.\n",
        "        \n",
        "        hidden_sum : 은닉층(layer 1)에서의 가중합(weighted sum)\n",
        "        activated_hidden : 은닉층(layer 1) 활성화 함수의 함숫값\n",
        "        output_sum : 출력층(layer 2)에서의 가중합(weighted sum)\n",
        "        activated_output : 출력층(layer 2) 활성화 함수의 함숫값\n",
        "        \"\"\"\n",
        "        \n",
        "        self.hidden_sum = np.dot(X, self.w1)\n",
        "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "\n",
        "        self.output_sum = np.dot(self.activated_hidden, self.w2)\n",
        "        self.activated_output = self.sigmoid(self.output_sum)\n",
        "        \n",
        "        return self.activated_output\n",
        "    \n",
        "    def backward(self, X, y, o):\n",
        "        \"\"\"\n",
        "        역전파를 구현합니다.\n",
        "        출력층에서 손실 값(Error)를 구한 뒤에 이를 각 가중치에 대해 미분한 값만큼 가중치를 수정합니다.\n",
        "\n",
        "        X : 입력 데이터(input)\n",
        "        y : 타겟값(target value)\n",
        "        o : 출력값(output)\n",
        "\n",
        "        o_error : 손실(Error) = 타겟값과 출력값의 차이\n",
        "        o_delta : 출력층 활성화 함수의 미분값\n",
        "        \"\"\"\n",
        "        \n",
        "        # o_error : 손실(Error)을 구합니다.\n",
        "        self.o_error = y - o \n",
        "        \n",
        "        # o_delta : 활성화 함수(시그모이드)의 도함수를 사용하여 출력층 활성화 함수 이전의 미분값을 구합니다.\n",
        "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
        "        \n",
        "        # z2 error : 은닉층에서의 손실을 구합니다.\n",
        "        self.z2_error = self.o_delta.dot(self.w2.T)\n",
        "        \n",
        "        # z2 delta : 활성화 함수(시그모이드)의 도함수를 사용하여 은닉층 활성화 함수 이전의 미분값을 구합니다.\n",
        "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.output_sum)\n",
        "\n",
        "        # w1, w2를 업데이트 합니다.\n",
        "        self.w1 += X.T.dot(self.z2_delta) # X * dE/dY * dY/dy(=Y(1-Y))\n",
        "        self.w2 += self.activated_hidden.T.dot(self.o_delta) # H1 * Y(1-Y) * (Y - o)\n",
        "        \n",
        "    def train(self, X, y):\n",
        "        \"\"\"\n",
        "        실제로 신경망 학습을 진행하는 코드입니다.\n",
        "        1번의 순전파-역전파, 즉 1 iteration 을 수행하는 함수입니다.\n",
        "        \n",
        "        X : 입력 데이터(input)\n",
        "        y : 타겟값(target value)\n",
        "        \"\"\"\n",
        "        o = self.feed_forward(X)\n",
        "        self.backward(X,y,o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTx0-U7ynZmw"
      },
      "source": [
        "> ❗️ ***당장 아래 수식을 이해하지 못해도 좋습니다. 아래에서 수학을 통해 알아볼 것입니다.<br/>\n",
        "다만 나중에는 수식만 보고도 이해할 수 있어야겠죠?***\n",
        "\n",
        "- 수식을 통해 위 코드를 알아보겠습니다.\n",
        "\n",
        "    손실(Error) : $E$<br/>\n",
        "출력층 활성화 함수의 출력값(`activated_output`) : $A_O$<br/>\n",
        "출력층 활성화 함수의 입력값(=가중합, `output_sum`) : $S_O$<br/>\n",
        "은닉층 활성화 함수의 출력값(`activated_hidden`) : $A_H$<br/>\n",
        "은닉층 활성화 함수의 입력값(=가중합, `hidden_sum`) : $S_H$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfh-8J7XqVi1"
      },
      "source": [
        "- **$w_2$(=출력층과 은닉층 사이의 가중치) 에 대한 미분**\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial E}{\\partial w_2} &= \\frac{\\partial E}{\\partial A_O} \\cdot \\frac{\\partial A_O}{\\partial w_2}\\\\\n",
        "\\frac{\\partial E}{\\partial w_2} &= \\frac{\\partial E}{\\partial A_O} \\cdot \n",
        "\\frac{\\partial A_O}{\\partial S_O} \\cdot \\frac{\\partial S_O}{\\partial w_2}\n",
        "= \\frac{\\partial E}{\\partial A_O} \\cdot \n",
        "\\frac{\\partial A_O}{\\partial S_O} \\cdot A_H \\quad \\bigg( \\because A_H = \\frac{\\partial S_O}{\\partial w_2}\\bigg)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "\n",
        "- **$w_1$(=은닉층과 입력층 사이의 가중치) 에 대한 미분**\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial E}{\\partial w_1} &= \\frac{\\partial E}{\\partial A_H} \\cdot \\frac{\\partial A_H}{\\partial w_1}\\\\\n",
        "\\frac{\\partial E}{\\partial w_2} &= \\frac{\\partial E}{\\partial A_H} \\cdot \n",
        "\\frac{\\partial A_H}{\\partial S_H} \\cdot \\frac{\\partial S_H}{\\partial w_1}\n",
        "= \\frac{\\partial E}{\\partial A_H} \\cdot \n",
        "\\frac{\\partial A_H}{\\partial S_H} \\cdot X \\quad \\bigg( \\because X = \\frac{\\partial S_H}{\\partial w_1}\\bigg)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9r5CAlht1Sb"
      },
      "source": [
        "#### 역전파가 추가된 신경망 클래스 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evfTvj1U2Yqd"
      },
      "source": [
        "- **순전파 후 손실(Error) 계산**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUmwEIh3PqCD"
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "nn.train(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evjw1NK4Pp_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ba2c75-07fc-4b04-895d-b689911814dc"
      },
      "source": [
        "# 순전파 후 손실(Error)을 확인해보겠습니다.\n",
        "nn.o_error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.70644301],\n",
              "       [0.10036169],\n",
              "       [0.56649547]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAbq8hWCPtn6"
      },
      "source": [
        "- **출력층의 경사(Gradient) 계산하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNWqlpnDVNUL"
      },
      "source": [
        "**에러(Error, `o_error`)**와 **출력층 활성화 함수를 미분한 함수(`sigmoidPrime`)**를 통해서 출력층의 경사(`o_delta`)를 구해보겠습니다.\n",
        "\n",
        "`self.o_delta = self.o_error * self.sigmoidPrime(self.output_sum)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfu_hl8CPvTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafa1e5d-de5b-4c0a-e90f-8f203c9397bf"
      },
      "source": [
        "# 순전파 시 출력층에서의 가중합\n",
        "nn.o_error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.70644301],\n",
              "       [0.10036169],\n",
              "       [0.56649547]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxVc1iycPxmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132de16b-5ccb-49f4-fee6-10934f000d2b"
      },
      "source": [
        "# 순전파 시 출력층에서의 가중합을 활성화 함수에 통과시킨 \n",
        "nn.sigmoidPrime(nn.o_error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22123085],\n",
              "       [0.24937153],\n",
              "       [0.23096866]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVjfaGwQPx7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a65542b-6523-4592-fb4a-ceaf91fb0c7d"
      },
      "source": [
        "# 출력층 활성화 함수 이전의 미분값을 구합니다.\n",
        "# o_delta = o_error * sigmoidPrime(o)\n",
        "nn.o_delta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.17285985],\n",
              "       [0.02468133],\n",
              "       [0.13902149]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQyKhgPmP0cF"
      },
      "source": [
        "- **은닉층이 받는 손실(Error) 계산**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EljA-ddtVj7A"
      },
      "source": [
        "이전 단계에서 구했던 **출력층의 경사(`o_delta`)**와 **출력층의 가중치(`w2`)**를 통해서 은닉층이 받는 손실(`z2_error`)을 구해보겠습니다.\n",
        "\n",
        "`self.z2_error = self.o_delta.dot(self.w2.T)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ3pQbwrP0uP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d7a5bb-9ffb-4bbd-8b46-8b8d931fd945"
      },
      "source": [
        "nn.o_delta.dot(nn.w2.T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.28194591, -0.23236088,  0.12295841],\n",
              "       [-0.04025689, -0.03317703,  0.01755629],\n",
              "       [-0.22675329, -0.18687483,  0.09888856]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaN7hHWmWDRY"
      },
      "source": [
        "> ❗️ ***해당 연산의 결과로 나오는 행렬의 shape이 왜 (3,3)일지에 대해서 생각해보고 토론해봅시다.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-GvmzdCWQgo"
      },
      "source": [
        "- **은닉층의 경사(Gradient) 계산하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em8eSpBqP4Jd"
      },
      "source": [
        "**은닉층 에러(`z2_error`)**와 **은닉층 활성화 함수를 미분한 함수(`sigmoidPrime`)**를 통해서 은닉층의 경사(`z2_delta`)를 구해보겠습니다.\n",
        "\n",
        "`self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNp-1OzqP5rT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c75bde-8a67-4622-e812-634fa1aa0222"
      },
      "source": [
        "nn.activated_hidden"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.43460965, 0.23985861, 0.42340322],\n",
              "       [0.37111212, 0.48687214, 0.52242758],\n",
              "       [0.48093658, 0.2520165 , 0.4192448 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfC1no3TP5pE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636e1755-0ecc-4fb2-8298-c2aedd4e5384"
      },
      "source": [
        "nn.z2_delta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.06388859, -0.05136035,  0.020324  ],\n",
              "       [-0.00839476, -0.00674859,  0.00267051],\n",
              "       [-0.04915074, -0.03951252,  0.01563565]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAzRNK57P5mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b54e03b-f58e-48d9-a471-10bbaffe696b"
      },
      "source": [
        "X.T.shape == nn.w1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPB5af8rZW6d",
        "outputId": "dba642af-38c9-46ac-95a4-4fab8fefd87e"
      },
      "source": [
        "nn.z2_delta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.06388859, -0.05136035,  0.020324  ],\n",
              "       [-0.00839476, -0.00674859,  0.00267051],\n",
              "       [-0.04915074, -0.03951252,  0.01563565]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8cQi2-XZeza"
      },
      "source": [
        "#### 경사 하강법(Gradient Descent)을 적용하여 가중치 업데이트\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_q1Hh-BP_gX"
      },
      "source": [
        "- 은닉층 가중치(`w1`)를 업데이트 합니다.\n",
        "\n",
        "> ❗️ ***토론해봅시다.<br/>\n",
        "1) 왜 입력값(`X`)와 은닉층 기울기 값(`z2_delta`)을 곱해주는 것일까요?<br/>\n",
        "2) `X`는 왜 Transpose 해주어야 할까요?***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS66sQMBQAfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b6c0ff-3371-4447-9bce-47038a1b594a"
      },
      "source": [
        "X.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.   , 0.25 , 0.875],\n",
              "       [1.   , 0.625, 0.75 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zyPq4O3QAcY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42df4cbd-c441-48d5-8adb-c952a8f21852"
      },
      "source": [
        "X.T.dot(nn.z2_delta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.10899418, -0.08762095,  0.03467281],\n",
              "       [-0.10599837, -0.0852126 ,  0.0337198 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVcrBcMIaa5f"
      },
      "source": [
        "- 출력층 가중치(`w2`)를 업데이트 합니다.\n",
        "\n",
        "> ❗️ ***토론해봅시다.<br/>\n",
        "1) 왜 첫 번째 층의 출력값(`activated_hidden`)과 출력층의 기울기(`o_delta`)를 곱해주는 것일까요?<br/>\n",
        "2) 출력층의 shape은 어떻게 3X1이 될까요?***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjt0nZL_QFGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b7d9e6-d1c8-4818-adda-fcc874709ed4"
      },
      "source": [
        "nn.activated_hidden.T.dot(nn.o_delta)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.15114662],\n",
              "       [0.08851428],\n",
              "       [0.14436766]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XndaS_3LQHyQ"
      },
      "source": [
        "### 신경망 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AboyJKFhbc2q"
      },
      "source": [
        "이제 순전파와 역전파를 정해진 횟수(iterations or epochs)만큼 반복하여 신경망을 학습시켜 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbCo1KQMQJok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1af69c2-c779-48c8-cb27-fb633495bf3f"
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "\n",
        "# 반복수(epochs or iterations)를 정합니다.\n",
        "iter = 10000\n",
        "\n",
        "# 지정한 반복수 만큼 반복합니다.\n",
        "for i in range(iter):\n",
        "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 == 0):\n",
        "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
        "        print('입력: \\n', X)\n",
        "        print('타겟출력: \\n', y)\n",
        "        print('예측: \\n', str(nn.feed_forward(X)))\n",
        "        print(\"에러: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
        "    nn.train(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------EPOCH 1---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.37768395]\n",
            " [0.40886333]\n",
            " [0.39684567]]\n",
            "에러: \n",
            " 0.19523515397548788\n",
            "+---------EPOCH 2---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.45734397]\n",
            " [0.47891087]\n",
            " [0.47278046]]\n",
            "에러: \n",
            " 0.14787637084266458\n",
            "+---------EPOCH 3---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.52094752]\n",
            " [0.53342462]\n",
            " [0.5325371 ]]\n",
            "에러: \n",
            " 0.11822041803732024\n",
            "+---------EPOCH 4---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.57039035]\n",
            " [0.57514949]\n",
            " [0.57861702]]\n",
            "에러: \n",
            " 0.10001317226025601\n",
            "+---------EPOCH 5---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.60862211]\n",
            " [0.60709769]\n",
            " [0.61410496]]\n",
            "에러: \n",
            " 0.08878681402481621\n",
            "+---------EPOCH 1000---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.91658292]\n",
            " [0.36458715]\n",
            " [0.92264135]]\n",
            "에러: \n",
            " 0.004653996157757957\n",
            "+---------EPOCH 2000---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.9208668 ]\n",
            " [0.36266393]\n",
            " [0.91689461]]\n",
            "에러: \n",
            " 0.004105228792044443\n",
            "+---------EPOCH 3000---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.92299619]\n",
            " [0.36183207]\n",
            " [0.91443433]]\n",
            "에러: \n",
            " 0.0038662965205599926\n",
            "+---------EPOCH 4000---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.92488749]\n",
            " [0.36088798]\n",
            " [0.91269919]]\n",
            "에러: \n",
            " 0.003681818226952254\n",
            "+---------EPOCH 5000---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.92684465]\n",
            " [0.36000853]\n",
            " [0.91054078]]\n",
            "에러: \n",
            " 0.0034790672406160316\n",
            "+---------EPOCH 6000---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.92685943]\n",
            " [0.36127375]\n",
            " [0.90749191]]\n",
            "에러: \n",
            " 0.0033395642642349618\n",
            "+---------EPOCH 7000---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.92336329]\n",
            " [0.36401733]\n",
            " [0.90897934]]\n",
            "에러: \n",
            " 0.003592548203894095\n",
            "+---------EPOCH 8000---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.92257479]\n",
            " [0.3638548 ]\n",
            " [0.91152851]]\n",
            "에러: \n",
            " 0.003752911674675145\n",
            "+---------EPOCH 9000---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.92239308]\n",
            " [0.36390556]\n",
            " [0.91194685]]\n",
            "에러: \n",
            " 0.0037827367165428074\n",
            "+---------EPOCH 10000---------+\n",
            "입력: \n",
            " [[1.    1.   ]\n",
            " [0.25  0.625]\n",
            " [0.875 0.75 ]]\n",
            "타겟출력: \n",
            " [[1.        ]\n",
            " [0.35714286]\n",
            " [0.83928571]]\n",
            "예측: \n",
            " [[0.92226356]\n",
            " [0.36399293]\n",
            " [0.91211178]]\n",
            "에러: \n",
            " 0.0037978381910849734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcKdSR8Ub9XY"
      },
      "source": [
        "출력 결과로 반복 수가 1-5회일 때의 에러와 이후 1000회 마다의 에러를 볼 수 있습니다.<br/>\n",
        "점점 에러가 줄어드는 경향성을 보이는 것을 확인할 수 있습니다 :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB7Qlpq1QNoB"
      },
      "source": [
        "> ❗️ ***여기까지 간단한 신경망 학습 과정을 파이썬 코드로 직접 구현해보았습니다.<br/>\n",
        "하지만 <font color=\"ff6f61\">아직 역전파에 대해서 잘 이해하지 못한 분이 대부분</font>일 것으로 생각합니다.<br/>\n",
        "역전파를 한 번에 이해하기란 쉽지 않은데요. 아래에서 역전파 과정에 대해 한 번 더 설명을 드리도록 하겠습니다.***\n",
        "\n",
        "그 전에 경사 하강법에서 빠질 수 없는 옵티마이저(Optimizer)에 대해서 다루고 넘어가겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM3fd8aQSIS6"
      },
      "source": [
        "## 옵티마이저(Optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOhGWKYaSU7m"
      },
      "source": [
        "위에서 경사 하강법을 배우면서\n",
        "\n",
        "> ***지역 최적점에 빠지게 되는 문제를 방지하기 위한 여러가지 방법이 있는데요.<br/>\n",
        "이런 알고리즘에 대해서는 잠시 후에 알아보도록 하겠습니다.***\n",
        "\n",
        "라고 남겨둔 부분이 있었는데요.\n",
        "\n",
        "위 문장에서 '이런 알고리즘'에 해당하는 것이 바로 **<font color=\"ff6f61\">옵티마이저(Optimizer)</font>** 입니다.\n",
        "\n",
        "옵티마이저는 쉽게 말해 **<font color=\"ff6f61\">경사를 내려가는 방법을 결정</font>**하는데요.<br/>\n",
        "대표적인 옵티마이저로는 아래와 같은 것들이 있습니다. (다 외우지 않아도 됩니다!)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtNcfeuzIpec"
      },
      "source": [
        "<img src=\"https://i.imgur.com/UQfpjpP.png\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D2hleJxItct"
      },
      "source": [
        "이번 강의에서는 **확률적 경사 하강법(`sgd`)** 을 알아보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbeBYh-yEjwq"
      },
      "source": [
        "### 확률적 경사 하강법(Stochastic Gradient Descent, SGD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrYCXdg1v9b9"
      },
      "source": [
        "위에서 구현했던 신경망은 모든 입력 데이터에 대해 손실을 계산하고 기울기를 계산한 후에 가중치를 업데이트 하였습니다.<br/>\n",
        "위 신경망에서는 입력 데이터가 3개 뿐이었기에 이 방법으로도 손실과 그 역전파 값을 금방 구할 수 있었습니다.<br/>\n",
        "\n",
        "실제 딥러닝에서는 이보다 훨씬 더 큰 데이터를 다루게 됩니다.<br/>\n",
        "만약 입력 데이터가 3천만개, 3억개 라면 모든 데이터에 대한 손실을 계산하는 과정이 굉장히 오래 걸리겠죠?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6E5K0kX_gOt"
      },
      "source": [
        "<img src=\"http://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization_files/ball.png\" width=\"600\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckujousyLHfw"
      },
      "source": [
        "그래서 등장한 것이 바로 **<font color=\"ff6f61\">확률적 경사 하강법</font>**과 **<font color=\"ff6f61\">미니 배치(Mini-batch) 경사 하강법</font>**입니다.\n",
        "\n",
        "확률적 경사 하강법(`sgd`)은 전체 데이터에서 하나의 데이터를 뽑아서 신경망에 입력한 후 손실을 계산합니다.<br/>\n",
        "그리고 그 손실 정보를 역전파하여 신경망의 가중치를 업데이트하게 됩니다.\n",
        "\n",
        "확률적 경사 하강법은 1개의 데이터만 사용하여 손실을 계산하기 때문에 **가중치를 빠르게 업데이트** 할 수 있다는 장점이 있습니다.<br/>\n",
        "물론 확률적 경사 하강법에도 단점이 있습니다. 1개의 데이터만 보기 때문에 학습 과정에서 불안정한 경사 하강을 보인다는 점인데요.\n",
        "\n",
        "아래 그림에서 확률적 경사 하강법(왼쪽)과 전체 데이터를 보고 가중치를 수정하는 방식(오른쪽)에서 경사 하강이 어떻게 일어나는 지의 차이를 볼 수 있습니다.\n",
        "\n",
        "> ❗️ ***아래 그림을 보면서 경사 하강이 왼쪽과 같이 불안정하면 어떤 문제가 발생할 수 있을지 생각해봅시다.***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rvf52cA_Zxk"
      },
      "source": [
        "<img src=\"https://datascience-enthusiast.com/figures/kiank_sgd.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKz8iv7j_aEa"
      },
      "source": [
        "그래서 두 방법을 적절히 융화한 **미니 배치(Mini-batch) 경사 하강법**이 등장하게 되었습니다.<br/>\n",
        "N개의 데이터로 미니 배치를 구성하여 해당 미니 배치를 신경망에 입력한 후 이 결과를 바탕으로 가중치를 업데이트합니다.<br/>\n",
        "일반적으로는 두 방법의 장점을 적절히 융화한 미니 배치 경사 하강법을 많이 사용합니다.\n",
        "\n",
        "아래 그림에서 확률적 경사 하강법(왼쪽)과 미니 배치 경사 하강법(오른쪽)에서 경사 하강이 어떻게 일어나는 지의 차이를 볼 수 있습니다.\n",
        "\n",
        "> ❗️ ***iteration, batch-size, epochs, 전체 데이터셋에 있는 데이터의 개수 사이의 관계에 대해 조사해봅시다.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRDGfFtjQQks"
      },
      "source": [
        "<img src=\"https://datascience-enthusiast.com/figures/kiank_minibatch.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcbksDU2CQJF"
      },
      "source": [
        "### 경사하강법의 변형들(다양한 Optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgi9ghdUQSmU"
      },
      "source": [
        "위에서 배운 확률적 경사 하강법을 포함하여 다음과 같은 경사 하강법 알고리즘(Optimizer)이 사용되고 있습니다.\n",
        "\n",
        "1. 확률적 경사 하강법(Stochastic Gradient Descent, SGD)\n",
        "2. 확률적 경사 하강법(SGD)를 변형한 알고리즘 - Momentum, RMSProp, Adam 등\n",
        "3. Newton's method 등의 2차 최적화 알고리즘 기반 방법 - BFGS 등\n",
        "\n",
        "> ❗️ ***특히 BFGS의 경우 당장 이해하지 않아도 좋습니다.***\n",
        "\n",
        "아래 그림은 여러 가지 옵티마이저가 경사를 어떻게 내려가는 지에 대한 예시입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dExM6zlzF7vW"
      },
      "source": [
        "<img src=\"https://developer.nvidia.com/blog/wp-content/uploads/2015/12/NKsFHJb.gif\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V1q7JgKF-Nf"
      },
      "source": [
        "여러 가지 옵티마이저 중에서 어떤 것이 가장 좋다고 말하기는 어렵습니다.<br/>\n",
        "문제마다, 데이터마다 달라지기 때문에 여러 옵티마이저를 적용하면서 서로 비교해보아야 하는데요.\n",
        "\n",
        "다음 강의에서 최적의 하이퍼파라미터를 찾아보면서 여러 옵티마이저를 비교해 볼 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37N5MaSIQW7S"
      },
      "source": [
        "## 수학으로 다시보는 역전파(Backpropagation Review with Math)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZYENoA98CHU"
      },
      "source": [
        "위에서 했던 역전파 과정을 수학으로 다시 보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jv9b-hVQXjq"
      },
      "source": [
        "<img src=\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/note2_image/bp1.png\">\n",
        "\n",
        "---\n",
        "\n",
        "<img src=\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/note2_image/bp2.png\">\n",
        "\n",
        "---\n",
        "\n",
        "<img src=\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/note2_image/bp3.png\">\n",
        "\n",
        "---\n",
        "\n",
        "<img src=\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/note2_image/bp4.png\">\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<img src=\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/note2_image/bp5.png\">\n",
        "\n",
        "\n",
        "by. Lee"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmuEIo0ghoeN"
      },
      "source": [
        "- **오타 수정**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-SsoBmRQbAN"
      },
      "source": [
        "> ### $ \\partial E_1 \\over \\partial H_1 $\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial E_1}{\\partial H_1} &= \\frac{\\partial E_1}{\\color{blue}{\\partial y_1}} \\cdot \\frac{\\color{blue}{\\partial y_1}}{\\partial H_1} \\\\\n",
        "\\frac{\\partial E_1}{\\partial H_1} &= \\frac{\\partial E_1}{\\color{red}{\\partial Y_1}} \\cdot \\frac{\\color{red}{\\partial Y_1}}{\\color{blue}{\\partial y_1}} \\cdot \\frac{\\color{blue}{\\partial y_1}}{\\partial H_1}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "> ### $ \\partial E_2 \\over \\partial H_1 $\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial E_2}{\\partial H_1} &= \\frac{\\partial E_2}{\\color{green}{\\partial y_2}} \\cdot \\frac{\\color{green}{\\partial y_2}}{\\partial H_1} \\\\\n",
        "\\frac{\\partial E_2}{\\partial H_1} &= \\frac{\\partial E_2}{\\color{orange}{\\partial Y_2}} \\cdot \\frac{\\color{orange}{\\partial Y_2}}{\\color{green}{\\partial y_2}} \\cdot \\frac{\\color{green}{\\partial y_2}}{\\partial H_1}\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj07q-sJQhbw"
      },
      "source": [
        "## Keras를 이용한 역전파 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9_6QRfBQjfL"
      },
      "source": [
        "[케라스(keras)](https://keras.io)는 신경망 모델을 간편하게 만들고 훈련시킬 수 있는 고수준 신경망 API입니다.\n",
        "\n",
        "텐서의 조작, 미분 등의 low-level 연산을 만들지 않아도 잘 동작한다는 장점이 있습니다.<br/>\n",
        "텐서플로우(Tensorflow)를 포함한 프레임워크와 함께 사용할 수 있으며 빠르고 간편한 프로토타이핑이 가능합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICWeKN4Bjqb1"
      },
      "source": [
        "케라스에서 신경망을 구축할 때 가장 많이 사용되는 방법 중 하나는 `Sequential` 입ㄴ디ㅏ.<br/>\n",
        "이 방법은 신경망 각 층을 쌓아올릴 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVl9yR3SkIrA"
      },
      "source": [
        "- **신경망 학습 메커니즘**\n",
        "\n",
        "신경망 학습은 다음과 같은 메커니즘으로 구성됩니다.\n",
        "\n",
        "1. 학습 데이터 로드(Load data)\n",
        "2. 모델 정의(Define model)\n",
        "3. 컴파일(Compile)\n",
        "4. 모델 학습(Fit)\n",
        "5. 모델 검증(Evaluate)\n",
        "\n",
        "> ❗️ ***5단계로 이루어진 이 과정은 앞으로도 계속 반복될 것입니다.<br/>\n",
        "강의 노트의 예제나 과제를 풀며 코드가 등장할 때마다 이 흐름을 잘 기억해두시면 좋겠습니다.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1fa_6DKl1ZK"
      },
      "source": [
        "1. **학습 데이터를 만듭니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNMFIQZ1Qm_k"
      },
      "source": [
        "# 앞서 살펴본 선형 데이터를 만들기 위함 함수\n",
        "def make_samples(n=1000):\n",
        "    study = np.random.uniform(1, 8, (n, 1))\n",
        "    sleep = np.random.uniform(1, 8, (n, 1))\n",
        "    \n",
        "    y = 5 * study + 2 * sleep + 40\n",
        "    X = np.append(study, sleep, axis = 1)\n",
        "    \n",
        "    # 정규화 \n",
        "    X = X / np.amax(X, axis = 0)\n",
        "    y = y / 100\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFmFCDjSQnER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9942571-ed7c-43f6-d4b6-61983990686b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "X, y = make_samples()\n",
        "X[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.76155759, 0.4065224 ],\n",
              "       [0.78699611, 0.19627527],\n",
              "       [0.39267953, 0.53940436],\n",
              "       [0.36391073, 0.99427628],\n",
              "       [0.64412524, 0.48054391],\n",
              "       [0.22616247, 0.13942684],\n",
              "       [0.70853207, 0.3407582 ],\n",
              "       [0.85016525, 0.44315516],\n",
              "       [0.26123166, 0.63737043],\n",
              "       [0.94228448, 0.48463672]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyIky88il-NQ"
      },
      "source": [
        "2. **필요한 라이브러리를 불러온 후 신경망을 구축하고 컴파일(compile)합니다.**\n",
        "\n",
        "> ❗️ ***아래 코드에서 출력층의 노드 수는 몇 개인지, 출력층의 활성화 함수는 무엇인지, 손실 함수는 어떻게 지정하였는지에 주목해봅시다.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-bbTtYEQnB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa502ba5-bcd5-43fa-ad7c-7d23c9f5aea3"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        " \n",
        "model = Sequential()\n",
        "\n",
        "# 신경망 모델 구조 정의\n",
        "model.add(Dense(3, input_dim=2, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성을 마무리 합니다.\n",
        "model.compile(optimizer='sgd', loss='mse', metrics=['mae', 'mse'])\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # 분류인 경우 예시\n",
        "\n",
        "results = model.fit(X,y, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 1s 1ms/step - loss: 0.0819 - mae: 0.2704 - mse: 0.0819\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 987us/step - loss: 0.0738 - mae: 0.2550 - mse: 0.0738\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0665 - mae: 0.2402 - mse: 0.0665\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0601 - mae: 0.2264 - mse: 0.0601\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 978us/step - loss: 0.0544 - mae: 0.2135 - mse: 0.0544\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0493 - mae: 0.2012 - mse: 0.0493\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0448 - mae: 0.1897 - mse: 0.0448\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - mae: 0.1790 - mse: 0.0408\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0373 - mae: 0.1694 - mse: 0.0373\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0342 - mae: 0.1605 - mse: 0.0342\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0315 - mae: 0.1524 - mse: 0.0315\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0291 - mae: 0.1453 - mse: 0.0291\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0270 - mae: 0.1386 - mse: 0.0270\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0251 - mae: 0.1327 - mse: 0.0251\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0235 - mae: 0.1273 - mse: 0.0235\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0220 - mae: 0.1225 - mse: 0.0220\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.1184 - mse: 0.0207\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0196 - mae: 0.1146 - mse: 0.0196\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0185 - mae: 0.1112 - mse: 0.0185\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0176 - mae: 0.1082 - mse: 0.0176\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0168 - mae: 0.1056 - mse: 0.0168\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0161 - mae: 0.1032 - mse: 0.0161\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0154 - mae: 0.1011 - mse: 0.0154\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0149 - mae: 0.0992 - mse: 0.0149\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 954us/step - loss: 0.0143 - mae: 0.0976 - mse: 0.0143\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0139 - mae: 0.0962 - mse: 0.0139\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0134 - mae: 0.0948 - mse: 0.0134\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0131 - mae: 0.0936 - mse: 0.0131\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 988us/step - loss: 0.0127 - mae: 0.0925 - mse: 0.0127\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0124 - mae: 0.0916 - mse: 0.0124\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0122 - mae: 0.0907 - mse: 0.0122\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0119 - mae: 0.0899 - mse: 0.0119\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0117 - mae: 0.0891 - mse: 0.0117\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0115 - mae: 0.0885 - mse: 0.0115\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0113 - mae: 0.0879 - mse: 0.0113\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 995us/step - loss: 0.0111 - mae: 0.0873 - mse: 0.0111\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0110 - mae: 0.0868 - mse: 0.0110\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0108 - mae: 0.0864 - mse: 0.0108\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0107 - mae: 0.0860 - mse: 0.0107\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 992us/step - loss: 0.0106 - mae: 0.0856 - mse: 0.0106\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0105 - mae: 0.0853 - mse: 0.0105\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0104 - mae: 0.0849 - mse: 0.0104\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0847 - mse: 0.0103\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0102 - mae: 0.0844 - mse: 0.0102\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0101 - mae: 0.0842 - mse: 0.0101\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0101 - mae: 0.0839 - mse: 0.0101\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0100 - mae: 0.0837 - mse: 0.0100\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0100 - mae: 0.0835 - mse: 0.0100\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 998us/step - loss: 0.0099 - mae: 0.0834 - mse: 0.0099\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0832 - mse: 0.0099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXQjCklXQs_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87318ccc-33b5-47b1-f127-7e5b4b1e1a0d"
      },
      "source": [
        "results.history.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mae', 'mse'])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raqPpzbKmXY2"
      },
      "source": [
        "3. **손실이 어떻게 줄어드는 지 시각화 해봅시다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezeUP1AXQs7T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d4e554ed-224b-435d-9cc4-d915161040d4"
      },
      "source": [
        "plt.plot(results.history['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f926a734510>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy5GnubhQs4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "03ff5c47-5e4c-4ed8-f274-0e95edb9ef8a"
      },
      "source": [
        "plt.plot(results.history['mae'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f926a290c50>]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GiD7JHWlDVR"
      },
      "source": [
        "### Fashion MNIST 예제를 통한 신경망 실습\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHS_DpgSQzEV"
      },
      "source": [
        "**\"Fashion MNIST\"**는 \"손글씨 MNIST\"와 더불어 신경망으로 이미지 분류 실습을 해볼 수 있는 대표적인 예제입니다.<br/>\n",
        "Fashion MNIST 예제를 통해 이미지 분류 문제에서 **어떤 전처리 과정이 필요한지, 신경망은 어떻게 구축되어야 하고 학습되는지**에 대해 알아보겠습니다.\n",
        "\n",
        "전체적인 과정은 위와 유사합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRCKf3UQmhfx"
      },
      "source": [
        "1. **학습 데이터를 불러옵니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvL1q_hTQ1KV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd60a43-2c5d-4072-8c0d-c1e4de91aa1a"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# 데이터 불러오기\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IdUpZNimqm8"
      },
      "source": [
        "2. **불러온 학습 데이터가 어떻게 생겼는지, 혹은 어떤 레이블(label)을 갖는지 확인해보고 정규화합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP_qZpgcQ1H0"
      },
      "source": [
        "# 데이터를 정규화 합니다\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test /255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYXQ2kx6Q1Fm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "76201399-d532-458f-ff20-83193bf4b3ef"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(9):\n",
        "    # subplot 정의\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    \n",
        "    # 데이터를 plot 합니다.\n",
        "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "    \n",
        "plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSI1r9wvQ0mk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd236a51-c50c-4734-bfb8-d753323e73c4"
      },
      "source": [
        "# 클래스를 확인합니다.\n",
        "np.unique(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXQsItuemgXp"
      },
      "source": [
        "3. **필요한 라이브러리를 불러온 후 신경망을 구축하고 컴파일(compile)합니다.**\n",
        "\n",
        "> ❗️ ***아래 코드에서 출력층의 노드 수는 몇 개인지, 출력층의 활성화 함수는 무엇인지, 손실 함수는 어떻게 지정하였는지에 주목해봅시다.<br/>\n",
        "`.summary()`를 활용하면 모델의 구조를 빠르게 파악해 볼 수 있습니다.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcnIMts_Q5Hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d08586e-c669-483d-d9b9-05ef1cf2c9d3"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "\n",
        "model = Sequential() \n",
        "model.add(Flatten(input_shape=(28, 28))) # 28*28 = 784 특성 벡터로 펼쳐 변환해 Dense 층으로 들어갑니다\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam'\n",
        "             , loss='sparse_categorical_crossentropy'\n",
        "             , metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "# 총 7850 parameters (10 bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmgYV_rNnLbh"
      },
      "source": [
        "> ❗️ ***위 모델의 파라미터 수는 총 7,850개입니다. 왜 7,850개가 될 지에 대해 생각해봅시다.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEIGcMEBQ6-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b0a6aa-ac0e-4385-f1fd-8e87daa4d71d"
      },
      "source": [
        "# 모델 학습\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test,y_test))\n",
        "# model.fit(X_train, y_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6010 - accuracy: 0.7971 - val_loss: 0.5208 - val_accuracy: 0.8167\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4616 - accuracy: 0.8427 - val_loss: 0.4759 - val_accuracy: 0.8338\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4355 - accuracy: 0.8510 - val_loss: 0.4702 - val_accuracy: 0.8347\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4223 - accuracy: 0.8538 - val_loss: 0.4745 - val_accuracy: 0.8318\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4153 - accuracy: 0.8570 - val_loss: 0.4580 - val_accuracy: 0.8383\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4072 - accuracy: 0.8599 - val_loss: 0.4736 - val_accuracy: 0.8383\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4035 - accuracy: 0.8599 - val_loss: 0.4466 - val_accuracy: 0.8481\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3974 - accuracy: 0.8624 - val_loss: 0.4552 - val_accuracy: 0.8424\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3945 - accuracy: 0.8635 - val_loss: 0.4425 - val_accuracy: 0.8454\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3930 - accuracy: 0.8635 - val_loss: 0.4513 - val_accuracy: 0.8429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9266bda550>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXPdYBdgQ9Yr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff83f0fe-22a2-49c8-a764-e0f39d7ae882"
      },
      "source": [
        "# 예측\n",
        "model.predict(X_test[0:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.62648438e-07, 1.74089614e-08, 1.51180375e-05, 3.10818064e-06,\n",
              "        4.04791763e-06, 5.53222373e-02, 3.58409670e-05, 3.93314958e-02,\n",
              "        6.38620043e-03, 8.98901403e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63o3zxMHQ-xt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c38404-6f00-40ab-a618-9dedc28345b7"
      },
      "source": [
        "# 테스트 데이터 예측 정확도\n",
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 0s - loss: 0.4513 - accuracy: 0.8429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46QaqNEyOSNm"
      },
      "source": [
        "## 🧐  Review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD89MRJBOU4s"
      },
      "source": [
        "- 처음에 말씀드린 것처럼 오늘 배운 역전파와 경사 하강법은 신경망을 처음 공부할 때 대부분이 가장 어려워 하는 부분입니다.<br/>\n",
        "한 번에 이해가 되지 않는 부분이기 때문에 많은 자료를 찾아보고 처음에는 여러분의 언어로 이해를 해보는 것이 중요합니다.\n",
        "\n",
        "    대략적인 과정은 아래와 같습니다.\n",
        "\n",
        "    1. 신경망(Neural Network)에서 사용할 초기 가중치(파라미터,parameter)를 임의로 설정합니다.\n",
        "    2. 설정한 파라미터를 이용하여 입력 데이터를 신경망에 넣은 후 **<font color=\"ff6f61\">순전파 과정을 거쳐 출력값(Output)을 얻습니다.</font>**\n",
        "    3. 출력값과 타겟(Target, Label)을 비교하여 **<font color=\"ff6f61\">손실(Loss)를 계산</font>**합니다.\n",
        "    4. 손실(Loss)의 Gradient를 계산하여 **<font color=\"ff6f61\">Gradient가 줄어드는 방향으로 가중치를 업데이트</font>**합니다.<br/>\n",
        "    이 때 각 가중치의 Gradient를 계산할 수 있도록 **<font color=\"ff6f61\">손실 정보를 전달하는 과정을 역전파(Backpropagation)</font>**이라고 합니다.\n",
        "    5. 얼마만큼의 데이터를 사용하여 가중치를 어떻게 업데이트 할 지를 결정합니다.<br/>\n",
        "    이를 **<font color=\"ff6f61\">옵티마이저(Optimizer)</font>**라는 하이퍼파라미터로 정해줍니다. (Stochastic or Batch 등...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BBjN1-a52EH"
      },
      "source": [
        "### 🔝 References\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U8M_9dgOPJ6"
      },
      "source": [
        "- [backpropagation example](https://www.youtube.com/watch?v=0e0z28wAWfg)\n",
        "- [Neural network learning by Andrew Ng](https://www.coursera.org/learn/machine-learning/lecture/Wh6s3/putting-it-together)\n",
        "- [An overview of gradient descent optimization algorithms](https://ruder.io/optimizing-gradient-descent/)\n",
        "\n",
        "다음으로는 경사하강법의 변형 중 한 방법인 뉴턴 메소드를 사용한 BFGS(Broyden–Fletcher–Goldfarb–Shanno) 방법을 적용한 신경망으로 학습을 진행해 보겠습니다. (코드 와 설명은 [welch lab](\"https://github.com/stephencwelch/Neural-Networks-Demystified/blob/master/Part%206%20Training.ipynb\") 에서 확인 가능합니다.)"
      ]
    }
  ]
}