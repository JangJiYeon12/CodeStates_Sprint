{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "P41_NLP",
      "language": "python",
      "name": "p41_nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "n412-vectorization-of-texts.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2shgXaGhA1H"
      },
      "source": [
        "<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / NOTE 2*\n",
        "\n",
        "---\n",
        "\n",
        "# Text Vectorization & Documents Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWJIs-m6cZus"
      },
      "source": [
        "# 🏆 학습목표"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfDrzKrHhA1W"
      },
      "source": [
        "* 텍스트 문서를 벡터로 표현해 봅시다\n",
        "* 유사도를 이용해 문서를 검색해 봅시다\n",
        "* 텍스트에서 특성을 추출하고 문서 분류기를 만들 수 있습니다\n",
        "* 잠재의미분석(Latent Semantic Analysis,LSA)을 수행합니다\n",
        "* Spacy 단어 임베딩을 사용합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRFs_igVhA1W"
      },
      "source": [
        "## Warm up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AK8K-Yseiz-"
      },
      "source": [
        "### TF-IDF\n",
        "\n",
        "다음 동영상을 시청하세요.\n",
        "- [TF-IDF](https://www.youtube.com/watch?v=meEchvkdB1U&feature=youtu.be)\n",
        "  - TF스코어는 어떤 스코어 일까요? \n",
        "  - 왜 IDF 스코어를 추가로 고려할까요? \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NS02N-dgN1i"
      },
      "source": [
        "### SVD\n",
        "다음 동영상을 시청하세요.\n",
        "- [특이값 분해(SVD)의 기하학적 의미와 활용 소개](https://youtu.be/cq5qlYtnLoY)\n",
        "    - 우리는 SVD를 통해 무엇을 얻고자 하는 것일까요?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE1hCjhjitji"
      },
      "source": [
        "### TEXT 분류\n",
        "다음 웹페이지를 읽어보세요. \n",
        "- [Text classification](https://developers.google.com/machine-learning/guides/text-classification)\n",
        "    - Introduction\n",
        "    - Step 1: Gather Data\n",
        "    - Step 2: Explore Your Data\n",
        "    - Step 2.5: Choose a Model\n",
        "    - Step 3: Prepare Your Data\n",
        "\n",
        "전체적인 시각을 늘리는 것이 중요합니다. \n",
        "<br> 페이지를 모두 이해해도 좋겠지만, 내가 앞으로 해나갈 일들을 멀리서 바라볼 수 있도록 준비해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKCHMkiNhA1X"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMP1QpY6hA1Y"
      },
      "source": [
        "## 텍스트 문서를 벡터로 표현해 봅시다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gyzYHuqdMcL"
      },
      "source": [
        "머신러닝 모델에서 텍스트를 사용하기 위해서는 텍스트 데이터를 벡터화해야 합니다. 이것은 텍스트를 컴퓨터가 사용할 수 있게 수치정보로 변환하는 것으로 생각할 수 있습니다. 지난 시간 단어들을 토큰화 했다면, 토큰화한 정보들을 컴퓨터의 언어체계 속으로 넣어준다는 개념으로 받아들이면 됩니다. \n",
        "\n",
        "Bag-of-Words(BoW) 개념은 우리가 사용하는 언어모델을 단순화 시킨 모델입니다. 문서, 문장들에서 문법, 즉 어떤 단어들의 순서 등의 개념을 제거하고 단순히 **단어들의 빈도**만 고려하는 모델입니다.\n",
        "\n",
        "BoW는 문서를 토큰화한 후 토큰의 빈도를 기반으로 벡터화 합니다. 데이터프레임 형태로 보자면 행은 각 문서가 되고 열은 중복되지 않는 각 단어가 됩니다. 열에는 단순히 각 단어가 문서에 얼마나 존재하는지를 카운트한 값을 넣거나(*CountVectorizer* 사용) TF-IDF 값이 오게 할 수 있습니다(*TfidfVectorizer 사용).\n",
        "\n",
        "벡터 표현은 파이썬에서는 `sklearn`, `spacy`패키지를 사용해 구현할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnkwcG3Xf6I2"
      },
      "source": [
        "### BBC Dataset\n",
        "\n",
        "이번 세션에서는 BBC에서 제공하는 데이터셋을 사용하여 텍스트를 다뤄볼 예정입니다. BBC 웹사이트를 방문하는 고객이 방금 읽은 뉴스(문서)를 기반으로 비슷한 다른 문서를 적절하게 추천하게 만들 수 있으면 좋겠죠. 그런 작업을 한번 시작해 봅니다. \n",
        "\n",
        "* 아래 링크에서 파일을 다운로드 받아 노트 폴더에서 압축을 해제합니다. <br> data folder가 생성되고 001.txt ~ 401.txt 파일이 있는지 확인합니다.\n",
        "* colab 유저들은 업로드 코드를 이용하여 업로드 후 unzip하여 파일을 풀면 사용할 수 있습니다.\n",
        "\n",
        "* [bbc_fulltext.zip](https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/bbc_fulltext/bbc_fulltext.zip)\n",
        "\n",
        "\n",
        "* 레퍼런스 - [BBC News Tech]('https://www.bbc.com/news/technology')\n",
        ", D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006. [논문링크](http://mlg.ucd.ie/datasets/bbc.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmN9EYHt54t9"
      },
      "source": [
        "# for Colab User\n",
        "# Upload files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!unzip \"bbc_fulltext.zip\" # 업로드 이름이 다르다면 수정해서 사용하세요."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2ZNkN-36qcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98db0a6-e003-43dd-85b7-7982365bf34d"
      },
      "source": [
        "# data 폴더가 제대로 생성되었는 지 확인합니다. \n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bbc_fulltext.zip  data\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW3iUy8nhA1Y"
      },
      "source": [
        "BoW를 사용해 Document Term Matrices(DTM, 문서-단어행렬)을 만들어 보겠습니다. 각 행은 문서를 나타내고 각 열은 단어를 나타냅니다.\n",
        "- 각 셀의 값은 여러가지 방법으로 표현될 수 있는데\n",
        "    - 단어의 출현 빈도를 나타내거나,\n",
        "    - 단순히 단어의 존재 유무(binary)를 표현할 수 있고,\n",
        "    - TF-IDF 값으로 나타낼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0UrJckqhA1Z"
      },
      "source": [
        "### spacy 예제\n",
        "**Spacy로 텍스트에서 토큰을 추출해 보겠습니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIshXRhDhA1Y"
      },
      "source": [
        "# 모듈에서 사용할 라이브러리와 spacy 모델을 불러옵니다.\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zl8SfWFhA1Z"
      },
      "source": [
        "# 예제로 사용할 Text를 선언합니다. \n",
        "text = \"In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general. tf–idf is one of the most popular term-weighting schemes today. A survey conducted in 2015 showed that 83% of text-based recommender systems in digital libraries use tf–idf.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMz6Z1FchA1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc676e0-f020-48fe-873b-eb266dbd2461"
      },
      "source": [
        "# spacy의 언어모델을 이용하여 token화된 단어들을 확인합니다. \n",
        "doc = nlp(text)\n",
        "print([token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['information', 'retrieval', 'tf', 'idf', 'TFIDF', 'short', 'term', 'frequency', 'inverse', 'document', 'frequency', 'numerical', 'statistic', 'intend', 'reflect', 'important', 'word', 'document', 'collection', 'corpus', 'weight', 'factor', 'search', 'information', 'retrieval', 'text', 'mining', 'user', 'modeling', 'tf', 'idf', 'value', 'increase', 'proportionally', 'number', 'time', 'word', 'appear', 'document', 'offset', 'number', 'document', 'corpus', 'contain', 'word', 'help', 'adjust', 'fact', 'word', 'appear', 'frequently', 'general', 'tf', 'idf', 'popular', 'term', 'weight', 'scheme', 'today', 'survey', 'conduct', '2015', 'show', '83', 'text', 'base', 'recommender', 'system', 'digital', 'library', 'use', 'tf', 'idf']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOWp3EEkhA1a"
      },
      "source": [
        "#### BBC Dataset에 적용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiPRiorSq29h"
      },
      "source": [
        "데이터를 축적하는 함수를 제작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJEsWTtvhA1a"
      },
      "source": [
        "# BBC 데이터를 불러오기 위한 함수\n",
        "import os \n",
        "\n",
        "def gather_data(filefolder):\n",
        "    \"\"\" 폴더 내 텍스트 파일을 각각 리스트 요소에 저장하는 함수\n",
        "    Args:\n",
        "        filefolder (str): .txt 파일이 존재하는 경로\n",
        "    Returns:\n",
        "        문서를 요소로하는 리스트\n",
        "    \"\"\"\n",
        "    \n",
        "    data = []\n",
        "    files = os.listdir(filefolder)\n",
        "    for article in files: \n",
        "        path = os.path.join(filefolder, article)\n",
        "        # txt로 끝나는 파일만 읽습니다\n",
        "        if  path[-3:] == 'txt':\n",
        "            # rb:Read the file in Binary mode\n",
        "            with open(path, 'rb') as f:\n",
        "                data.append(f.read())\n",
        "    \n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7i7-H9mhA1a"
      },
      "source": [
        "data = gather_data('./data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcFIgb8rhA1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd50361-3e1e-4f62-ddb7-8fac429dc1ad"
      },
      "source": [
        "# 샘플 확인\n",
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Joke e-mail virus tricks users\\n\\nA virus that disguises itself as a joke is spreading rapidly across the net.\\n\\nAnti-virus firms are issuing high-level warnings about the new version of the Bagle e-mail program that seems to be catching a lot of people out. The Windows virus grabs e-mail addresses from Microsoft Outlook and uses its own mail sending software to spread itself to new victims. When it infects a machine, the Bagle variant turns off security measures that usually protect PCs.\\n\\nThe new variant is called Bagle.AT, Bagle.BB and Bagle.AU and the attachment bearing the virus code is labelled as either \"joke\" or \"price\".\\n\\nThe body of the virus usually contains nothing but a smiley or emoticon. The virus can strike computers running Windows 95, 98, ME, NT, 2000 and XP. Users will be infected if they open the attachment that travels with the e-mail. As well as plundering Microsoft Outlook for e-mail addresses to send itself to, Bagle.AT also tries to turn off the firewall and security centre services on Windows XP machines. BBC News Online has received five warnings about the virus from security companies. Finnish company F-Secure gave the virus its second highest threat level. \"We\\'ve had several reports all over the world,\" said Mikko Hypponen, director of anti-virus research for F-Secure. Security firm Network Box said that it stopped more than 30,000 copies an hour of the virus as the outbreak reached a peak. Black Spider said it had stopped more than 1 million copies of Bagle.AT since the outbreak began at 0630 BST (0530 GMT). Anti-virus firms urged users to be wary of unexpected e-mail messages bearing attachments and to update their software to ensure they are protected against the latest threats.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwyREcsrrQMH"
      },
      "source": [
        "문서별 단어의 수 분포도를 그려봅니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ineq4LzfhA1b"
      },
      "source": [
        "import seaborn as sns\n",
        "# plot 스타일과 폰트 크기를 설정합니다.\n",
        "sns.set(style='whitegrid', font_scale=1.15)\n",
        "\n",
        "# 문서별 단어의 수 분포도 그리는 함수\n",
        "def plot_text_length_dist(text_list):\n",
        "\n",
        "    # 문장이 요소인 리스트를 받아 각 문서의 단어 수를 가진 리스트를 만듭니다\n",
        "    num_words = [len(doc.split()) for doc in text_list]\n",
        "    \n",
        "    sns.displot(num_words)\n",
        "    plt.title('# of words per documents')\n",
        "    plt.xlabel('Number of words')\n",
        "    plt.ylabel('Number of documents')\n",
        "    plt.show()       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juxrcqHDhA1b"
      },
      "source": [
        "대략 500 단어 정도로 표현된 문서가 가장 많이 보입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riyI9CVThA1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "fb4ed304-3228-459a-a12f-850b1a272846"
      },
      "source": [
        "plot_text_length_dist(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iW_tDfwhA1c"
      },
      "source": [
        "### CountVectorizer 예제\n",
        ": 단어들의 출현 빈도로 여러개의 문서를 벡터화하는 함수 <br>\n",
        ": 모든 문자를 소문자로 전환하여 계산함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQpwlq6ghA1c"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# wiki 문장들을 리스트에 나누어 입력해봅니다. \n",
        "text = [\"In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\"\n",
        ",\"It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling.\"\n",
        ",\"The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.\"\n",
        ",\"tf–idf is one of the most popular term-weighting schemes today.\"\n",
        ",\"A survey conducted in 2015 showed that 83% of text-based recommender systems in digital libraries use tf–idf.\"]\n",
        "\n",
        "# CountVectorizer 생성\n",
        "vect = CountVectorizer()\n",
        "\n",
        "# text를 기반으로 어휘 사전을 생성\n",
        "vect.fit(text) \n",
        "# vect.fit(data[:5])\n",
        "\n",
        "# text를 DTM(document-term matrix)으로 변환(transform)\n",
        "dtm = vect.transform(text)\n",
        "# dtm = vect.transform(data[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYo0jODwhA1c"
      },
      "source": [
        "vocabulary(모든 토큰)와 맵핑된 인덱스 정보를 확인할 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1EtyoQchA1c"
      },
      "source": [
        "vect.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZLNl0pUhA1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b01ec8-6032-4eba-876f-bb63a626e559"
      },
      "source": [
        "dtm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj4dr7UvhA1d"
      },
      "source": [
        "추출된 토큰을 나열해 봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_034SHvhA1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb7971d1-4993-4d8b-82df-e2b9ea2e0cbc"
      },
      "source": [
        "print(vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['2015', '83', 'adjust', 'and', 'appear', 'appears', 'as', 'based', 'by', 'collection', 'conducted', 'contain', 'corpus', 'digital', 'document', 'documents', 'fact', 'factor', 'for', 'frequency', 'frequently', 'general', 'helps', 'how', 'idf', 'important', 'in', 'increases', 'information', 'intended', 'inverse', 'is', 'it', 'libraries', 'mining', 'modeling', 'more', 'most', 'number', 'numerical', 'of', 'offset', 'often', 'one', 'or', 'popular', 'proportionally', 'recommender', 'reflect', 'retrieval', 'schemes', 'searches', 'short', 'showed', 'some', 'statistic', 'survey', 'systems', 'term', 'text', 'tf', 'tfidf', 'that', 'the', 'times', 'to', 'today', 'use', 'used', 'user', 'value', 'weighting', 'which', 'word', 'words']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo8ojHRBhA1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5fa252-0651-4fac-9fed-b12f5d1b66b8"
      },
      "source": [
        "text[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Mobiles rack up 20 years of use\\n\\nMobile phones in the UK are celebrating their 20th anniversary this weekend.\\n\\nBritain\\'s first mobile phone call was made across the Vodafone network on 1 January 1985 by veteran comedian Ernie Wise. In the 20 years since that day, mobile phones have become an integral part of modern life and now almost 90% of Britons own a handset. Mobiles have become so popular that many people use their handset as their only phone and rarely use a landline.\\n\\nThe first ever call over a portable phone was made in 1973 in New York but it took 10 years for the first commercial mobile service to be launched. The UK was not far behind the rest of the world in setting up networks in 1985 that let people make calls while they walked. The first call was made from St Katherine\\'s dock to Vodafone\\'s head office in Newbury which at the time was over a curry house. For the first nine days of 1985 Vodafone was the only firm with a mobile network in the UK. Then on 10 January Cellnet (now O2) launched its service. Mike Caudwell, spokesman for Vodafone, said that when phones were launched they were the size of a briefcase, cost about \\xc2\\xa32,000 and had a battery life of little more than 20 minutes.\\n\\n\"Despite that they were hugely popular in the mid-80s,\" he said. \"They became a yuppy must-have and a status symbol among young wealthy business folk.\" This was also despite the fact that the phones used analogue radio signals to communicate which made them very easy to eavesdrop on. He said it took Vodafone almost nine years to rack up its first million customers but only 18 months to get the second million. \"It\\'s very easy to forget that in 1983 when we put the bid document in we were forecasting that the total market would be two million people,\" he said. \"Cellnet was forecasting half that.\" Now Vodafone has 14m customers in the UK alone. Cellnet and Vodafone were the only mobile phone operators in the UK until 1993 when One2One (now T-Mobile) was launched. Orange had its UK launch in 1994. Both newcomers operated digital mobile networks and now all operators use this technology. The analogue spectrum for the old phones has been retired. Called Global System for Mobiles (GSM) this is now the most widely used phone technology on the planet and is used to help more than 1.2 billion people make calls. Mr Caudwell said the advent of digital technology also helped to introduce all those things, such as text messaging and roaming that have made mobiles so popular.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUj5YBA0hA1d"
      },
      "source": [
        "dtm의 타입을 보면 compressed sparse Row matrix임을 알 수 있습니다. <br> csr: Compressed Sparse Row matrix, sparse matrix 형태에서 0을 표현하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EonNdMuvhA1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8686bc2a-a8f1-4a3e-e8c6-8c5503a88d1d"
      },
      "source": [
        "# CountVectorizer 로 제작한 dtm을 분석\n",
        "type(dtm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j_S9jAYhA1e"
      },
      "source": [
        "# (row, column)  count\n",
        "print(dtm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcfHPTRrhA1e"
      },
      "source": [
        "0을 표현한 형태로 만들면 .todense를 사용할 수 있고, 이런경우 numpy.matrix형태가 됩니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz3m9i8ahA1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc0d265-e748-4781-9a58-eb22d9f38498"
      },
      "source": [
        "# Return a dense matrix representation\n",
        "# dtm.todense()\n",
        "print(type(dtm))\n",
        "print(type(dtm.todense()))\n",
        "dtm.todense()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "<class 'numpy.matrix'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZaCXze6hA1e"
      },
      "source": [
        "데이터프레임 형태로 결과를 보고 싶다면"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5h5m4FHhA1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "785d5c53-9891-45a9-a562-28d2c6ed59e6"
      },
      "source": [
        "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
        "print(type(dtm))\n",
        "dtm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2015</th>\n",
              "      <th>83</th>\n",
              "      <th>adjust</th>\n",
              "      <th>and</th>\n",
              "      <th>appear</th>\n",
              "      <th>appears</th>\n",
              "      <th>as</th>\n",
              "      <th>based</th>\n",
              "      <th>by</th>\n",
              "      <th>collection</th>\n",
              "      <th>conducted</th>\n",
              "      <th>contain</th>\n",
              "      <th>corpus</th>\n",
              "      <th>digital</th>\n",
              "      <th>document</th>\n",
              "      <th>documents</th>\n",
              "      <th>fact</th>\n",
              "      <th>factor</th>\n",
              "      <th>for</th>\n",
              "      <th>frequency</th>\n",
              "      <th>frequently</th>\n",
              "      <th>general</th>\n",
              "      <th>helps</th>\n",
              "      <th>how</th>\n",
              "      <th>idf</th>\n",
              "      <th>important</th>\n",
              "      <th>in</th>\n",
              "      <th>increases</th>\n",
              "      <th>information</th>\n",
              "      <th>intended</th>\n",
              "      <th>inverse</th>\n",
              "      <th>is</th>\n",
              "      <th>it</th>\n",
              "      <th>libraries</th>\n",
              "      <th>mining</th>\n",
              "      <th>modeling</th>\n",
              "      <th>more</th>\n",
              "      <th>most</th>\n",
              "      <th>number</th>\n",
              "      <th>numerical</th>\n",
              "      <th>of</th>\n",
              "      <th>offset</th>\n",
              "      <th>often</th>\n",
              "      <th>one</th>\n",
              "      <th>or</th>\n",
              "      <th>popular</th>\n",
              "      <th>proportionally</th>\n",
              "      <th>recommender</th>\n",
              "      <th>reflect</th>\n",
              "      <th>retrieval</th>\n",
              "      <th>schemes</th>\n",
              "      <th>searches</th>\n",
              "      <th>short</th>\n",
              "      <th>showed</th>\n",
              "      <th>some</th>\n",
              "      <th>statistic</th>\n",
              "      <th>survey</th>\n",
              "      <th>systems</th>\n",
              "      <th>term</th>\n",
              "      <th>text</th>\n",
              "      <th>tf</th>\n",
              "      <th>tfidf</th>\n",
              "      <th>that</th>\n",
              "      <th>the</th>\n",
              "      <th>times</th>\n",
              "      <th>to</th>\n",
              "      <th>today</th>\n",
              "      <th>use</th>\n",
              "      <th>used</th>\n",
              "      <th>user</th>\n",
              "      <th>value</th>\n",
              "      <th>weighting</th>\n",
              "      <th>which</th>\n",
              "      <th>word</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   2015  83  adjust  and  appear  ...  value  weighting  which  word  words\n",
              "0     0   0       0    0       0  ...      0          0      0     1      0\n",
              "1     0   0       0    1       0  ...      0          1      0     0      0\n",
              "2     0   0       1    1       1  ...      1          0      1     2      1\n",
              "3     0   0       0    0       0  ...      0          1      0     0      0\n",
              "4     1   1       0    0       0  ...      0          0      0     0      0\n",
              "\n",
              "[5 rows x 75 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGuj6KyThA1e"
      },
      "source": [
        "세번째 문장과, dtm을 비교해 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd-D524WhA1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4c93c8bc-47d3-4dee-e57d-00704a2c88df"
      },
      "source": [
        "text[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAzTOSWOhA1f"
      },
      "source": [
        "#### BBC dataset에 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9pVcwbRhA1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64605ba0-f22b-4c6c-9909-6b4b9d60e61f"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "## stop_words = 'english' 영어에 해당하는 불용어 처리를 합니다.\n",
        "## max_features=n, 빈도 순서대로 top n 단어만 사용합니다.\n",
        "vect = CountVectorizer(stop_words='english'\n",
        "                       , max_features=10000)\n",
        "# fit & transform\n",
        "dtm = vect.fit_transform(data)\n",
        "\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
        "dtm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(401, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsgyNcfHhA1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "5226fdb5-4cc6-4d86-90f5-25b6001d2c7f"
      },
      "source": [
        "dtm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>000s</th>\n",
              "      <th>0051</th>\n",
              "      <th>007</th>\n",
              "      <th>01</th>\n",
              "      <th>028</th>\n",
              "      <th>04m</th>\n",
              "      <th>05</th>\n",
              "      <th>0530</th>\n",
              "      <th>056</th>\n",
              "      <th>0630</th>\n",
              "      <th>080</th>\n",
              "      <th>0800</th>\n",
              "      <th>0870</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>100m</th>\n",
              "      <th>100s</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>104</th>\n",
              "      <th>106</th>\n",
              "      <th>106cm</th>\n",
              "      <th>1080</th>\n",
              "      <th>10cm</th>\n",
              "      <th>10m</th>\n",
              "      <th>10s</th>\n",
              "      <th>10th</th>\n",
              "      <th>10x7in</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>115</th>\n",
              "      <th>117</th>\n",
              "      <th>11b</th>\n",
              "      <th>11m</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>120bn</th>\n",
              "      <th>...</th>\n",
              "      <th>yeob</th>\n",
              "      <th>yepp</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yeun</th>\n",
              "      <th>yh</th>\n",
              "      <th>yle</th>\n",
              "      <th>yoda</th>\n",
              "      <th>yoga</th>\n",
              "      <th>yonca</th>\n",
              "      <th>yoran</th>\n",
              "      <th>york</th>\n",
              "      <th>yorker</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youngsters</th>\n",
              "      <th>youth</th>\n",
              "      <th>yuppy</th>\n",
              "      <th>yusuf</th>\n",
              "      <th>zafi</th>\n",
              "      <th>zander</th>\n",
              "      <th>zar</th>\n",
              "      <th>zdnet</th>\n",
              "      <th>zealous</th>\n",
              "      <th>zed</th>\n",
              "      <th>zelda</th>\n",
              "      <th>zen</th>\n",
              "      <th>zenith</th>\n",
              "      <th>zens</th>\n",
              "      <th>zero</th>\n",
              "      <th>zhang</th>\n",
              "      <th>zip</th>\n",
              "      <th>zodiac</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombies</th>\n",
              "      <th>zone</th>\n",
              "      <th>zonealarm</th>\n",
              "      <th>zones</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zooms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   00  000  000s  0051  007  01  ...  zombies  zone  zonealarm  zones  zoom  zooms\n",
              "0   0    1     0     0    0   0  ...        0     0          0      0     0      0\n",
              "1   0    0     0     0    0   0  ...        0     0          0      0     0      0\n",
              "2   0    1     0     0    0   0  ...        0     0          0      0     0      0\n",
              "3   0    0     0     0    0   0  ...        0     0          0      0     0      0\n",
              "4   0    1     0     0    0   0  ...        0     0          0      0     0      0\n",
              "\n",
              "[5 rows x 10000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp_BuYEYhA1f"
      },
      "source": [
        "### TfidfVectorizer 예제\n",
        "\n",
        "Term Frequency - Inverse Document Frequency ([TF-IDF](https://mungingdata.wordpress.com/2017/11/25/episode-1-using-tf-idf-to-identify-the-signal-from-the-noise/), 단어빈도-역문서빈도)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFv0E6ZIhA1g"
      },
      "source": [
        "Warmup 보았던 영상의 내용을 정리해봅시다. \n",
        "\n",
        "-  TF(Term Frequency, 단어의 빈도) : 문서에서 단어가 많이 등장하는 지를 수치화한 중요도 스코어(score)\n",
        " <br> **특정 문서 d에서 특정 단어 t가 쓰인 빈도**:\n",
        "\n",
        "$\\large tf(t,d) = \\frac{Term\\; t\\; frequency\\; in\\; document}{Total\\; words\\; in\\; document}$\n",
        "\n",
        "`ex) \"A new car, used car, car reivew\" `\n",
        "  - TF score :  A($1 \\over 7$), new($1 \\over 7$), car($3 \\over 7$), used($1 \\over 7$), reivew($1 \\over 7$)  \n",
        "  - IDF - $log {(총 \\space 문장 \\space 개수) \\over {(단어가 \\space 출현한 \\space 문장의 \\space 개수)}}$\n",
        "  $\\large idf(t) = log(\\frac{n}{1+df(t)})$\n",
        "<br></br>\n",
        "  \n",
        "`ex) 'A'가 모든 문장에서 등장 IDF = log(N/N) = 0`<br>\n",
        "\n",
        "- TF-IDF Score \n",
        "<br> $ = \\large tf(t,d) \\times idf(t)$\n",
        "  <br> (t=단어, d=문서, n=총 문서수*)\n",
        "\n",
        "`ex) TF-IDF score = TF * IDF = (1/7) * 0 = 0`\n",
        "\n",
        "\n",
        "TF-IDF 를 사용하는 이유는 문서를 구분하는데 어떤 단어가 중요한지(**unique**) 찾는 것 입니다.\n",
        "\n",
        "수식을 살펴보면, \n",
        "<br> 여러 문서에서 많이 등장하는 단어일 수록 중요도가 낮다고 판단하며(IDF), <br> 특정 문서에서만 자주 등장하는 단어는 중요도가 높다고 판단합니다(TF).\n",
        "\n",
        "TF-IDF를 통한 자연어 처리는 간단하고 빠르게 구현할 수 있으므로 좋은 Baseline으로 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg2e_5NZsbiv"
      },
      "source": [
        "#### TF-IDF vs Count vectorizer \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceXM5l7yhA1g"
      },
      "source": [
        "[1] TF-IDF(Tfidf) vectorizer를 생성하고 Document-Term Matrix (DTM)을 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhHOIOh_hA1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "dc2e0399-f06e-473f-a0c9-fe15ea269c31"
      },
      "source": [
        "# TF-IDF vectorizer. 테이블을 작게 만들기 위해 max_features=15로 제한하였습니다.\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=15)\n",
        "\n",
        "# Fit 후 dtm을 만듭니다.(문서, 단어마다 tf-idf 값을 계산합니다)\n",
        "dtm = tfidf.fit_transform(text)\n",
        "\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "dtm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>corpus</th>\n",
              "      <th>document</th>\n",
              "      <th>frequency</th>\n",
              "      <th>idf</th>\n",
              "      <th>information</th>\n",
              "      <th>number</th>\n",
              "      <th>recommender</th>\n",
              "      <th>reflect</th>\n",
              "      <th>retrieval</th>\n",
              "      <th>searches</th>\n",
              "      <th>term</th>\n",
              "      <th>text</th>\n",
              "      <th>tf</th>\n",
              "      <th>weighting</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.237982</td>\n",
              "      <td>0.475965</td>\n",
              "      <td>0.589946</td>\n",
              "      <td>0.166183</td>\n",
              "      <td>0.237982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.294973</td>\n",
              "      <td>0.237982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.237982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166183</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.237982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.425001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.425001</td>\n",
              "      <td>0.526778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.425001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.425001</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.276074</td>\n",
              "      <td>0.276074</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.192782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.684374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.192782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.552149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.404837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.579748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.404837</td>\n",
              "      <td>0.579748</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.372642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.661438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.533644</td>\n",
              "      <td>0.372642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     corpus  document  frequency  ...        tf  weighting      word\n",
              "0  0.237982  0.475965   0.589946  ...  0.166183   0.000000  0.237982\n",
              "1  0.000000  0.000000   0.000000  ...  0.000000   0.425001  0.000000\n",
              "2  0.276074  0.276074   0.000000  ...  0.192782   0.000000  0.552149\n",
              "3  0.000000  0.000000   0.000000  ...  0.404837   0.579748  0.000000\n",
              "4  0.000000  0.000000   0.000000  ...  0.372642   0.000000  0.000000\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqNXLX1yhA1h"
      },
      "source": [
        "[2] 같은 파라미터로 CountVectorizer를 사용해 tfidf 결과와 비교해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfy8eVKOhA1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "d24488e0-5110-4f57-e010-ed24316a15a7"
      },
      "source": [
        "vect = CountVectorizer(stop_words='english', max_features=15)\n",
        "dtm = vect.fit_transform(text)\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
        "dtm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>corpus</th>\n",
              "      <th>document</th>\n",
              "      <th>frequency</th>\n",
              "      <th>idf</th>\n",
              "      <th>information</th>\n",
              "      <th>number</th>\n",
              "      <th>recommender</th>\n",
              "      <th>reflect</th>\n",
              "      <th>retrieval</th>\n",
              "      <th>searches</th>\n",
              "      <th>term</th>\n",
              "      <th>text</th>\n",
              "      <th>tf</th>\n",
              "      <th>weighting</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   corpus  document  frequency  idf  ...  text  tf  weighting  word\n",
              "0       1         2          2    1  ...     0   1          0     1\n",
              "1       0         0          0    0  ...     1   0          1     0\n",
              "2       1         1          0    1  ...     0   1          0     2\n",
              "3       0         0          0    1  ...     0   1          1     0\n",
              "4       0         0          0    1  ...     1   1          0     0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7nUg4rphA1h"
      },
      "source": [
        "#### BBC Dataset에 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHnIK0uqhA1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "6cc7c1fa-1bd3-49a7-ea10-92f016eba9b2"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "dtm = tfidf.fit_transform(data)\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "\n",
        "dtm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>104</th>\n",
              "      <th>10m</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>13</th>\n",
              "      <th>130</th>\n",
              "      <th>14</th>\n",
              "      <th>149</th>\n",
              "      <th>15</th>\n",
              "      <th>150</th>\n",
              "      <th>16</th>\n",
              "      <th>167</th>\n",
              "      <th>17</th>\n",
              "      <th>17m</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>1980s</th>\n",
              "      <th>1982</th>\n",
              "      <th>1983</th>\n",
              "      <th>1985</th>\n",
              "      <th>1990s</th>\n",
              "      <th>1993</th>\n",
              "      <th>1994</th>\n",
              "      <th>1995</th>\n",
              "      <th>1bn</th>\n",
              "      <th>1m</th>\n",
              "      <th>20</th>\n",
              "      <th>200</th>\n",
              "      <th>2000</th>\n",
              "      <th>2001</th>\n",
              "      <th>2002</th>\n",
              "      <th>2003</th>\n",
              "      <th>2004</th>\n",
              "      <th>2005</th>\n",
              "      <th>2006</th>\n",
              "      <th>...</th>\n",
              "      <th>worry</th>\n",
              "      <th>worrying</th>\n",
              "      <th>worse</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>worthwhile</th>\n",
              "      <th>wouldn</th>\n",
              "      <th>wow</th>\n",
              "      <th>wright</th>\n",
              "      <th>wristwatch</th>\n",
              "      <th>write</th>\n",
              "      <th>writer</th>\n",
              "      <th>writers</th>\n",
              "      <th>writing</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrongful</th>\n",
              "      <th>wrote</th>\n",
              "      <th>wsis</th>\n",
              "      <th>x1</th>\n",
              "      <th>xbox</th>\n",
              "      <th>xenon</th>\n",
              "      <th>xp</th>\n",
              "      <th>xxx</th>\n",
              "      <th>yahoo</th>\n",
              "      <th>yang</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yen</th>\n",
              "      <th>yes</th>\n",
              "      <th>yoda</th>\n",
              "      <th>yoran</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youngsters</th>\n",
              "      <th>youth</th>\n",
              "      <th>zafi</th>\n",
              "      <th>zen</th>\n",
              "      <th>zombies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.026072</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.051915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.102341</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.066212</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.034386</td>\n",
              "      <td>0.079190</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.087326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027346</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.028940</td>\n",
              "      <td>0.066646</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045824</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.073493</td>\n",
              "      <td>0.241386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071006</td>\n",
              "      <td>0.067081</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122338</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.123824</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05528</td>\n",
              "      <td>0.058505</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        000        10  100  101  104  ...  youngsters  youth  zafi  zen  zombies\n",
              "0  0.026072  0.000000  0.0  0.0  0.0  ...         0.0    0.0   0.0  0.0      0.0\n",
              "1  0.000000  0.000000  0.0  0.0  0.0  ...         0.0    0.0   0.0  0.0      0.0\n",
              "2  0.034386  0.079190  0.0  0.0  0.0  ...         0.0    0.0   0.0  0.0      0.0\n",
              "3  0.000000  0.000000  0.0  0.0  0.0  ...         0.0    0.0   0.0  0.0      0.0\n",
              "4  0.028940  0.066646  0.0  0.0  0.0  ...         0.0    0.0   0.0  0.0      0.0\n",
              "\n",
              "[5 rows x 5000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoiVe1n7hA1h"
      },
      "source": [
        "#### 파라미터 튜닝\n",
        "\n",
        "> 이번에는 조금 더 파라미터를 튜닝하고, spacy tokenizer 를 사용해서 벡터화를 진행해 보겠습니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Oq9Yq4hA1i"
      },
      "source": [
        "# spacy tokenizer 함수\n",
        "def tokenize(document):\n",
        "    \n",
        "    doc = nlp(document)\n",
        "    # punctuations: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True) and (token.is_alpha == True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wOsy1gVhA1i"
      },
      "source": [
        "파라미터 튜닝을 더 해보겠습니다. 여러 파라미터들을 변경해 가며 결과를 비교해 보십시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa8za2l8hA1i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "e85dc98b-51fa-4950-9361-78903c8b50d6"
      },
      "source": [
        "# ngram_range = (min_n, max_n), min_n 개~ max_n 개를 갖는 n-gram(n개의 연속적인 토큰)을 토큰으로 사용합니다.\n",
        "# min_df = n, 최소 n개의 문서에 나타나는 토큰만 사용합니다\n",
        "# max_df = .7, 70% 이상 문서에 나타나는 토큰은 제거합니다\n",
        "tfidf = TfidfVectorizer(stop_words='english'\n",
        "                        ,tokenizer=tokenize\n",
        "                        ,ngram_range=(1,2)\n",
        "                        ,max_df=.7\n",
        "                        ,min_df=3\n",
        "#                         ,max_features = 4000\n",
        "                       )\n",
        "\n",
        "dtm = tfidf.fit_transform(data)\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "dtm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-PRON-</th>\n",
              "      <th>abandon</th>\n",
              "      <th>ability</th>\n",
              "      <th>ability record</th>\n",
              "      <th>able</th>\n",
              "      <th>able access</th>\n",
              "      <th>able choose</th>\n",
              "      <th>able control</th>\n",
              "      <th>able handle</th>\n",
              "      <th>able offer</th>\n",
              "      <th>able play</th>\n",
              "      <th>able store</th>\n",
              "      <th>able thing</th>\n",
              "      <th>able use</th>\n",
              "      <th>able watch</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absorb</th>\n",
              "      <th>abuse</th>\n",
              "      <th>academic</th>\n",
              "      <th>academy</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>acceptance</th>\n",
              "      <th>access</th>\n",
              "      <th>access available</th>\n",
              "      <th>access datum</th>\n",
              "      <th>access device</th>\n",
              "      <th>access e</th>\n",
              "      <th>access grow</th>\n",
              "      <th>access home</th>\n",
              "      <th>access information</th>\n",
              "      <th>access internet</th>\n",
              "      <th>access medium</th>\n",
              "      <th>access mobile</th>\n",
              "      <th>access net</th>\n",
              "      <th>access point</th>\n",
              "      <th>access service</th>\n",
              "      <th>accessible</th>\n",
              "      <th>accident</th>\n",
              "      <th>acclaim</th>\n",
              "      <th>...</th>\n",
              "      <th>year launch</th>\n",
              "      <th>year microsoft</th>\n",
              "      <th>year million</th>\n",
              "      <th>year motorola</th>\n",
              "      <th>year new</th>\n",
              "      <th>year number</th>\n",
              "      <th>year old</th>\n",
              "      <th>year people</th>\n",
              "      <th>year portable</th>\n",
              "      <th>year predict</th>\n",
              "      <th>year real</th>\n",
              "      <th>year release</th>\n",
              "      <th>year report</th>\n",
              "      <th>year say</th>\n",
              "      <th>year service</th>\n",
              "      <th>year think</th>\n",
              "      <th>year time</th>\n",
              "      <th>year uk</th>\n",
              "      <th>year use</th>\n",
              "      <th>year year</th>\n",
              "      <th>yen</th>\n",
              "      <th>yepp</th>\n",
              "      <th>yes</th>\n",
              "      <th>york</th>\n",
              "      <th>york base</th>\n",
              "      <th>york state</th>\n",
              "      <th>york times</th>\n",
              "      <th>young</th>\n",
              "      <th>young americans</th>\n",
              "      <th>young people</th>\n",
              "      <th>young user</th>\n",
              "      <th>youngster</th>\n",
              "      <th>youth</th>\n",
              "      <th>zelda</th>\n",
              "      <th>zen</th>\n",
              "      <th>zen micro</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombie bot</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.068952</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.074656</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024268</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.069914</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.052588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.049556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 7604 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   -PRON-  abandon   ability  ability record  ...  zombie  zombie bot  zone  zoom\n",
              "0     0.0      0.0  0.000000             0.0  ...     0.0         0.0   0.0   0.0\n",
              "1     0.0      0.0  0.000000             0.0  ...     0.0         0.0   0.0   0.0\n",
              "2     0.0      0.0  0.000000             0.0  ...     0.0         0.0   0.0   0.0\n",
              "3     0.0      0.0  0.024268             0.0  ...     0.0         0.0   0.0   0.0\n",
              "4     0.0      0.0  0.000000             0.0  ...     0.0         0.0   0.0   0.0\n",
              "\n",
              "[5 rows x 7604 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2fjGZhRhA1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72c1924-b80b-4e5d-dde3-334c1c34e184"
      },
      "source": [
        "dtm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(401, 7604)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76FurcFFhA1j"
      },
      "source": [
        "## 유사도를 이용해 문서를 검색해 봅시다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyZVc10EhA1j"
      },
      "source": [
        "네이버, 구글과 같은 검색엔진의 원리는 무엇입니까? \n",
        "<br> 검색어를 인터넷에 존재하는 여러 문서들과 단순히 같은지만 비교 하는것은 아닙니다. 쿼리와 문서들을 매칭(matching) 하는 방법은 여러가지가 있습니다. 그중 가장 클래식한 방법인 \"유사도 측정 방법\"을 시도해 봅니다. \n",
        "<br> 이를 위해 n-차원 거리를 사용하는 방법을 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "przZffV_hA1j"
      },
      "source": [
        "### 코사인 유사도(Cosine Similarity, Brute Force 방법)\n",
        "\n",
        "$\\Large similarity=cos(Θ)=\\frac{A⋅B}{||A||\\ ||B||}=\\frac{\\sum_{i=1}^{n}{A_{i}×B_{i}}}{\\sqrt{\\sum_{i=1}^{n}(A_{i})^2}×\\sqrt{\\sum_{i=1}^{n}(B_{i})^2}}$\n",
        "\n",
        "<img align=\"center\" src=\"https://images.deepai.org/glossary-terms/cosine-similarity-1007790.jpg\" width=700 title=\"Cosine Similarity\" alt=\"https://deepai.org/machine-learning-glossary-and-terms/cosine-similarity\">\n",
        "\n",
        "\n",
        "코사인 유사도는 두 벡터(문서벡터) 간의 각의 코사인 값을 이용하여 구할 수 있는 유사도 입니다.\n",
        "- 두 벡터(문서)가 \n",
        "    - 완전히 같을 경우 1이며\n",
        "    - 90도의 각을 이루면 0\n",
        "    - 완전히 반대방향을 이루면 -1 입니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nruxP2slhA1j"
      },
      "source": [
        "#### TF-IDF 벡터 거리\n",
        "TF-IDF 벡터들의 거리를 계산해 보겠습니다\n",
        "[sklearn.metrics.pairwise.cosine_similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html#sklearn-metrics-pairwise-cosine-similarity)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp6Jm7UfhA1j"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# input, X:(n_samples_X, n_features)\n",
        "distance_matrix  = cosine_similarity(dtm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9c8KIXUhA1k"
      },
      "source": [
        "df = pd.DataFrame(distance_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m_so22thA1k"
      },
      "source": [
        "유사도는 문서 x 문서 행렬로 표현됩니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNP1zFs2hA1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6c1104-3c34-4dc7-894a-c78dc8cf5ad0"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(401, 401)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMii6L8AhA1k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "26a2cf07-f90b-4c1c-8ff0-f7b82c5ffdfd"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>361</th>\n",
              "      <th>362</th>\n",
              "      <th>363</th>\n",
              "      <th>364</th>\n",
              "      <th>365</th>\n",
              "      <th>366</th>\n",
              "      <th>367</th>\n",
              "      <th>368</th>\n",
              "      <th>369</th>\n",
              "      <th>370</th>\n",
              "      <th>371</th>\n",
              "      <th>372</th>\n",
              "      <th>373</th>\n",
              "      <th>374</th>\n",
              "      <th>375</th>\n",
              "      <th>376</th>\n",
              "      <th>377</th>\n",
              "      <th>378</th>\n",
              "      <th>379</th>\n",
              "      <th>380</th>\n",
              "      <th>381</th>\n",
              "      <th>382</th>\n",
              "      <th>383</th>\n",
              "      <th>384</th>\n",
              "      <th>385</th>\n",
              "      <th>386</th>\n",
              "      <th>387</th>\n",
              "      <th>388</th>\n",
              "      <th>389</th>\n",
              "      <th>390</th>\n",
              "      <th>391</th>\n",
              "      <th>392</th>\n",
              "      <th>393</th>\n",
              "      <th>394</th>\n",
              "      <th>395</th>\n",
              "      <th>396</th>\n",
              "      <th>397</th>\n",
              "      <th>398</th>\n",
              "      <th>399</th>\n",
              "      <th>400</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014998</td>\n",
              "      <td>0.041514</td>\n",
              "      <td>0.035916</td>\n",
              "      <td>0.011299</td>\n",
              "      <td>0.021492</td>\n",
              "      <td>0.008861</td>\n",
              "      <td>0.019746</td>\n",
              "      <td>0.308156</td>\n",
              "      <td>0.019956</td>\n",
              "      <td>0.027771</td>\n",
              "      <td>0.020529</td>\n",
              "      <td>0.007588</td>\n",
              "      <td>0.045374</td>\n",
              "      <td>0.019767</td>\n",
              "      <td>0.047641</td>\n",
              "      <td>0.017975</td>\n",
              "      <td>0.019942</td>\n",
              "      <td>0.018530</td>\n",
              "      <td>0.034216</td>\n",
              "      <td>0.015849</td>\n",
              "      <td>0.055570</td>\n",
              "      <td>0.021976</td>\n",
              "      <td>0.035695</td>\n",
              "      <td>0.024257</td>\n",
              "      <td>0.012487</td>\n",
              "      <td>0.009431</td>\n",
              "      <td>0.028583</td>\n",
              "      <td>0.033699</td>\n",
              "      <td>0.031327</td>\n",
              "      <td>0.041125</td>\n",
              "      <td>0.023959</td>\n",
              "      <td>0.346372</td>\n",
              "      <td>0.097859</td>\n",
              "      <td>0.012726</td>\n",
              "      <td>0.020045</td>\n",
              "      <td>0.014379</td>\n",
              "      <td>0.030776</td>\n",
              "      <td>0.372439</td>\n",
              "      <td>0.210640</td>\n",
              "      <td>...</td>\n",
              "      <td>0.050091</td>\n",
              "      <td>0.035916</td>\n",
              "      <td>0.007387</td>\n",
              "      <td>0.291799</td>\n",
              "      <td>0.014685</td>\n",
              "      <td>0.031490</td>\n",
              "      <td>0.021084</td>\n",
              "      <td>0.118558</td>\n",
              "      <td>0.064996</td>\n",
              "      <td>0.021972</td>\n",
              "      <td>0.021492</td>\n",
              "      <td>0.080722</td>\n",
              "      <td>0.024713</td>\n",
              "      <td>0.024085</td>\n",
              "      <td>0.013938</td>\n",
              "      <td>0.018448</td>\n",
              "      <td>0.634388</td>\n",
              "      <td>0.030939</td>\n",
              "      <td>0.017447</td>\n",
              "      <td>0.014625</td>\n",
              "      <td>0.021464</td>\n",
              "      <td>0.038563</td>\n",
              "      <td>0.008291</td>\n",
              "      <td>0.052448</td>\n",
              "      <td>0.041029</td>\n",
              "      <td>0.026842</td>\n",
              "      <td>0.025648</td>\n",
              "      <td>0.005956</td>\n",
              "      <td>0.040467</td>\n",
              "      <td>0.034726</td>\n",
              "      <td>0.162121</td>\n",
              "      <td>0.229296</td>\n",
              "      <td>0.011844</td>\n",
              "      <td>0.018227</td>\n",
              "      <td>0.028107</td>\n",
              "      <td>0.011830</td>\n",
              "      <td>0.019738</td>\n",
              "      <td>0.013596</td>\n",
              "      <td>0.009184</td>\n",
              "      <td>0.052448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.014998</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.024811</td>\n",
              "      <td>0.036935</td>\n",
              "      <td>0.029222</td>\n",
              "      <td>0.221671</td>\n",
              "      <td>0.031656</td>\n",
              "      <td>0.036121</td>\n",
              "      <td>0.025296</td>\n",
              "      <td>0.043338</td>\n",
              "      <td>0.028627</td>\n",
              "      <td>0.040830</td>\n",
              "      <td>0.039587</td>\n",
              "      <td>0.039457</td>\n",
              "      <td>0.041103</td>\n",
              "      <td>0.022156</td>\n",
              "      <td>0.024584</td>\n",
              "      <td>0.036916</td>\n",
              "      <td>0.018690</td>\n",
              "      <td>0.085091</td>\n",
              "      <td>0.012136</td>\n",
              "      <td>0.016791</td>\n",
              "      <td>0.054708</td>\n",
              "      <td>0.042296</td>\n",
              "      <td>0.028373</td>\n",
              "      <td>0.190720</td>\n",
              "      <td>0.112254</td>\n",
              "      <td>0.009806</td>\n",
              "      <td>0.014573</td>\n",
              "      <td>0.021385</td>\n",
              "      <td>0.040554</td>\n",
              "      <td>0.054340</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>0.037784</td>\n",
              "      <td>0.033729</td>\n",
              "      <td>0.032849</td>\n",
              "      <td>0.040577</td>\n",
              "      <td>0.077081</td>\n",
              "      <td>0.032485</td>\n",
              "      <td>0.028017</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047781</td>\n",
              "      <td>0.036935</td>\n",
              "      <td>0.066005</td>\n",
              "      <td>0.054850</td>\n",
              "      <td>0.017615</td>\n",
              "      <td>0.036496</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.055365</td>\n",
              "      <td>0.031680</td>\n",
              "      <td>0.057967</td>\n",
              "      <td>0.221671</td>\n",
              "      <td>0.068739</td>\n",
              "      <td>0.078008</td>\n",
              "      <td>0.025764</td>\n",
              "      <td>0.077448</td>\n",
              "      <td>0.037202</td>\n",
              "      <td>0.025191</td>\n",
              "      <td>0.020430</td>\n",
              "      <td>0.050165</td>\n",
              "      <td>0.049785</td>\n",
              "      <td>0.044212</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>0.032681</td>\n",
              "      <td>0.022416</td>\n",
              "      <td>0.024362</td>\n",
              "      <td>0.037098</td>\n",
              "      <td>0.017768</td>\n",
              "      <td>0.038760</td>\n",
              "      <td>0.022998</td>\n",
              "      <td>0.019019</td>\n",
              "      <td>0.015845</td>\n",
              "      <td>0.012626</td>\n",
              "      <td>0.022334</td>\n",
              "      <td>0.019251</td>\n",
              "      <td>0.042788</td>\n",
              "      <td>0.016940</td>\n",
              "      <td>0.052463</td>\n",
              "      <td>0.032662</td>\n",
              "      <td>0.037820</td>\n",
              "      <td>0.022416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.041514</td>\n",
              "      <td>0.024811</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.026519</td>\n",
              "      <td>0.102332</td>\n",
              "      <td>0.030127</td>\n",
              "      <td>0.022638</td>\n",
              "      <td>0.019852</td>\n",
              "      <td>0.040847</td>\n",
              "      <td>0.024582</td>\n",
              "      <td>0.021479</td>\n",
              "      <td>0.012252</td>\n",
              "      <td>0.020282</td>\n",
              "      <td>0.044144</td>\n",
              "      <td>0.017505</td>\n",
              "      <td>0.032934</td>\n",
              "      <td>0.010031</td>\n",
              "      <td>0.034399</td>\n",
              "      <td>0.056063</td>\n",
              "      <td>0.050406</td>\n",
              "      <td>0.009653</td>\n",
              "      <td>0.013851</td>\n",
              "      <td>0.053768</td>\n",
              "      <td>0.027988</td>\n",
              "      <td>0.043993</td>\n",
              "      <td>0.039948</td>\n",
              "      <td>0.026018</td>\n",
              "      <td>0.010103</td>\n",
              "      <td>0.016034</td>\n",
              "      <td>0.027391</td>\n",
              "      <td>0.305195</td>\n",
              "      <td>0.009918</td>\n",
              "      <td>0.035028</td>\n",
              "      <td>0.036705</td>\n",
              "      <td>0.014177</td>\n",
              "      <td>0.027256</td>\n",
              "      <td>0.047349</td>\n",
              "      <td>0.033202</td>\n",
              "      <td>0.042810</td>\n",
              "      <td>0.051493</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056372</td>\n",
              "      <td>0.026519</td>\n",
              "      <td>0.001741</td>\n",
              "      <td>0.022204</td>\n",
              "      <td>0.010895</td>\n",
              "      <td>0.039594</td>\n",
              "      <td>0.026958</td>\n",
              "      <td>0.025563</td>\n",
              "      <td>0.049380</td>\n",
              "      <td>0.068558</td>\n",
              "      <td>0.030127</td>\n",
              "      <td>0.063957</td>\n",
              "      <td>0.027046</td>\n",
              "      <td>0.130258</td>\n",
              "      <td>0.008647</td>\n",
              "      <td>0.086470</td>\n",
              "      <td>0.038239</td>\n",
              "      <td>0.018313</td>\n",
              "      <td>0.030108</td>\n",
              "      <td>0.038741</td>\n",
              "      <td>0.009442</td>\n",
              "      <td>0.015001</td>\n",
              "      <td>0.018815</td>\n",
              "      <td>0.025128</td>\n",
              "      <td>0.037379</td>\n",
              "      <td>0.039582</td>\n",
              "      <td>0.014557</td>\n",
              "      <td>0.018246</td>\n",
              "      <td>0.024711</td>\n",
              "      <td>0.094204</td>\n",
              "      <td>0.006628</td>\n",
              "      <td>0.040698</td>\n",
              "      <td>0.008616</td>\n",
              "      <td>0.019255</td>\n",
              "      <td>0.021837</td>\n",
              "      <td>0.097403</td>\n",
              "      <td>0.033770</td>\n",
              "      <td>0.058408</td>\n",
              "      <td>0.055404</td>\n",
              "      <td>0.025128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.035916</td>\n",
              "      <td>0.036935</td>\n",
              "      <td>0.026519</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.033863</td>\n",
              "      <td>0.035101</td>\n",
              "      <td>0.024513</td>\n",
              "      <td>0.044580</td>\n",
              "      <td>0.056627</td>\n",
              "      <td>0.041961</td>\n",
              "      <td>0.027201</td>\n",
              "      <td>0.028365</td>\n",
              "      <td>0.025973</td>\n",
              "      <td>0.047236</td>\n",
              "      <td>0.035606</td>\n",
              "      <td>0.036020</td>\n",
              "      <td>0.028055</td>\n",
              "      <td>0.027350</td>\n",
              "      <td>0.012107</td>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.130271</td>\n",
              "      <td>0.036489</td>\n",
              "      <td>0.045174</td>\n",
              "      <td>0.073751</td>\n",
              "      <td>0.070594</td>\n",
              "      <td>0.056464</td>\n",
              "      <td>0.048537</td>\n",
              "      <td>0.026928</td>\n",
              "      <td>0.010123</td>\n",
              "      <td>0.017588</td>\n",
              "      <td>0.074734</td>\n",
              "      <td>0.022392</td>\n",
              "      <td>0.014626</td>\n",
              "      <td>0.085479</td>\n",
              "      <td>0.023353</td>\n",
              "      <td>0.036605</td>\n",
              "      <td>0.043523</td>\n",
              "      <td>0.071219</td>\n",
              "      <td>0.054669</td>\n",
              "      <td>0.030636</td>\n",
              "      <td>...</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.024633</td>\n",
              "      <td>0.064317</td>\n",
              "      <td>0.026145</td>\n",
              "      <td>0.080492</td>\n",
              "      <td>0.032622</td>\n",
              "      <td>0.061752</td>\n",
              "      <td>0.078756</td>\n",
              "      <td>0.058491</td>\n",
              "      <td>0.035101</td>\n",
              "      <td>0.030452</td>\n",
              "      <td>0.054023</td>\n",
              "      <td>0.023876</td>\n",
              "      <td>0.034721</td>\n",
              "      <td>0.037571</td>\n",
              "      <td>0.021993</td>\n",
              "      <td>0.419053</td>\n",
              "      <td>0.039765</td>\n",
              "      <td>0.033855</td>\n",
              "      <td>0.049457</td>\n",
              "      <td>0.096033</td>\n",
              "      <td>0.011827</td>\n",
              "      <td>0.044153</td>\n",
              "      <td>0.028183</td>\n",
              "      <td>0.046056</td>\n",
              "      <td>0.029091</td>\n",
              "      <td>0.019028</td>\n",
              "      <td>0.288912</td>\n",
              "      <td>0.023389</td>\n",
              "      <td>0.054317</td>\n",
              "      <td>0.050017</td>\n",
              "      <td>0.029934</td>\n",
              "      <td>0.021308</td>\n",
              "      <td>0.052214</td>\n",
              "      <td>0.017941</td>\n",
              "      <td>0.028565</td>\n",
              "      <td>0.032798</td>\n",
              "      <td>0.035675</td>\n",
              "      <td>0.044153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011299</td>\n",
              "      <td>0.029222</td>\n",
              "      <td>0.102332</td>\n",
              "      <td>0.033863</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015927</td>\n",
              "      <td>0.021267</td>\n",
              "      <td>0.042578</td>\n",
              "      <td>0.017994</td>\n",
              "      <td>0.037723</td>\n",
              "      <td>0.019082</td>\n",
              "      <td>0.037993</td>\n",
              "      <td>0.024628</td>\n",
              "      <td>0.025644</td>\n",
              "      <td>0.026537</td>\n",
              "      <td>0.044846</td>\n",
              "      <td>0.018199</td>\n",
              "      <td>0.040985</td>\n",
              "      <td>0.214319</td>\n",
              "      <td>0.043961</td>\n",
              "      <td>0.029113</td>\n",
              "      <td>0.004304</td>\n",
              "      <td>0.070805</td>\n",
              "      <td>0.046170</td>\n",
              "      <td>0.013404</td>\n",
              "      <td>0.030189</td>\n",
              "      <td>0.035723</td>\n",
              "      <td>0.034755</td>\n",
              "      <td>0.040293</td>\n",
              "      <td>0.025615</td>\n",
              "      <td>0.023515</td>\n",
              "      <td>0.022184</td>\n",
              "      <td>0.008476</td>\n",
              "      <td>0.032747</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.014011</td>\n",
              "      <td>0.183162</td>\n",
              "      <td>0.079023</td>\n",
              "      <td>0.075975</td>\n",
              "      <td>0.020922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046772</td>\n",
              "      <td>0.033863</td>\n",
              "      <td>0.022562</td>\n",
              "      <td>0.041920</td>\n",
              "      <td>0.017766</td>\n",
              "      <td>0.023313</td>\n",
              "      <td>0.013541</td>\n",
              "      <td>0.068659</td>\n",
              "      <td>0.022806</td>\n",
              "      <td>0.235065</td>\n",
              "      <td>0.015927</td>\n",
              "      <td>0.215408</td>\n",
              "      <td>0.066968</td>\n",
              "      <td>0.367712</td>\n",
              "      <td>0.011235</td>\n",
              "      <td>0.040682</td>\n",
              "      <td>0.010589</td>\n",
              "      <td>0.042264</td>\n",
              "      <td>0.067912</td>\n",
              "      <td>0.051215</td>\n",
              "      <td>0.055502</td>\n",
              "      <td>0.032859</td>\n",
              "      <td>0.024812</td>\n",
              "      <td>0.010446</td>\n",
              "      <td>0.098037</td>\n",
              "      <td>0.100497</td>\n",
              "      <td>0.051738</td>\n",
              "      <td>0.036786</td>\n",
              "      <td>0.026930</td>\n",
              "      <td>0.186684</td>\n",
              "      <td>0.036569</td>\n",
              "      <td>0.010800</td>\n",
              "      <td>0.018684</td>\n",
              "      <td>0.021447</td>\n",
              "      <td>0.054540</td>\n",
              "      <td>0.327685</td>\n",
              "      <td>0.040275</td>\n",
              "      <td>0.174066</td>\n",
              "      <td>0.245809</td>\n",
              "      <td>0.010446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 401 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       398       399       400\n",
              "0  1.000000  0.014998  0.041514  ...  0.013596  0.009184  0.052448\n",
              "1  0.014998  1.000000  0.024811  ...  0.032662  0.037820  0.022416\n",
              "2  0.041514  0.024811  1.000000  ...  0.058408  0.055404  0.025128\n",
              "3  0.035916  0.036935  0.026519  ...  0.032798  0.035675  0.044153\n",
              "4  0.011299  0.029222  0.102332  ...  0.174066  0.245809  0.010446\n",
              "\n",
              "[5 rows x 401 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SWlGndPhA1k"
      },
      "source": [
        "#### 문서간 유사도 측정\n",
        "문서0과 문서0은 같으므로 유사도가 1입니다. 문서0과 문서1~4 와의의 유사도를 확인해 보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnyM8LnehA1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1bdaaf-7f7f-4f5a-f936-9787ebc50a08"
      },
      "source": [
        "df[0][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.000000\n",
              "1    0.014998\n",
              "2    0.041514\n",
              "3    0.035916\n",
              "4    0.011299\n",
              "Name: 0, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7x3f9d1hA1l"
      },
      "source": [
        "#### 유사도를 이용한 정렬\n",
        "\n",
        "문서0과 유사도가 큰 문서를 순서대로 정렬해서 살펴보겠습니다 (TF-IDF vectorization 방법에 따라 많이 다를 수 있습니다)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB2EiAUChA1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00cba837-067c-434d-ba41-95a28012676e"
      },
      "source": [
        "ind = df[df[0] < 1][0].sort_values(ascending=False)[:5]\n",
        "ind"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "377    0.634388\n",
              "301    0.634388\n",
              "222    0.595379\n",
              "38     0.372439\n",
              "32     0.346372\n",
              "Name: 0, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh0LsGb4dwgZ"
      },
      "source": [
        "index = 377"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUk_QuWNhA1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62eb7fc4-b698-44e7-ed22-687d2f5e7407"
      },
      "source": [
        "print(data[0][:100])\n",
        "print(data[index][:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Joke e-mail virus tricks users\\n\\nA virus that disguises itself as a joke is spreading rapidly across '\n",
            "b'Virus poses as Christmas e-mail\\n\\nSecurity firms are warning about a Windows virus disguising itself '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XI2RDt4hA1l"
      },
      "source": [
        "코사인 유사도와 같은 Brute Force 방법은 비교해야 할 문서의 양이 많아 질 수록 많은 계산을 필요로합니다. <br> 실제 어플리케이션 환경에서는 더 빠른 비교 방법을 사용해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmTXnGIChA1l"
      },
      "source": [
        "### NearestNeighbor (K-NN, K-최근접 이웃) \n",
        "\n",
        "K-최근접 이웃법은 쿼리와 가장 가까운 상위 K개의 근접한 데이터를 찾아서 K개 데이터의 유사성을 기반으로 **점을 추정하거나 분류**하는 예측 분석에 사용됩니다.\n",
        "최근접 이웃 방법은 non-generalizing 머신러닝 방법인데, 모든 학습 데이터를 KD Tree 나 Ball Tree같은 빠른 색인 구조(indexing structure)에 단순히 저장하기 때문입니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64mTWdKZpK-b"
      },
      "source": [
        "[K-D Tree](https://scikit-learn.org/stable/modules/neighbors.html?highlight=very%20distant%20from%20point#k-d-tree)의 기본아이디어는 점 A와 B가 멀고, B가 C와 가까우면 A가 C와 멀다는 것을 알 수 있는데 이때 명시적으로 A와 C의 거리를 계산할 필요가 없다는 것입니다.\n",
        "\n",
        "<img src=\"https://i.imgur.com/CKKoz5W.png\" width=\"500\"/>\n",
        "\n",
        "[Ball Tree](https://scikit-learn.org/stable/modules/neighbors.html?highlight=very%20distant%20from%20point#ball-tree)는 K-D 트리를 더욱 효율적으로 만들기 위해 개발되었습니다. KD 트리는 데이터를 Cartesian 축으로 분할하지만 Ball Tree는 nesting hyper-spheres 형태로 분할하여 트리구성에 비용이 더 들지만, 매우 구조화된 데이터나 높은 차원의 데이터에 더 효율적입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhso8V_WhA1l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "6d0fe15f-2778-41f0-842a-68e0142dce50"
      },
      "source": [
        "dtm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-PRON-</th>\n",
              "      <th>abandon</th>\n",
              "      <th>ability</th>\n",
              "      <th>ability record</th>\n",
              "      <th>able</th>\n",
              "      <th>able access</th>\n",
              "      <th>able choose</th>\n",
              "      <th>able control</th>\n",
              "      <th>able handle</th>\n",
              "      <th>able offer</th>\n",
              "      <th>able play</th>\n",
              "      <th>able store</th>\n",
              "      <th>able thing</th>\n",
              "      <th>able use</th>\n",
              "      <th>able watch</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absorb</th>\n",
              "      <th>abuse</th>\n",
              "      <th>academic</th>\n",
              "      <th>academy</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>acceptance</th>\n",
              "      <th>access</th>\n",
              "      <th>access available</th>\n",
              "      <th>access datum</th>\n",
              "      <th>access device</th>\n",
              "      <th>access e</th>\n",
              "      <th>access grow</th>\n",
              "      <th>access home</th>\n",
              "      <th>access information</th>\n",
              "      <th>access internet</th>\n",
              "      <th>access medium</th>\n",
              "      <th>access mobile</th>\n",
              "      <th>access net</th>\n",
              "      <th>access point</th>\n",
              "      <th>access service</th>\n",
              "      <th>accessible</th>\n",
              "      <th>accident</th>\n",
              "      <th>acclaim</th>\n",
              "      <th>...</th>\n",
              "      <th>year launch</th>\n",
              "      <th>year microsoft</th>\n",
              "      <th>year million</th>\n",
              "      <th>year motorola</th>\n",
              "      <th>year new</th>\n",
              "      <th>year number</th>\n",
              "      <th>year old</th>\n",
              "      <th>year people</th>\n",
              "      <th>year portable</th>\n",
              "      <th>year predict</th>\n",
              "      <th>year real</th>\n",
              "      <th>year release</th>\n",
              "      <th>year report</th>\n",
              "      <th>year say</th>\n",
              "      <th>year service</th>\n",
              "      <th>year think</th>\n",
              "      <th>year time</th>\n",
              "      <th>year uk</th>\n",
              "      <th>year use</th>\n",
              "      <th>year year</th>\n",
              "      <th>yen</th>\n",
              "      <th>yepp</th>\n",
              "      <th>yes</th>\n",
              "      <th>york</th>\n",
              "      <th>york base</th>\n",
              "      <th>york state</th>\n",
              "      <th>york times</th>\n",
              "      <th>young</th>\n",
              "      <th>young americans</th>\n",
              "      <th>young people</th>\n",
              "      <th>young user</th>\n",
              "      <th>youngster</th>\n",
              "      <th>youth</th>\n",
              "      <th>zelda</th>\n",
              "      <th>zen</th>\n",
              "      <th>zen micro</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombie bot</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.068952</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.074656</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024268</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.069914</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.052588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.049556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 7604 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   -PRON-  abandon   ability  ability record  ...  zombie  zombie bot  zone  zoom\n",
              "0     0.0      0.0  0.000000             0.0  ...     0.0         0.0   0.0   0.0\n",
              "1     0.0      0.0  0.000000             0.0  ...     0.0         0.0   0.0   0.0\n",
              "2     0.0      0.0  0.000000             0.0  ...     0.0         0.0   0.0   0.0\n",
              "3     0.0      0.0  0.024268             0.0  ...     0.0         0.0   0.0   0.0\n",
              "4     0.0      0.0  0.000000             0.0  ...     0.0         0.0   0.0   0.0\n",
              "\n",
              "[5 rows x 7604 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBToNaAhhA1m"
      },
      "source": [
        "#### sklearn - NearestNeighbors\n",
        "sklearn에서 비지도학습을 위한 NearestNeighbors 모델을 사용합니다\n",
        "[sklearn.neighbors.NearestNeighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn-neighbors-nearestneighbors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7z2v2aHhA1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0817e9a1-a9b3-483b-c4c0-1f44638f7a0f"
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# dtm을 사용히 NN 모델을 학습시킵니다. (디폴트)최근접 5 이웃.\n",
        "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "nn.fit(dtm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrmaUZU5hA1m"
      },
      "source": [
        "문서0과 가장 가까운 문서 (0 포함) 5개의 거리(값이 작을수록 유사합니다)와, 문서의 인덱스를 알 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8VirpVdhA1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed34f898-b14b-4667-8a7f-02dab9940626"
      },
      "source": [
        "nn.kneighbors([dtm.iloc[0].values])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.85511637, 0.85511637, 0.89957864, 1.12032242]]),\n",
              " array([[  0, 377, 301, 222,  38]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCOAsaBRhA1m"
      },
      "source": [
        "문서0의 이웃인 문서377로 검색해 보겠습니다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mQaJkM4hA1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b35b8a44-f57b-4a2d-be62-85b3c7581d05"
      },
      "source": [
        "nn.kneighbors([dtm.iloc[377]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.        , 0.85511637, 0.91629024, 1.10942847]]),\n",
              " array([[377, 301,   0, 222,  38]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uUn6P5OhA1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e777f87-9018-47e9-9634-aa9e77b0194b"
      },
      "source": [
        "print(data[222][:300])\n",
        "print(data[301][:300])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Toxic web links help virus spread\\n\\nVirus writers have begun using the power of the web to spread their malicious wares.\\n\\nA Windows virus called Bofra is turning infected machines into distributors of its malicious code. Those clicking on the poisoned links in e-mail messages sent out by infected mac'\n",
            "b'Virus poses as Christmas e-mail\\n\\nSecurity firms are warning about a Windows virus disguising itself as an electronic Christmas card.\\n\\nThe Zafi.D virus translates the Christmas greeting on its subject line into the language of the person receiving infected e-mail. Anti-virus firms speculate that this'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ7KPCgJhA1n"
      },
      "source": [
        "#### 문서 검색 예제\n",
        "\n",
        "CNN 에서 tech 기사를 가져와서 문서검색에 사용해봅시다. 다른 기사를 가지고 테스트해봐도 좋습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gh7h7IlhA1n"
      },
      "source": [
        "# https://edition.cnn.com/2020/07/30/tech/huawei-samsung-q2-hnk-intl/index.html\n",
        "cnn_tech_article = [ \"\"\"\n",
        "Hong Kong (CNN Business)Huawei became the world's top smartphone seller last quarter, overtaking Samsung for the first time ever, according to an independent market research report released Thursday.\n",
        "The Chinese tech company shipped 55.8 million phones in the three months ended in June, surpassing longtime rival Samsung, which shipped 53.7 million, according to the Canalys report.\n",
        "\"Taking first place is very important for Huawei,\" said Canalys analyst Mo Jia. \"It is desperate to showcase its brand strength to domestic consumers, component suppliers and developers.\"\n",
        "A years-long US pressure campaign against Huawei has handicapped the Shenzhen-based firm's global business.\n",
        "Huawei still suffered an annual decline in smartphone shipments of 5%. But Samsung's was a lot bigger at 30%, according to Canalys.\n",
        "The market research firm said Huawei's victory over Samsung wouldn't have happened without Covid-19. The company was able to take advantage of the economic recovery in China, where Huawei now sells over 70% of its smartphones. Samsung has a very small presence in China.\n",
        "Huawei&#39;s hopes of global domination have been dashed\n",
        "Huawei's hopes of global domination have been dashed\n",
        "Huawei's global smartphone and telecom gear business continues to suffer the fallout from US sanctions that cut the company off from key American tech and supplies.\n",
        "Without access to popular Google (GOOGL GOOGLE) apps such as YouTube, maps and Gmail, Huawei's latest smartphones are a lot less attractive to international buyers. That will make it very difficult for Huawei to hold on to the global No. 1 position, according to Jia.\n",
        "\"It will be hard for Huawei to maintain its lead in the long term. Its major channel partners in key regions, such as Europe, are increasingly wary of ranging Huawei devices, taking on fewer models, and bringing in new brands to reduce risk. Strength in China alone will not be enough to sustain Huawei at the top once the global economy starts to recover,\" he said.\n",
        "\"Our business has demonstrated exceptional resilience in these difficult times,\" Huawei spokeswoman Evita Cao said. Cao did not respond to questions on how the company can maintain its lead going forward.\n",
        "Huawei's victory came on the same day Samsung posted a big profit bump for the second quarter, with strong chip demand helping the company weather the fallout from the coronavirus pandemic.\n",
        "Samsung reported operating profit of 8.15 trillion won ($6.8 billion) for the three months that ended in June, up more than 23% compared to the same period last year.\n",
        "Samsung said sales fell about 6% to 53 trillion won ($44.6 billion).\n",
        "Shares in Samsung were last up 0.7% in Seoul. South Korea's Kospi (KOSPI) rose 0.1%.\n",
        "Taiwan&#39;s TSMC is becoming one of the world&#39;s top companies. Intel&#39;s problems are helping\n",
        "Taiwan's TSMC is becoming one of the world's top companies. Intel's problems are helping\n",
        "Despite the double digit declines in annual smartphone shipments for the quarter noted by the Canalys report, Samsung reported that the unit remained profitable thanks to savings on marketing costs. (Samsung does not break out specifics about its smartphone shipments, but noted that they declined.)\n",
        "For the second half of 2020, however, Samsung is warning that \"uncertainties related to Covid-19 linger\" for its mobile business.\n",
        "That could be enough to drag the company to revenue losses for the year, according to research firm Crisp Idea.\n",
        "The consumer electronics unit, which includes smartphones and TVs, is \"expected to decline significantly as Covid-19 affects demand and leads to store and plant closures globally,\" Crisp Idea analysts wrote in a note earlier this month.\n",
        "Smartphone shipments worldwide are expected to fall about 18% in the first half of the year as the pandemic continues to affect consumer spending, analysts at IDC said in a note last month.\n",
        "The market research firm added that global smartphone shipments are not expected to return to growth until the first quarter of 2021.\n",
        "That would also hurt Samsung's memory chip business, because the company supplies chips for rival smartphone companies such as Apple (AAPL) and Huawei.\"\"\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vOr8kVjhA1n"
      },
      "source": [
        "CNN Tech 뉴스를 쿼리로 쓰기 위해 학습된 tfidf vectorizer를 통해 변환하겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsCn9IkPhA1n"
      },
      "source": [
        "new = tfidf.transform(cnn_tech_article)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pVXr1YzhA1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485e7b90-b601-4f83-bd01-c0a7b4aa128e"
      },
      "source": [
        "nn.kneighbors(new.todense())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.31624638, 1.3174223 , 1.31770469, 1.31778057, 1.31848904]]),\n",
              " array([[297, 218,  56, 374, 232]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iSQ0s5-hA1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac271f7-625c-4bcf-ea4f-2731d78dca2d"
      },
      "source": [
        "# 가장 가깝게 나온 문서를 확인합니다 \n",
        "data[297]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Gadget growth fuels eco concerns\\n\\nTechnology firms and gadget lovers are being urged to think more about the environment when buying and disposing of the latest hi-tech products.\\n\\nAt the Consumer Electronics Show in Las Vegas earlier this month, several hi-tech firms were recognised for their strategies to help the environment. Ebay also announced the Rethink project bringing together Intel, Apple, and IBM among others to promote recycling. The US consumer electronics market is set to grow by over 11% in 2005. But more awareness is needed about how and where old gadgets can be recycled as well as how to be more energy efficient, said the US Environmental Protection Agency (EPA). Of particular growing concern is how much energy it takes to recharge portable devices, one of the fastest growing markets in technology. The Consumer Electronics Association (CEA) has predicted that shipments of consumer technologies in 2005 will reach more than $125.73 billion (nearly \\xc2\\xa368 billion).\\n\\nEbay\\'s initiative pulls together major technology firms, environment groups, government agencies and eBay users to give information about what to do with old computers and where to send them. The online auction house thinks that its already-established community of loyal users could be influential. \"We really became aware of the e-waste issue and we saw that our 125 million users can be a powerful force for good,\" eBay\\'s David Stern told the BBC News website.\\n\\n\"We saw the opportunity to meet the additional demand we have on the site for used computers and saw the opportunity too to good some good for the environment.\" But it is not just computers that cause a problem for the environment. Teenagers get a new mobile every 11 months, adults every 18 months and a 15 million handsets are replaced in total each year. Yet, only 15% are actually recycled. This year, a predicted two billion people worldwide will own a mobile, according to a Deloitte report. Schemes in the US, like RIPMobile, could help in targeting younger generations with recycling messages. The initiative, which was also launched at CES, rewards 10 to 28-year-olds for returning unused phones. \"This system allows for the transformation of a drawer full of unused mobile phones into anything from music to clothes to electronics or games,\" said Seth Heine from RIPMobile.\\n\\nOne group of students collected 1,000 mobiles for recycling in just three months. Mr Heine told the BBC News website that what was important was to raise awareness amongst the young so that recycling becomes \"learned behaviour\". Europe is undoubtedly more advanced than the US in terms of recycling awareness and robust \"end of life\" programmes, although there is a tide change happening in the rest of the world too. Intel showcased some its motherboards and chips at CES which are entirely lead free.\\n\\n\"There is more and more awareness on the consumer side, but the whole industry is moving towards being lead free,\" Intel\\'s Allen Wilson told the BBC News website. \"There is still low-level awareness right now, but it is on the rise - the highest level of awareness is in Europe.\" A European Union (EU) directive, WEEE (Waste Electronic and Electrical Equipment), comes into effect in August. It puts the responsibility on electrical manufacturers to recycle items that are returned to them. But developments are also being made to design better technologies which are more energy efficient and which do not contain harmful substances. Elements like chromium, lead, and cadmium - common in consumer electronics goods - will be prohibited in all products in the EU by 2006.\\n\\nBut it is not just about recycling either. The predicted huge growth in the gadget market means the amount of energy used to power them up is on the rise too. The biggest culprit, according to the EPA, is the innocuous power adaptor, nicknamed \"energy vampires\". They provide vital juice for billions of mobile phones, PDAs (personal digital assistants), digital cameras, camcorders, and digital music players.\\n\\nAlthough there is a focus on developing efficient and improved circuits in the devices themselves, the technologies inside rechargers are still outdated and so eat up more energy than is needed to power a gadget. On 1 January, new efficiency standards for external power supplies came into effect as part of the European Commission Code of Conduct. But at CES, the EPA also unveiled new guidelines for its latest Energy Star initiative which targets external power adapters. These map out the framework for developing better adaptors that can be labelled with an Energy Star logo, meaning they are about 35% more efficient. The initiative is a global effort and more manufacturers\\' adaptors are being brought on board. Most are made in China. About two billion are shipped global every year, and about three billion are in use in the US alone. The EPA is already working with several companies which make more than 22% of power supplies on the market. \"We are increasingly finding companies that not only want to provide neat, hi-tech devices, but also bundle with it a hi-tech, efficient power supply,\" the EPA\\'s Andrew Fanara said. Initiatives like this are critical; if power adaptors continue to be made and used as they are now, consumer electronics and other small appliances will be responsible for more than 40% of electricity used in US homes, said the EPA.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUuQQBwFcw0Z"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRmbTtyecw0Z"
      },
      "source": [
        "여러분은 이미 머신러닝을 이용해 분류기를 학습시킬 수 있습니다. 그리고 텍스트 문서에서 어떻게 특성들을 추출하는지 배웠습니다. 이제 텍스트 문서를 분류하는 모델을 만들 차례 입니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rll8BiMGcw0a"
      },
      "source": [
        "## 텍스트에서 특성들을 추출하고 문서 분류기를 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQTs6vWEcw0a"
      },
      "source": [
        "Sklearn 파이프라인을 사용하면 머신러닝 프로세스에 사용되는 여러 컴포넌트들을 쉽게 연결할 수 있었습니다.\n",
        "\n",
        "이번에는 파이프라인을 이용해 코퍼스 입력, 차원 축소, 학습 프로세스를 진행해 보겠습니다.\n",
        "\n",
        "벡터화 과정중에 n-gram 범위, 최대 토큰의 수 같은 하이퍼파라미터들을 수정해 가며 실험을 해 보아야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrJ9-RkBcw0a"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFH03a_Xcw0b"
      },
      "source": [
        "20개 뉴스그룹으로 분류된 18,000개의 뉴스그룹 문서 데이터셋 입니다.\n",
        "- [20newsgroups](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups)\n",
        "- 전자와 정치에 관한 두 개의 다른 카테고리 뉴스를 가져오겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB_MPmeacw0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5ee924-4bd5-4874-d679-46eefd2a1ac6"
      },
      "source": [
        "categories = ['sci.electronics',\n",
        "              'talk.politics.misc']\n",
        "\n",
        "ng_train = fetch_20newsgroups(subset='train'\n",
        "                             , remove=('headers', 'footers', 'quotes')\n",
        "                             , categories=categories\n",
        "                             )\n",
        "\n",
        "ng_test = fetch_20newsgroups(subset='test'\n",
        "                             , remove=('headers', 'footers', 'quotes')\n",
        "                             , categories=categories\n",
        "                             )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU0Jt2iNcw0b"
      },
      "source": [
        "학습, 테스트 데이터가 분리되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYp4f-SScw0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f0ee9f-21ab-42c1-8531-4ff6da405472"
      },
      "source": [
        "len(ng_train.data), len(ng_test.data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1056, 703)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URUyGDqvcw0c"
      },
      "source": [
        "한 문서를 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxl1DlbAcw0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "b047c003-dc98-4602-cd98-679c349faa02"
      },
      "source": [
        "ng_train.data[5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nMight be a good idea...  The resolution you requested is about 0.3mV\\nIn order to get what you've paid for, noise level better be lower than\\nthat.  It is kind of hard to do it in a noisy box like you can expect\\ninside a PC.\\n\\nBefore you pay $$$ for a PC card, test it out by sampling a low\\ndistortion sine wave (I think there is a sine wave on a CD.  Digital\\nDomain ?  There are possibly other low THD sources)  Run the digitized\\nwaveform through a FFT transform and take alook at the noise floor on\\nthe spectrum.  That's should give you a good indication of the design.\\n(That's what I am doing to test a data acquistion system I have designed\\n- I got the idea from MAXIM data sheet.)\\n\\nIf you can live with 14 bit resolution, I would recommend looking at\\nthe MAX121 from MAXIM.  It is a high speed (308KHz) complete\\nsampling A/D with DSP interface.  The input range is +/- 5V and it\\nuses a serial interface (which can easily be optically isolated\\nfrom the computer to elinimate a major noise source)  The Analog design\\nguide I got from them shows a -100db noise level.  They claim a -77db\\nmax (-85 typ.) THD.  Looks pretty good for the $12 @ 1000 pieces\\n\\nA evaluation kit is available.  Might want to give these nice folks a\\ncall.  1-800-998-8800 or fax: (408)737-7194 and (408) 737-7600 ext4000\\nfor application assistance.\\n\\nThis assumes that you can build your own DAS and write your own software.\\n(Hey you can get the MAX121 as a free sample just by calling the 1-800 #)\\n\\n\\nI would recommend you to find out the resolution that can be gotten out\\nof your system by looking at the noise level, otherwise you might be\\nthrowing out your money.\\n\\n\\nK. C. Lee\\nElec. Eng. Grad. Student\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL7Bkvbrcw0c"
      },
      "source": [
        "이 문서의 타겟 레이블 입니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJYcdu4Icw0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00f45d4-2ede-428e-8f9f-e2f65c455047"
      },
      "source": [
        "ng_train.target[5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6QaGCSjcw0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef515ecd-aa40-4cb2-94d0-d7767545390a"
      },
      "source": [
        "ng_train.target_names"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sci.electronics', 'talk.politics.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ8Qfh_ccw0d"
      },
      "source": [
        "### 데이터를 살펴봅시다\n",
        "- [Step 1: Gather Data](https://developers.google.com/machine-learning/guides/text-classification/step-1)\n",
        "\n",
        "- [Step 2: Explore Your Data](https://developers.google.com/machine-learning/guides/text-classification/step-2)\n",
        "\n",
        "학습 모델을 만드는 일은 데이터 분석 과정 중 한 부분입니다. 모델링 전 데이터의 특성을 확인하고 이해하는 과정을 통해 더욱 좋은 모델을 만들 수 있게 됩니다. 데이터를 미리 잘 살펴보면 더 적은 데이터로 더 높은 성능을 가진 모델을 만들 수도 있습니다.\n",
        "\n",
        "- [explore_data.py](https://github.com/google/eng-edu/blob/master/ml/guides/text_classification/explore_data.py) 파일은 ipynb 폴더에 다운받아 import 하여 사용하세요\n",
        "\n",
        "- [Direct Download Link](https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/explore_data.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p3OiXx9r0Up",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4c7c3ba6-c1f8-46d8-f1a0-cdc8f228d2f1"
      },
      "source": [
        "# for Colab User\n",
        "# Upload files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-db1ff96d-8946-4ae3-9b89-90a856f449d7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-db1ff96d-8946-4ae3-9b89-90a856f449d7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving explore_data.py to explore_data (1).py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWdlj3qqcw0d"
      },
      "source": [
        "# 그냥 실핼하면 에러가 날 수 있습니다. \n",
        "# 위 'Direct Download Link'에서 explore_data를 다운받은 뒤 업로드해서 사용합니다. \n",
        "import explore_data as ed\n",
        "import seaborn as sns"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FyEX7QLcw0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f6c083-fdab-457c-b188-ff8c7a873d64"
      },
      "source": [
        "# Gets the median number of words per sample given corpus.\n",
        "median_words_per_sample = ed.get_num_words_per_sample(ng_train.data)\n",
        "print('Median words per sample: ', median_words_per_sample)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Median words per sample:  91.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXwjr9-Ucw0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e0049dfe-0ee8-4e91-c24c-8e719b68eca9"
      },
      "source": [
        "# 데이터 길이 확인\n",
        "ed.plot_sample_length_distribution(ng_train.data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d6pkZEQcw0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ef4290a3-ec39-444b-c652-591d729e63a0"
      },
      "source": [
        "# 전자와 정치 두 카테고리 확인\n",
        "ed.plot_class_distribution(ng_train.target)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TijdMKoocw0e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = [15, 4]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKxlSOYJcw0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "f268224c-7c92-4596-8e02-557fa471f7b9"
      },
      "source": [
        "# Plots the frequency distribution of n-grams.\n",
        "ed.plot_frequency_distribution_of_ngrams(ng_train.data\n",
        "                                     , ngram_range=(1, 2)\n",
        "                                     , num_ngrams=50)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mY9oiF5cw0e"
      },
      "source": [
        "### 모델은 어떻게 선택할까요? \n",
        "- [Step 2.5: Choose a Model](https://developers.google.com/machine-learning/guides/text-classification/step-2-5)\n",
        "\n",
        "앞서 간단히 살펴본 데이터의 수치를 기반해서 2.5단계에서는 어떤 분류 모델을 사용할 것인지 선택을 해 보겠습니다.\n",
        "\n",
        "다음 플로우차트에서 어떻게 분류 모델을 선택해야 하는지 구글에서 수행한 여러 실험 결과를 가지고 간략한 가이드를 제공합니다. 목표는 주어진 데이터세트에서 가능한 최선의 정확도를 낼 수 있고 동시에 학습계산량을 줄이는 것이었습니다. 최적의 방법을 찾기 위해 감성분석, 토픽 분류 등 여러 문제들에 대한 12개의 데이터 세트를 사용했으며 또한 여러 학습 모델구조를 사용해 45만번 이상의 실험을 수행하였습니다.\n",
        "\n",
        "![flowchart](https://developers.google.com/machine-learning/guides/text-classification/images/TextClassificationFlowchart.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWqvu-skcw0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bbf1dae-4d50-46d7-d0ca-5fd01d725f01"
      },
      "source": [
        "# 데이터 출처... \n",
        "# categories = ['sci.electronics',\n",
        "#               'talk.politics.misc']\n",
        "\n",
        "# ng_train = fetch_20newsgroups(subset='train'\n",
        "#                              , remove=('headers', 'footers', 'quotes')\n",
        "#                              , categories=categories\n",
        "#                              )\n",
        "\n",
        "# ng_test = fetch_20newsgroups(subset='test'\n",
        "#                              , remove=('headers', 'footers', 'quotes')\n",
        "#                              , categories=categories\n",
        "#                              )\n",
        "\n",
        "# S/W ratio를 계산해 봅시다, 구글 flowchar에 따르면,\n",
        "# S/W < 1500 일 경우 BoW 를 사용해 벡터화 하고 simple MLP 모델 or 앙상블 모델을 사용하는것을 추천하고 있습니다.\n",
        "sw_ratio = len(ng_train.data) / median_words_per_sample\n",
        "print('number of samples / median words per sample ratio: ', int(sw_ratio))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples / median words per sample ratio:  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp6d-P1Zcw0f"
      },
      "source": [
        "### TF-IDF 모델로 베이스라인을 만들어 봅시다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACEA2Gu1cw0f"
      },
      "source": [
        "# 파이프라인 구성 요소를 만듭니다\n",
        "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "rfc = RandomForestClassifier()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qJydSP4cw0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5356a7-e0a9-4dee-c199-021f56bb1ff2"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# DTM을 생성합니다.\n",
        "# fit_transform : Learn vocabulary and idf, return document-term matrix.\n",
        "dtm = vect.fit_transform(ng_train.data) \n",
        "\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
        "dtm.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1056, 97372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLfA9rMgcw0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716d01a6-fb2b-4c9d-e33f-4119880711a6"
      },
      "source": [
        "# 파이프라인을 정의합니다\n",
        "pipe = Pipeline([\n",
        "    ('vect',vect)\n",
        "    ,('clf', rfc)\n",
        "])\n",
        "pipe"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words='english', strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patte...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noL1qns7cw0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d283b388-2a73-45db-c8c4-9db0024586c6"
      },
      "source": [
        "# 파라미터 셋팅\n",
        "parameters = {\n",
        "    'vect__max_df': (0.7, 1.0) # document frequency(%) 높을 경우 제거\n",
        "    ,'vect__min_df': (2, 5, 10) # document frequency(횟수) 낮을 경우 제거\n",
        "    ,'vect__max_features': (5000, 20000) # 코퍼스에서 term frequency 높은 순서대로 나열하여 제한\n",
        "    ,'clf__n_estimators': (100, 500) # The number of trees in the forest.\n",
        "    ,'clf__max_depth': (10, 20, None) # The maximum depth of the tree\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(ng_train.data, ng_train.target)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   27.4s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  7.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 2),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words='english',\n",
              "                                                        strip...\n",
              "                                                               n_jobs=None,\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=None,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__max_depth': (10, 20, None),\n",
              "                         'clf__n_estimators': (100, 500),\n",
              "                         'vect__max_df': (0.7, 1.0),\n",
              "                         'vect__max_features': (5000, 20000),\n",
              "                         'vect__min_df': (2, 5, 10)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0EaF-A1cw0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9508fb-a332-4c40-ffe4-e724fb8709a7"
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9062505588840203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sff53Hfxcw0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64fc5678-a0cf-404c-f536-a6a2aecd9b9b"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__max_depth': None,\n",
              " 'clf__n_estimators': 100,\n",
              " 'vect__max_df': 0.7,\n",
              " 'vect__max_features': 20000,\n",
              " 'vect__min_df': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNNO8lvPcw0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5aec241-3cd5-4928-c3ee-f599378a92f9"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 테스트 데이터에 대해 정확도를 구해보겠습니다\n",
        "y_test = grid_search.predict(ng_test.data)\n",
        "accuracy_score(ng_test.target, y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8890469416785206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96o5cDQuLuj6"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrYyMDPwcw0g"
      },
      "source": [
        "## 잠재의미분석(Latent Semantic Analysis, LSA)\n",
        "\n",
        "\n",
        "잠재의미분석(LSA)는 Word2Vec, BoW 등의 방법론을 사용해 만든 문서-단어행렬(DTM) 데이터의 차원을 축소해 문서들에 숨어있는(latent) 의미(Topics)를 끌어내는 방법입니다.\n",
        "\n",
        "이때 차원 축소에는 Truncated SVD(특이값 분해)를 사용해 원하는 문서나, 단어의 차원을 축소합니다.\n",
        "\n",
        "물론 차원이 축소가 되더라도 기존에 문서나, 단어들 간의 거리관계는 어느정도 보존이 됩니다.\n",
        "\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Konstantinos_Bougiatiotis/publication/321025221/figure/fig9/AS:668660309962763@1536432449448/Singular-value-decomposition-followed-by-rank-lowering-for-latent-semantic-indexing.jpg\" alt=\"Singular value decomposition followed by rank lowering for latent semantic indexing\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4h2qAZ8cw0g"
      },
      "source": [
        "SVD를 사용해 행렬 $A$를 $U, Σ, V^{T}$ 세 행렬의 곱으로 분해(decomposion) 합니다.\n",
        "\n",
        "> $A=UΣV^{T}$\n",
        "\n",
        "여기서 $U$, $V$가 직교행렬(orthogonal matrix) 이고, $Σ$는 대각행렬로 대각성분이 특이값(singular value)입니다.\n",
        "\n",
        "$U$, $V$가 직교행렬(orthogonal matrix)일 때 $UU^T=U^TU=I$, $VV^T=V^TV=I$ 관계가 성립하므로\n",
        "\n",
        "> $AV=UΣ$  입니다\n",
        "\n",
        "$U$ 와 $V^T$ 의 열 벡터는 특이벡터(singular vector)라 불리는데\n",
        "\n",
        "Truncated SVD는 특이값(singular value, $Σ$ 대각성분) 가운데 가장 큰 k개만 남기고 해당 특이값에 대응하는 특이벡터들로 원래 행렬 A를 근사하는 방법입니다.\n",
        "\n",
        "물론 0보다 큰 특이값을 제거하면 정보의 손실이 발생하므로 적당히 필요한 차원만큼 k를 선택합니다.\n",
        "\n",
        "다음 그림에서 k값 선택에 따른 정보 손실을 확인할 수 있습니다.\n",
        "\n",
        "<img src=\"https://i.imgur.com/Dica82I.png\" width=\"600\" />\n",
        "\n",
        "\n",
        "행렬은 선형변환으로 볼 수 있으므로, $V$의 열벡터들을 $A$를 통해 선형변환하면 $Σ$의 특이값 만큼 크기가 변하면서 여전히 직교하는 $U$의 열벡터들을 얻을 수 있다는 것입니다.\n",
        "\n",
        "\n",
        "여기서 만약 m개 문서, n개 단어로 이루어진 행렬을 truncated SVD로 분해해 다음과 같은 분해를 수행 했다면 다음과 같은 근사 식을 얻을 것이며\n",
        "\n",
        "$$A_k=U_kΣ_kV^{T}_k$$\n",
        "\n",
        "$U_k$와 $V_k$를 사용해 n차원으로 표현 되었던 문서를 k차원으로, 또는 m 차원으로 표현되었던 단어를 k 차원으로 표현할 수 있게 됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tee6pqmacw0h"
      },
      "source": [
        "#### TruncatedSVD 를 사용하여 파이프라인에서 차원을 축소하고 분류문제를 풀어보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5fOjWzNcw0h"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# SVD를 사용한 차원 축소\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "vect = TfidfVectorizer(stop_words='english'\n",
        "                       , ngram_range=(1,2)\n",
        "                       , min_df=2\n",
        "                       , max_df=0.7\n",
        "                       , token_pattern=r'(?u)\\b\\w[A-Za-z]+\\b' # 영문자만 사용\n",
        "                       , max_features=10000\n",
        "                      )\n",
        "\n",
        "svd = TruncatedSVD(algorithm='randomized'\n",
        "                   , n_iter=5\n",
        "                   , random_state=2)\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=500, random_state=2)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pqw6H2scw0i"
      },
      "source": [
        "params = {\n",
        "    # 100~500 사이의 정수 크기로 차원을 줄입니다\n",
        "#     'svd__n_components': stats.randint(100, 500)\n",
        "    'svd__n_components': stats.randint(2, 3) # 문서의 차원을 2로 고정\n",
        "    \n",
        "}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uomwXfCwcw0i"
      },
      "source": [
        "# 1.Tfidf 문서 벡터화, 2. svd 차원축소, 3. 랜덤포레스트 분류기\n",
        "pipe = Pipeline([\n",
        "    ('vect', vect)\n",
        "    , ('svd', svd)\n",
        "    , ('clf', rfc)\n",
        "])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu3Di4vDcw0i",
        "outputId": "b8fe5c60-5563-482e-e72d-1c8413272a96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fit\n",
        "random_search = RandomizedSearchCV(pipe,params, cv=3, n_iter=5, n_jobs=-1, verbose=1)\n",
        "random_search.fit(ng_train.data, ng_train.target)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   16.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=Pipeline(memory=None,\n",
              "                                      steps=[('vect',\n",
              "                                              TfidfVectorizer(analyzer='word',\n",
              "                                                              binary=False,\n",
              "                                                              decode_error='strict',\n",
              "                                                              dtype=<class 'numpy.float64'>,\n",
              "                                                              encoding='utf-8',\n",
              "                                                              input='content',\n",
              "                                                              lowercase=True,\n",
              "                                                              max_df=0.7,\n",
              "                                                              max_features=10000,\n",
              "                                                              min_df=2,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           2),\n",
              "                                                              norm='l2',\n",
              "                                                              preprocessor=None,\n",
              "                                                              smooth_idf=True,\n",
              "                                                              stop_words='english...\n",
              "                                                                     n_estimators=500,\n",
              "                                                                     n_jobs=None,\n",
              "                                                                     oob_score=False,\n",
              "                                                                     random_state=2,\n",
              "                                                                     verbose=0,\n",
              "                                                                     warm_start=False))],\n",
              "                                      verbose=False),\n",
              "                   iid='deprecated', n_iter=5, n_jobs=-1,\n",
              "                   param_distributions={'svd__n_components': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fed5d83d550>},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSixIHkucw0i",
        "outputId": "fb6cf2f8-698c-4c38-d362-f7248bb0ab29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# svd__n_components: Random search에서 선택된 줄어든 차원을 확인할 수 있습니다.\n",
        "random_search.best_params_"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'svd__n_components': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jCVajTncw0i",
        "outputId": "c9b272d3-b004-489d-ccc1-7a5e4653e0e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "random_search.best_score_"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9147727272727272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoZUxlzccw0j",
        "outputId": "28b5824b-9f97-494f-b677-e0403a780caa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 테스트셋으로 정확도를 계산합니다\n",
        "y_test = random_search.predict(ng_test.data)\n",
        "accuracy_score(ng_test.target, y_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9075391180654339"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD052pBScw0j",
        "outputId": "16f91a2e-dafb-4bf9-f8f4-b3322a55a8e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(ng_test.target, y_test))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92       393\n",
            "           1       0.91      0.88      0.89       310\n",
            "\n",
            "    accuracy                           0.91       703\n",
            "   macro avg       0.91      0.90      0.91       703\n",
            "weighted avg       0.91      0.91      0.91       703\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ2xkx5_cw0j"
      },
      "source": [
        "#### SVD를 따로 수행해서 행렬분해가 어떻게 되는지 확인해 보겠습니다.\n",
        "\n",
        "- randomized_svd를 사용해서 $U$, $\\Sigma$, $V^T$ 행렬을 구해보겠습니다.\n",
        "- randomized_svd는 Truncated SVD에서 내부적으로 사용되는 기능입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpw-B8BVcw0j"
      },
      "source": [
        "# 학습 데이터를 TF-IDF vectorizer로 벡터화하여 사용하겠습니다.\n",
        "A = random_search.best_estimator_.named_steps['vect'].transform(ng_train.data).todense()\n",
        "X_test = random_search.best_estimator_.named_steps['vect'].transform(ng_test.data).todense()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG9MGR7scw0j",
        "outputId": "9fc733bb-acca-4fea-bbfa-43a408705bb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# DTM\n",
        "A.shape, X_test.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1056, 10000), (703, 10000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wXozeaHcw0k"
      },
      "source": [
        "# randomized_svd를 사용하여 U, S(Sigma), VT(V transposed) 행렬을 얻습니다\n",
        "from sklearn.utils.extmath import randomized_svd\n",
        "\n",
        "U, S, VT = randomized_svd(A\n",
        "                         , n_components=2 # 상위 특이값 2개를 선택합니다\n",
        "                         , n_iter=5\n",
        "                         , random_state=2)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IlvM14zcw0k",
        "outputId": "d396740a-40a6-4080-c6c9-cb78f8b0002a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "U.shape, S.shape, VT.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1056, 2), (2,), (2, 10000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2YFuXCncw0k",
        "outputId": "9001be74-7f90-48f5-8c9a-c8da7b4f3239",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "U"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02975338,  0.02040102],\n",
              "       [ 0.0290698 ,  0.04117074],\n",
              "       [ 0.03961388, -0.04253567],\n",
              "       ...,\n",
              "       [ 0.03970262, -0.01638489],\n",
              "       [ 0.03398986,  0.03985268],\n",
              "       [ 0.01414231, -0.01261801]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBZKePKicw0k",
        "outputId": "d1a84c45-0742-4584-dad7-66b5c214d96b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 대각 성분(특이값)만 가져왔습니다.\n",
        "S"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.92178091, 2.59248335])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owjWO96Ocw0k",
        "outputId": "71fbe780-e784-49e8-b211-64d2ae779703",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "VT"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00103713,  0.00276685,  0.00616488, ...,  0.00451874,\n",
              "         0.00629204,  0.0035681 ],\n",
              "       [ 0.00127521,  0.00616524,  0.01354243, ...,  0.00637487,\n",
              "         0.00368002, -0.00077783]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ_qfgq0cw0l"
      },
      "source": [
        "$V_k^{T} V_k = I_k$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veG_Llbxcw0l",
        "outputId": "b6a767b6-8af2-4b87-fffe-beb6d640e0dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "VT @ VT.T"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.00000000e+00, -1.90819582e-17],\n",
              "       [-1.90819582e-17,  1.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxd__xuDcw0l"
      },
      "source": [
        "$A_k=U_kΣ_kV^{T}_k$ \n",
        "\n",
        "=> $A_k V_k = U_k\\Sigma_k$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXvZ6aj5cw0l",
        "outputId": "5fcb5542-330a-4eb4-8c28-71ea0b0a278b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# A는 A_k는 아니지만 결과는 같습니다.\n",
        "AV = A @ VT.T\n",
        "AV"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[ 0.11668625,  0.0528893 ],\n",
              "        [ 0.11400537,  0.10673446],\n",
              "        [ 0.15535694, -0.11027301],\n",
              "        ...,\n",
              "        [ 0.15570497, -0.04247756],\n",
              "        [ 0.1333008 ,  0.10331742],\n",
              "        [ 0.05546305, -0.03271198]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S2Lxdn_cw0l",
        "outputId": "eacf2956-f80e-41db-b4ff-ee0156c5ac68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "US = U @ np.diag(S)\n",
        "US"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.11668625,  0.0528893 ],\n",
              "       [ 0.11400537,  0.10673446],\n",
              "       [ 0.15535694, -0.11027301],\n",
              "       ...,\n",
              "       [ 0.15570497, -0.04247756],\n",
              "       [ 0.1333008 ,  0.10331742],\n",
              "       [ 0.05546305, -0.03271198]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq3LCwEMcw0l"
      },
      "source": [
        "테스트 문서들도 $V_k$를 사용해서 문서의 차원을 축소할 수 있습니다.\n",
        "\n",
        "$XV_k$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN1HF-7Ucw0m",
        "outputId": "46694d66-2b9a-467c-83ff-64b60018a6c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test_trans = X_test @ VT.T\n",
        "X_test_trans"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[ 0.03407879, -0.03776464],\n",
              "        [ 0.14614089, -0.05216358],\n",
              "        [ 0.0676408 ,  0.07027432],\n",
              "        ...,\n",
              "        [ 0.14372308,  0.06976893],\n",
              "        [ 0.09377234,  0.04664435],\n",
              "        [ 0.10378836, -0.04427015]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7VkJmJ9cw0m",
        "outputId": "65ae06a3-530c-45b7-d0e1-7db66c7ecee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test_trans.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(703, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SN53cA0cw0m"
      },
      "source": [
        "#### truncatedSVD 결과물로 비교해 보겠습니다.\n",
        "\n",
        "truncatedSVD 속성 `components_` 가 행렬 VT입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZabbHsecw0m",
        "outputId": "a42e9c29-8354-407d-f63a-67403337f6f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "components = random_search.best_estimator_.named_steps['svd'].components_\n",
        "print((components - VT).sum())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.2119654035241435e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOlFnqAzcw0m"
      },
      "source": [
        "TruncatedSVD 속성을 조금 더 살펴봅시다.\n",
        "\n",
        "먼저 특이값를 확인해 보겠습니다. 위에서 구한 S(Sigma)와 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB1ajt_Pcw0m",
        "outputId": "c00ccab8-878b-46a3-9a8d-b22feba08a52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "components[:10].shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghmd4V1Ocw0n",
        "outputId": "5b211a0b-e535-476d-aff6-dd5586c5975f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(random_search.best_estimator_.named_steps['svd'].singular_values_)\n",
        "print(S)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.92178091 2.59248335]\n",
            "[3.92178091 2.59248335]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48swUKircw0n"
      },
      "source": [
        "차원이 줄어든 데이터(AV, US)의 분산값입니다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDg_b8K4cw0n",
        "outputId": "14edd04b-c188-401b-a306-d26cfcc11c4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(random_search.best_estimator_.named_steps['svd'].explained_variance_)\n",
        "print(np.var(US, axis=0))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00302819 0.00629697]\n",
            "[0.00302819 0.00629697]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i-lpQNXcw0n"
      },
      "source": [
        "이번에는 테스트 문서 샘플을 SVD를 사용해 차원 축소해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RFiqWOjcw0n",
        "outputId": "67002a35-d331-4297-830e-3afeb0958781",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 예시로 테스트 문서 0 벡터를 사용합니다.\n",
        "d0 = X_test[0]\n",
        "print(d0.shape)\n",
        "print(random_search.best_estimator_.named_steps['svd'].transform(d0))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 10000)\n",
            "[[ 0.03407879 -0.03776464]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97d1Ypk3cw0n"
      },
      "source": [
        "테스트 데이터를 모두 변환해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJQI5w9Jcw0o",
        "outputId": "39e3cb08-eb1f-4c32-fe2d-f1b0bd4718b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_test.shape)\n",
        "X_test_trans_2 = random_search.best_estimator_.named_steps['svd'].transform(X_test)\n",
        "print(X_test_trans_2.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(703, 10000)\n",
            "(703, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h938JJbcw0o"
      },
      "source": [
        "위에서 직접 구한 값과 같습니다. (X_test @ VT.T)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8pWdEX6cw0o",
        "outputId": "1e47f950-ac3e-4c07-de18-655ca1811415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 문서 0만 보겠습니다.\n",
        "X_test_trans[0], X_test_trans_2[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(matrix([[ 0.03407879, -0.03776464]]), array([ 0.03407879, -0.03776464]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RakLESJbcw0o"
      },
      "source": [
        "#### LSA는 SVD를 통해 찾아진 topic들을 가지고 문서와, 단어의 잠재적인 의미를 분석하는 것 입니다.\n",
        "\n",
        "각 차원에 어떤 단어들이 모여 있는지 확인해 봅시다.\n",
        "SVD를 통해 찾아진 두 잠재적 의미군(토픽)에 속하는 단어들을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBzTOqeqcw0o",
        "outputId": "9218b873-9283-450d-b94a-c51ed383a1c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# terms: 벡터화한 단어\n",
        "terms = random_search.best_estimator_.named_steps['vect'].get_feature_names()\n",
        "for index, topic in enumerate(components[:10]): # topic 최대 10개만 표시, 지금은 k가 2이므로 토픽 2개 다 프린트)\n",
        "    print('Topic %d: '%(index + 1), [terms[i] for i in topic.argsort()[::-1][:6]]) # 토픽에 가장 큰게 기여한 단어부터 최대 6단어 표시\n",
        "    print('Score %d: '%(index + 1), [topic[i] for i in topic.argsort()[::-1][:6]]) # 단어 스코어"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1:  ['people', 'don', 'like', 'know', 'just', 'think']\n",
            "Score 1:  [0.1812089691771802, 0.1480755846368723, 0.14591065367394312, 0.1395040623730916, 0.13370844711918825, 0.1236837187427575]\n",
            "Topic 2:  ['thanks', 'output', 'ingr', 'dtmedin', 'catbyte', 'circuit']\n",
            "Score 2:  [0.12865724561119146, 0.11374062140626552, 0.10726694807306968, 0.10726694807306968, 0.10726694807306968, 0.10172948540074012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbUalz1zcw0o"
      },
      "source": [
        "## Spacy 단어 임베딩을 사용합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDFev6ufcw0p"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDSnQjp8cw0p"
      },
      "source": [
        "doc = nlp(\"The tortoise jumped into the lake\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUUbE7fkcw0p"
      },
      "source": [
        "Spacy는 기본적으로 300차원으로 임베딩 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQO-FLBQcw0p"
      },
      "source": [
        "len(doc.vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRIIUlLfcw0p"
      },
      "source": [
        "def get_word_vectors(docs):\n",
        "    return [nlp(doc).vector for doc in docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oru9abO4cw0p"
      },
      "source": [
        "%%time\n",
        "X_spacy = get_word_vectors(ng_train.data)\n",
        "\n",
        "len(X_spacy) == len(ng_train.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JguT6d18cw0p"
      },
      "source": [
        "%%time\n",
        "X_test_spacy = get_word_vectors(ng_test.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp9yUsFIcw0q"
      },
      "source": [
        "랜덤포레스트로 학습해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIXwFDXlcw0q"
      },
      "source": [
        "rfc.fit(X_spacy, ng_train.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmhpNFy8cw0q"
      },
      "source": [
        "y_test_spacy = rfc.predict(X_test_spacy)\n",
        "accuracy_score(ng_test.target, y_test_spacy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqd6ojDPcw0q"
      },
      "source": [
        "#### MLP(Multi-layer perceptron classifier)를 간단히 사용해보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BFROfLCcw0q"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(solver='lbfgs'\n",
        "                   , alpha=1e-5\n",
        "                   , hidden_layer_sizes=(16,2)\n",
        "                   , random_state=2\n",
        "                   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdrbIaWEcw0q"
      },
      "source": [
        "clf.fit(X_spacy, ng_train.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jShS032cw0r"
      },
      "source": [
        "clf.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya9RqFr7cw0r"
      },
      "source": [
        "y_test = clf.predict(X_test_spacy)\n",
        "accuracy_score(ng_test.target, y_test_spacy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja8N-1lZc-jw"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvuOc9NOhA1t"
      },
      "source": [
        "## 참고자료\n",
        "\n",
        "- [NLTK Book](https://www.nltk.org/book/)\n",
        "- [KD tree algorithm: how it works](https://youtu.be/TLxWtXEbtFE)\n",
        "- [k-NN 7: how to make it faster](https://youtu.be/sCvJ3zo4DUA)\n",
        "- [An Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf)\n",
        "- [Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
        "- [A step by step explanation of PCA(principal component analysis)](http://localhost:8888/?token=ebeea486e072a985fe9597e449bd0f9cecbaec6ae8648532)\n",
        "\n",
        "### Text Classification\n",
        "- [Text Classification](https://developers.google.com/machine-learning/guides/text-classification)\n",
        "- [Text Classification using scikit-learn](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)\n",
        "\n",
        "### SVD\n",
        "- [특이값 분해(SVD)](https://angeloyeo.github.io/2019/08/01/SVD.html)\n",
        "- [Singular Value Decomposition (the SVD)](https://youtu.be/mBcLRGuAFUk)\n",
        "- [특이값 분해(Singular Value Decomposition, SVD)의 활용](https://darkpgmr.tistory.com/106)\n",
        "- [Singular Value Decomposition (SVD) tutorial](https://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm)\n",
        "- [numpy 벡터와 행렬연산 참고자료](https://ebbnflow.tistory.com/159)\n",
        "- [Image Compression with SVD](http://fourier.eng.hmc.edu/e161/lectures/svdcompression.html)\n",
        "- [Latent semantic indexing](https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html)"
      ]
    }
  ]
}